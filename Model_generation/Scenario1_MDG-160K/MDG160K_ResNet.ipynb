{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8562589866020298375\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9234234737\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 1088336075420756858\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "# 출처: https://3months.tistory.com/206 [Deep Play]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"path\" # please set the path where the dataset located in\n",
    "\n",
    "# < Important note > [ Please download input data from https://mega.nz/#F!CeYGDKyS!uqkmWJ4E2XSGJp_C2VO2gg]\n",
    "# IC50evaluation//Dataset//MDG160K\n",
    "dataset = np.load(workdir + \"//190320_cls4_druginfo_change.npz\") # MDG160K input file\n",
    "ss0 = np.load(workdir + '//190315_shuffle_split_r0.npz') # split for training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['x']\n",
    "y = dataset['y_lnIC50']\n",
    "# y_linear = dataset['y_lnIC50']\n",
    "ss0_train = ss0['train']\n",
    "ss0_test = ss0['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_array, training_label_array = x[ss0_train], y[ss0_train]\n",
    "test_image_array, test_label_array = x[ss0_test], y[ss0_test]\n",
    "\n",
    "# # In[9]:\n",
    "# ori = training_image_array\n",
    "# bat = np.zeros((ori.shape[0],178))\n",
    "# cat = np.hstack([ori,bat])\n",
    "# training_image_array = cat\n",
    "\n",
    "# # In[8]:\n",
    "# training_image_array.shape\n",
    "\n",
    "# # In[10]:\n",
    "# ori2 = test_image_array\n",
    "# bat2 = np.zeros((ori2.shape[0],178))\n",
    "# cat2 = np.hstack([ori2,bat2])\n",
    "# test_image_array = cat2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 24\n"
     ]
    }
   ],
   "source": [
    "# In[15]:\n",
    "ab =[]\n",
    "for i in range(100,300):\n",
    "    ab.append(len(training_image_array) % i)\n",
    "    \n",
    "print(min(ab), ab.index(min(ab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160375, 23538)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144338, 23538)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[21]: Hyper parameter section\n",
    "\n",
    "num_classes = 1\n",
    "learning_rate = 0.0002\n",
    "training_epochs = 150\n",
    "batch_size = 100\n",
    "img_rows, img_cols = 154, 154\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = training_image_array, training_label_array, test_image_array, test_label_array\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     train_X = train_X.reshape(train_X.shape[0], 1, img_rows, img_cols)\n",
    "#     test_X = test_X.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "# else:\n",
    "#     train_X = train_X.reshape(train_X.shape[0], img_rows, img_cols, 1)\n",
    "#     test_X = test_X.reshape(test_X.shape[0], img_rows, img_cols, 1)\n",
    "#     input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1], 1)\n",
    "#input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144338, 23538, 1) (144338,) (16037, 23538, 1) (16037,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (144338, 23538, 1)\n",
      "144338 train samples\n",
      "16037 test samples\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "# train_X /= 255\n",
    "# test_X /= 255\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144338, 23538)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 23538, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 11769, 16)    64          inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 2353, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2353, 16)     64          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2353, 16)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2353, 16)     784         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2353, 16)     64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2353, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2353, 16)     784         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2353, 16)     64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2353, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2353, 16)     784         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2353, 16)     64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2353, 16)     0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2353, 16)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2353, 16)     784         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2353, 16)     64          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2353, 16)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 2353, 16)     784         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2353, 16)     64          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2353, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2353, 16)     784         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2353, 16)     64          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 2353, 16)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 2353, 16)     784         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2353, 16)     64          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2353, 16)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2353, 16)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1177, 32)     1568        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1177, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1177, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1177, 32)     3104        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1177, 32)     3104        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1177, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1177, 32)     0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1177, 32)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1177, 32)     3104        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1177, 32)     128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1177, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1177, 32)     3104        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1177, 32)     128         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1177, 32)     0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1177, 32)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1177, 32)     3104        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1177, 32)     128         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1177, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1177, 32)     3104        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1177, 32)     128         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1177, 32)     0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1177, 32)     0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 589, 64)      6208        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 589, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 589, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 589, 64)      12352       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 589, 64)      12352       conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 589, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 589, 64)      0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 589, 64)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 589, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 589, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 589, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 589, 64)      12352       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 589, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 589, 64)      0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 589, 64)      0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 589, 64)      12352       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 589, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 589, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 589, 64)      12352       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 589, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 589, 64)      0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 589, 64)      0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 37696)        0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 2048)         77203456    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2048)         8192        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 2048)         0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2048)         0           dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense5 (Dense)                  (None, 1024)         2098176     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1024)         4096        dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout5 (Dropout)              (None, 1024)         0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1024)         0           dropout5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense6 (Dense)                  (None, 512)          524800      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512)          2048        dense6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout6 (Dropout)              (None, 512)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512)          0           dropout6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense7 (Dense)                  (None, 1024)         525312      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1024)         4096        dense7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout7 (Dropout)              (None, 1024)         0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1024)         0           dropout7[0][0]                   \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1024)         0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense8 (Dense)                  (None, 512)          524800      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 512)          2048        dense8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout8 (Dropout)              (None, 512)          0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512)          0           dropout8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense9 (Dense)                  (None, 256)          131328      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256)          1024        dense9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout9 (Dropout)              (None, 256)          0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256)          0           dropout9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense10 (Dense)                 (None, 128)          32896       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128)          512         dense10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout10 (Dropout)             (None, 128)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128)          0           dropout10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            129         activation_27[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 81,171,793\n",
      "Trainable params: 81,159,377\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "\n",
    "with K.tf.device('/GPU:0'):\n",
    "    inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     y = x\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#     x = AveragePooling1D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=2048, name='dense1'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout1') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#    x = Reshape((300,1))(x)\n",
    "\n",
    "#    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "#    x = MaxPooling1D(pool_size=2)(x)\n",
    "#    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense5'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout5') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=512, name='dense6'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout6') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense7'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout7') (x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=512, name='dense8'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout8') (x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=256, name='dense9'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout9') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=128, name='dense10'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout10') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN20190327')\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                  metrics=['mse','mae'])\n",
    "\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2019-05-11 23:10:51.941345\n",
      "Train on 144338 samples, validate on 16037 samples\n",
      "Epoch 1/150\n",
      "144338/144338 [==============================] - 219s 2ms/step - loss: 2.3809 - mean_squared_error: 2.3809 - mean_absolute_error: 1.1645 - val_loss: 1.7788 - val_mean_squared_error: 1.7788 - val_mean_absolute_error: 1.0023\n",
      "Epoch 2/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 1.7549 - mean_squared_error: 1.7549 - mean_absolute_error: 0.9988 - val_loss: 1.5495 - val_mean_squared_error: 1.5495 - val_mean_absolute_error: 0.9289\n",
      "Epoch 3/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 1.5516 - mean_squared_error: 1.5516 - mean_absolute_error: 0.9371 - val_loss: 1.4778 - val_mean_squared_error: 1.4778 - val_mean_absolute_error: 0.9065\n",
      "Epoch 4/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 1.3964 - mean_squared_error: 1.3964 - mean_absolute_error: 0.8888 - val_loss: 1.3662 - val_mean_squared_error: 1.3662 - val_mean_absolute_error: 0.8627\n",
      "Epoch 5/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 1.2469 - mean_squared_error: 1.2469 - mean_absolute_error: 0.8410 - val_loss: 1.3083 - val_mean_squared_error: 1.3083 - val_mean_absolute_error: 0.8325\n",
      "Epoch 6/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 1.1326 - mean_squared_error: 1.1326 - mean_absolute_error: 0.8008 - val_loss: 1.2207 - val_mean_squared_error: 1.2207 - val_mean_absolute_error: 0.8118\n",
      "Epoch 7/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 1.0115 - mean_squared_error: 1.0115 - mean_absolute_error: 0.7607 - val_loss: 1.1927 - val_mean_squared_error: 1.1927 - val_mean_absolute_error: 0.8025\n",
      "Epoch 8/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.9242 - mean_squared_error: 0.9242 - mean_absolute_error: 0.7273 - val_loss: 1.1512 - val_mean_squared_error: 1.1512 - val_mean_absolute_error: 0.7954\n",
      "Epoch 9/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.8195 - mean_squared_error: 0.8195 - mean_absolute_error: 0.6893 - val_loss: 1.0945 - val_mean_squared_error: 1.0945 - val_mean_absolute_error: 0.7591\n",
      "Epoch 10/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.7389 - mean_squared_error: 0.7389 - mean_absolute_error: 0.6548 - val_loss: 1.0853 - val_mean_squared_error: 1.0853 - val_mean_absolute_error: 0.7627\n",
      "Epoch 11/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.6623 - mean_squared_error: 0.6623 - mean_absolute_error: 0.6220 - val_loss: 1.0805 - val_mean_squared_error: 1.0805 - val_mean_absolute_error: 0.7516\n",
      "Epoch 12/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.6051 - mean_squared_error: 0.6051 - mean_absolute_error: 0.5959 - val_loss: 1.0501 - val_mean_squared_error: 1.0501 - val_mean_absolute_error: 0.7399\n",
      "Epoch 13/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.5486 - mean_squared_error: 0.5486 - mean_absolute_error: 0.5683 - val_loss: 1.0429 - val_mean_squared_error: 1.0429 - val_mean_absolute_error: 0.7376\n",
      "Epoch 14/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.4947 - mean_squared_error: 0.4947 - mean_absolute_error: 0.5417 - val_loss: 1.0303 - val_mean_squared_error: 1.0303 - val_mean_absolute_error: 0.7394\n",
      "Epoch 15/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.4561 - mean_squared_error: 0.4561 - mean_absolute_error: 0.5204 - val_loss: 1.0088 - val_mean_squared_error: 1.0088 - val_mean_absolute_error: 0.7239\n",
      "Epoch 16/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.4238 - mean_squared_error: 0.4238 - mean_absolute_error: 0.5021 - val_loss: 1.0277 - val_mean_squared_error: 1.0277 - val_mean_absolute_error: 0.7360\n",
      "Epoch 17/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.3948 - mean_squared_error: 0.3948 - mean_absolute_error: 0.4848 - val_loss: 1.0444 - val_mean_squared_error: 1.0444 - val_mean_absolute_error: 0.7435\n",
      "Epoch 18/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.3676 - mean_squared_error: 0.3676 - mean_absolute_error: 0.4678 - val_loss: 1.0415 - val_mean_squared_error: 1.0415 - val_mean_absolute_error: 0.7398\n",
      "Epoch 19/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.3501 - mean_squared_error: 0.3501 - mean_absolute_error: 0.4564 - val_loss: 0.9797 - val_mean_squared_error: 0.9797 - val_mean_absolute_error: 0.7147\n",
      "Epoch 20/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.3247 - mean_squared_error: 0.3247 - mean_absolute_error: 0.4402 - val_loss: 0.9947 - val_mean_squared_error: 0.9947 - val_mean_absolute_error: 0.7173\n",
      "Epoch 21/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.3102 - mean_squared_error: 0.3102 - mean_absolute_error: 0.4302 - val_loss: 0.9942 - val_mean_squared_error: 0.9942 - val_mean_absolute_error: 0.7195\n",
      "Epoch 22/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2936 - mean_squared_error: 0.2936 - mean_absolute_error: 0.4181 - val_loss: 0.9767 - val_mean_squared_error: 0.9767 - val_mean_absolute_error: 0.7115\n",
      "Epoch 23/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2789 - mean_squared_error: 0.2789 - mean_absolute_error: 0.4077 - val_loss: 0.9796 - val_mean_squared_error: 0.9796 - val_mean_absolute_error: 0.7211\n",
      "Epoch 24/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2696 - mean_squared_error: 0.2696 - mean_absolute_error: 0.4006 - val_loss: 0.9675 - val_mean_squared_error: 0.9675 - val_mean_absolute_error: 0.7060\n",
      "Epoch 25/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2535 - mean_squared_error: 0.2535 - mean_absolute_error: 0.3892 - val_loss: 0.9668 - val_mean_squared_error: 0.9668 - val_mean_absolute_error: 0.7079\n",
      "Epoch 26/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2458 - mean_squared_error: 0.2458 - mean_absolute_error: 0.3824 - val_loss: 0.9712 - val_mean_squared_error: 0.9712 - val_mean_absolute_error: 0.7095\n",
      "Epoch 27/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2373 - mean_squared_error: 0.2373 - mean_absolute_error: 0.3760 - val_loss: 0.9680 - val_mean_squared_error: 0.9680 - val_mean_absolute_error: 0.7078\n",
      "Epoch 28/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2282 - mean_squared_error: 0.2282 - mean_absolute_error: 0.3678 - val_loss: 0.9648 - val_mean_squared_error: 0.9648 - val_mean_absolute_error: 0.7051\n",
      "Epoch 29/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2184 - mean_squared_error: 0.2184 - mean_absolute_error: 0.3606 - val_loss: 0.9625 - val_mean_squared_error: 0.9625 - val_mean_absolute_error: 0.7065\n",
      "Epoch 30/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2125 - mean_squared_error: 0.2125 - mean_absolute_error: 0.3555 - val_loss: 0.9608 - val_mean_squared_error: 0.9608 - val_mean_absolute_error: 0.7044\n",
      "Epoch 31/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.2019 - mean_squared_error: 0.2019 - mean_absolute_error: 0.3473 - val_loss: 0.9606 - val_mean_squared_error: 0.9606 - val_mean_absolute_error: 0.7062\n",
      "Epoch 32/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1982 - mean_squared_error: 0.1982 - mean_absolute_error: 0.3439 - val_loss: 0.9337 - val_mean_squared_error: 0.9337 - val_mean_absolute_error: 0.6960\n",
      "Epoch 33/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1954 - mean_squared_error: 0.1954 - mean_absolute_error: 0.3406 - val_loss: 0.9691 - val_mean_squared_error: 0.9691 - val_mean_absolute_error: 0.7037\n",
      "Epoch 34/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1884 - mean_squared_error: 0.1884 - mean_absolute_error: 0.3344 - val_loss: 0.9599 - val_mean_squared_error: 0.9599 - val_mean_absolute_error: 0.7002\n",
      "Epoch 35/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1835 - mean_squared_error: 0.1835 - mean_absolute_error: 0.3304 - val_loss: 0.9374 - val_mean_squared_error: 0.9374 - val_mean_absolute_error: 0.6964\n",
      "Epoch 36/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1787 - mean_squared_error: 0.1787 - mean_absolute_error: 0.3265 - val_loss: 0.9403 - val_mean_squared_error: 0.9403 - val_mean_absolute_error: 0.6934\n",
      "Epoch 37/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1728 - mean_squared_error: 0.1728 - mean_absolute_error: 0.3210 - val_loss: 0.9478 - val_mean_squared_error: 0.9478 - val_mean_absolute_error: 0.6964\n",
      "Epoch 38/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1724 - mean_squared_error: 0.1724 - mean_absolute_error: 0.3197 - val_loss: 0.9316 - val_mean_squared_error: 0.9316 - val_mean_absolute_error: 0.6881\n",
      "Epoch 39/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - mean_absolute_error: 0.3135 - val_loss: 0.9384 - val_mean_squared_error: 0.9384 - val_mean_absolute_error: 0.6965\n",
      "Epoch 40/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - mean_absolute_error: 0.3128 - val_loss: 0.9448 - val_mean_squared_error: 0.9448 - val_mean_absolute_error: 0.6917\n",
      "Epoch 41/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1617 - mean_squared_error: 0.1617 - mean_absolute_error: 0.3084 - val_loss: 0.9301 - val_mean_squared_error: 0.9301 - val_mean_absolute_error: 0.6904\n",
      "Epoch 42/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1558 - mean_squared_error: 0.1558 - mean_absolute_error: 0.3032 - val_loss: 0.9288 - val_mean_squared_error: 0.9288 - val_mean_absolute_error: 0.6940\n",
      "Epoch 43/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1557 - mean_squared_error: 0.1557 - mean_absolute_error: 0.3032 - val_loss: 0.9376 - val_mean_squared_error: 0.9376 - val_mean_absolute_error: 0.6913\n",
      "Epoch 44/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1500 - mean_squared_error: 0.1500 - mean_absolute_error: 0.2987 - val_loss: 0.9247 - val_mean_squared_error: 0.9247 - val_mean_absolute_error: 0.6904\n",
      "Epoch 45/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.1462 - mean_squared_error: 0.1462 - mean_absolute_error: 0.2942 - val_loss: 0.9193 - val_mean_squared_error: 0.9193 - val_mean_absolute_error: 0.6903\n",
      "Epoch 46/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1434 - mean_squared_error: 0.1434 - mean_absolute_error: 0.2917 - val_loss: 0.9160 - val_mean_squared_error: 0.9160 - val_mean_absolute_error: 0.6819\n",
      "Epoch 47/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1443 - mean_squared_error: 0.1443 - mean_absolute_error: 0.2927 - val_loss: 0.9196 - val_mean_squared_error: 0.9196 - val_mean_absolute_error: 0.6874\n",
      "Epoch 48/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1408 - mean_squared_error: 0.1408 - mean_absolute_error: 0.2886 - val_loss: 0.9471 - val_mean_squared_error: 0.9471 - val_mean_absolute_error: 0.7015\n",
      "Epoch 49/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1367 - mean_squared_error: 0.1367 - mean_absolute_error: 0.2846 - val_loss: 0.9241 - val_mean_squared_error: 0.9241 - val_mean_absolute_error: 0.6838\n",
      "Epoch 50/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1366 - mean_squared_error: 0.1366 - mean_absolute_error: 0.2838 - val_loss: 0.9271 - val_mean_squared_error: 0.9271 - val_mean_absolute_error: 0.6851\n",
      "Epoch 51/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1331 - mean_squared_error: 0.1331 - mean_absolute_error: 0.2808 - val_loss: 0.9111 - val_mean_squared_error: 0.9111 - val_mean_absolute_error: 0.6819\n",
      "Epoch 52/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1323 - mean_squared_error: 0.1323 - mean_absolute_error: 0.2798 - val_loss: 0.9297 - val_mean_squared_error: 0.9297 - val_mean_absolute_error: 0.6899\n",
      "Epoch 53/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1300 - mean_squared_error: 0.1300 - mean_absolute_error: 0.2764 - val_loss: 0.9202 - val_mean_squared_error: 0.9202 - val_mean_absolute_error: 0.6890\n",
      "Epoch 54/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1288 - mean_squared_error: 0.1288 - mean_absolute_error: 0.2759 - val_loss: 0.9346 - val_mean_squared_error: 0.9346 - val_mean_absolute_error: 0.6869\n",
      "Epoch 55/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1259 - mean_squared_error: 0.1259 - mean_absolute_error: 0.2727 - val_loss: 0.9129 - val_mean_squared_error: 0.9129 - val_mean_absolute_error: 0.6826\n",
      "Epoch 56/150\n",
      "144338/144338 [==============================] - 222s 2ms/step - loss: 0.1234 - mean_squared_error: 0.1234 - mean_absolute_error: 0.2698 - val_loss: 0.9168 - val_mean_squared_error: 0.9168 - val_mean_absolute_error: 0.6819\n",
      "Epoch 57/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1204 - mean_squared_error: 0.1204 - mean_absolute_error: 0.2666 - val_loss: 0.9223 - val_mean_squared_error: 0.9223 - val_mean_absolute_error: 0.6875\n",
      "Epoch 58/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1196 - mean_squared_error: 0.1196 - mean_absolute_error: 0.2657 - val_loss: 0.9182 - val_mean_squared_error: 0.9182 - val_mean_absolute_error: 0.6877\n",
      "Epoch 59/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1248 - mean_squared_error: 0.1248 - mean_absolute_error: 0.2689 - val_loss: 0.9283 - val_mean_squared_error: 0.9283 - val_mean_absolute_error: 0.6870\n",
      "Epoch 60/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1162 - mean_squared_error: 0.1162 - mean_absolute_error: 0.2614 - val_loss: 0.9184 - val_mean_squared_error: 0.9184 - val_mean_absolute_error: 0.6823\n",
      "Epoch 61/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1171 - mean_squared_error: 0.1171 - mean_absolute_error: 0.2619 - val_loss: 0.9197 - val_mean_squared_error: 0.9197 - val_mean_absolute_error: 0.6846\n",
      "Epoch 62/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1119 - mean_squared_error: 0.1119 - mean_absolute_error: 0.2576 - val_loss: 0.9155 - val_mean_squared_error: 0.9155 - val_mean_absolute_error: 0.6846\n",
      "Epoch 63/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1149 - mean_squared_error: 0.1149 - mean_absolute_error: 0.2595 - val_loss: 0.9200 - val_mean_squared_error: 0.9200 - val_mean_absolute_error: 0.6825\n",
      "Epoch 64/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1104 - mean_squared_error: 0.1104 - mean_absolute_error: 0.2554 - val_loss: 0.9100 - val_mean_squared_error: 0.9100 - val_mean_absolute_error: 0.6834\n",
      "Epoch 65/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1093 - mean_squared_error: 0.1093 - mean_absolute_error: 0.2538 - val_loss: 0.9116 - val_mean_squared_error: 0.9116 - val_mean_absolute_error: 0.6854\n",
      "Epoch 66/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1089 - mean_squared_error: 0.1089 - mean_absolute_error: 0.2530 - val_loss: 0.9118 - val_mean_squared_error: 0.9118 - val_mean_absolute_error: 0.6805\n",
      "Epoch 67/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1069 - mean_squared_error: 0.1069 - mean_absolute_error: 0.2510 - val_loss: 0.9213 - val_mean_squared_error: 0.9213 - val_mean_absolute_error: 0.6827\n",
      "Epoch 68/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1074 - mean_squared_error: 0.1074 - mean_absolute_error: 0.2508 - val_loss: 0.9140 - val_mean_squared_error: 0.9140 - val_mean_absolute_error: 0.6790\n",
      "Epoch 69/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1048 - mean_squared_error: 0.1048 - mean_absolute_error: 0.2481 - val_loss: 0.9154 - val_mean_squared_error: 0.9154 - val_mean_absolute_error: 0.6827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1046 - mean_squared_error: 0.1046 - mean_absolute_error: 0.2472 - val_loss: 0.9163 - val_mean_squared_error: 0.9163 - val_mean_absolute_error: 0.6808\n",
      "Epoch 71/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1037 - mean_squared_error: 0.1037 - mean_absolute_error: 0.2467 - val_loss: 0.9181 - val_mean_squared_error: 0.9181 - val_mean_absolute_error: 0.6840\n",
      "Epoch 72/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1017 - mean_squared_error: 0.1017 - mean_absolute_error: 0.2442 - val_loss: 0.9058 - val_mean_squared_error: 0.9058 - val_mean_absolute_error: 0.6799\n",
      "Epoch 73/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.1030 - mean_squared_error: 0.1030 - mean_absolute_error: 0.2449 - val_loss: 0.9172 - val_mean_squared_error: 0.9172 - val_mean_absolute_error: 0.6830\n",
      "Epoch 74/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0994 - mean_squared_error: 0.0994 - mean_absolute_error: 0.2407 - val_loss: 0.9107 - val_mean_squared_error: 0.9107 - val_mean_absolute_error: 0.6784\n",
      "Epoch 75/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0978 - mean_squared_error: 0.0978 - mean_absolute_error: 0.2397 - val_loss: 0.9083 - val_mean_squared_error: 0.9083 - val_mean_absolute_error: 0.6781\n",
      "Epoch 76/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0987 - mean_squared_error: 0.0987 - mean_absolute_error: 0.2403 - val_loss: 0.9187 - val_mean_squared_error: 0.9187 - val_mean_absolute_error: 0.6803\n",
      "Epoch 77/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0964 - mean_squared_error: 0.0964 - mean_absolute_error: 0.2378 - val_loss: 0.9171 - val_mean_squared_error: 0.9171 - val_mean_absolute_error: 0.6807\n",
      "Epoch 78/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0957 - mean_squared_error: 0.0957 - mean_absolute_error: 0.2366 - val_loss: 0.9167 - val_mean_squared_error: 0.9167 - val_mean_absolute_error: 0.6805\n",
      "Epoch 79/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.0947 - mean_squared_error: 0.0947 - mean_absolute_error: 0.2354 - val_loss: 0.9120 - val_mean_squared_error: 0.9120 - val_mean_absolute_error: 0.6772\n",
      "Epoch 80/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0938 - mean_squared_error: 0.0938 - mean_absolute_error: 0.2343 - val_loss: 0.9491 - val_mean_squared_error: 0.9491 - val_mean_absolute_error: 0.6940\n",
      "Epoch 81/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.0953 - mean_squared_error: 0.0953 - mean_absolute_error: 0.2354 - val_loss: 0.9074 - val_mean_squared_error: 0.9074 - val_mean_absolute_error: 0.6802\n",
      "Epoch 82/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0915 - mean_squared_error: 0.0915 - mean_absolute_error: 0.2321 - val_loss: 0.9234 - val_mean_squared_error: 0.9234 - val_mean_absolute_error: 0.6831\n",
      "Epoch 83/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0919 - mean_squared_error: 0.0919 - mean_absolute_error: 0.2314 - val_loss: 0.9198 - val_mean_squared_error: 0.9198 - val_mean_absolute_error: 0.6807\n",
      "Epoch 84/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - mean_absolute_error: 0.2301 - val_loss: 0.9169 - val_mean_squared_error: 0.9169 - val_mean_absolute_error: 0.6821\n",
      "Epoch 85/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0900 - mean_squared_error: 0.0900 - mean_absolute_error: 0.2292 - val_loss: 0.9248 - val_mean_squared_error: 0.9248 - val_mean_absolute_error: 0.6816\n",
      "Epoch 86/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0900 - mean_squared_error: 0.0900 - mean_absolute_error: 0.2292 - val_loss: 0.9146 - val_mean_squared_error: 0.9146 - val_mean_absolute_error: 0.6845\n",
      "Epoch 87/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0891 - mean_squared_error: 0.0891 - mean_absolute_error: 0.2279 - val_loss: 0.9309 - val_mean_squared_error: 0.9309 - val_mean_absolute_error: 0.6834\n",
      "Epoch 88/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0889 - mean_squared_error: 0.0889 - mean_absolute_error: 0.2270 - val_loss: 0.9176 - val_mean_squared_error: 0.9176 - val_mean_absolute_error: 0.6824\n",
      "Epoch 89/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0860 - mean_squared_error: 0.0860 - mean_absolute_error: 0.2240 - val_loss: 0.9088 - val_mean_squared_error: 0.9088 - val_mean_absolute_error: 0.6760\n",
      "Epoch 90/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0868 - mean_squared_error: 0.0868 - mean_absolute_error: 0.2245 - val_loss: 0.9123 - val_mean_squared_error: 0.9123 - val_mean_absolute_error: 0.6780\n",
      "Epoch 91/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0865 - mean_squared_error: 0.0865 - mean_absolute_error: 0.2239 - val_loss: 0.9118 - val_mean_squared_error: 0.9118 - val_mean_absolute_error: 0.6787\n",
      "Epoch 92/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0857 - mean_squared_error: 0.0857 - mean_absolute_error: 0.2229 - val_loss: 0.9126 - val_mean_squared_error: 0.9126 - val_mean_absolute_error: 0.6782\n",
      "Epoch 93/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0853 - mean_squared_error: 0.0853 - mean_absolute_error: 0.2216 - val_loss: 0.9247 - val_mean_squared_error: 0.9247 - val_mean_absolute_error: 0.6835\n",
      "Epoch 94/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0840 - mean_squared_error: 0.0840 - mean_absolute_error: 0.2210 - val_loss: 0.9149 - val_mean_squared_error: 0.9149 - val_mean_absolute_error: 0.6788\n",
      "Epoch 95/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0841 - mean_squared_error: 0.0841 - mean_absolute_error: 0.2205 - val_loss: 0.9150 - val_mean_squared_error: 0.9150 - val_mean_absolute_error: 0.6803\n",
      "Epoch 96/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0839 - mean_squared_error: 0.0839 - mean_absolute_error: 0.2202 - val_loss: 0.9156 - val_mean_squared_error: 0.9156 - val_mean_absolute_error: 0.6775\n",
      "Epoch 97/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0818 - mean_squared_error: 0.0818 - mean_absolute_error: 0.2170 - val_loss: 0.9189 - val_mean_squared_error: 0.9189 - val_mean_absolute_error: 0.6822\n",
      "Epoch 98/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0813 - mean_squared_error: 0.0813 - mean_absolute_error: 0.2167 - val_loss: 0.9277 - val_mean_squared_error: 0.9277 - val_mean_absolute_error: 0.6837\n",
      "Epoch 99/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0823 - mean_squared_error: 0.0823 - mean_absolute_error: 0.2180 - val_loss: 0.9159 - val_mean_squared_error: 0.9159 - val_mean_absolute_error: 0.6797\n",
      "Epoch 100/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0800 - mean_squared_error: 0.0800 - mean_absolute_error: 0.2151 - val_loss: 0.9153 - val_mean_squared_error: 0.9153 - val_mean_absolute_error: 0.6779\n",
      "Epoch 101/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0798 - mean_squared_error: 0.0798 - mean_absolute_error: 0.2148 - val_loss: 0.9136 - val_mean_squared_error: 0.9136 - val_mean_absolute_error: 0.6790\n",
      "Epoch 102/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0808 - mean_squared_error: 0.0808 - mean_absolute_error: 0.2155 - val_loss: 0.9102 - val_mean_squared_error: 0.9102 - val_mean_absolute_error: 0.6751\n",
      "Epoch 103/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0802 - mean_squared_error: 0.0802 - mean_absolute_error: 0.2157 - val_loss: 0.9257 - val_mean_squared_error: 0.9257 - val_mean_absolute_error: 0.6805\n",
      "Epoch 104/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0784 - mean_squared_error: 0.0784 - mean_absolute_error: 0.2126 - val_loss: 0.9189 - val_mean_squared_error: 0.9189 - val_mean_absolute_error: 0.6829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0810 - mean_squared_error: 0.0810 - mean_absolute_error: 0.2150 - val_loss: 0.9165 - val_mean_squared_error: 0.9165 - val_mean_absolute_error: 0.6748\n",
      "Epoch 106/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0767 - mean_squared_error: 0.0767 - mean_absolute_error: 0.2102 - val_loss: 0.9256 - val_mean_squared_error: 0.9256 - val_mean_absolute_error: 0.6807\n",
      "Epoch 107/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0766 - mean_squared_error: 0.0766 - mean_absolute_error: 0.2099 - val_loss: 0.9154 - val_mean_squared_error: 0.9154 - val_mean_absolute_error: 0.6774\n",
      "Epoch 108/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0752 - mean_squared_error: 0.0752 - mean_absolute_error: 0.2083 - val_loss: 0.9133 - val_mean_squared_error: 0.9133 - val_mean_absolute_error: 0.6766\n",
      "Epoch 109/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0761 - mean_squared_error: 0.0761 - mean_absolute_error: 0.2098 - val_loss: 0.9152 - val_mean_squared_error: 0.9152 - val_mean_absolute_error: 0.6780\n",
      "Epoch 110/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0770 - mean_squared_error: 0.0770 - mean_absolute_error: 0.2106 - val_loss: 0.9218 - val_mean_squared_error: 0.9218 - val_mean_absolute_error: 0.6794\n",
      "Epoch 111/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0744 - mean_squared_error: 0.0744 - mean_absolute_error: 0.2076 - val_loss: 0.9192 - val_mean_squared_error: 0.9192 - val_mean_absolute_error: 0.6821\n",
      "Epoch 112/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0737 - mean_squared_error: 0.0737 - mean_absolute_error: 0.2063 - val_loss: 0.9405 - val_mean_squared_error: 0.9405 - val_mean_absolute_error: 0.6937\n",
      "Epoch 113/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0740 - mean_squared_error: 0.0740 - mean_absolute_error: 0.2065 - val_loss: 0.9135 - val_mean_squared_error: 0.9135 - val_mean_absolute_error: 0.6791\n",
      "Epoch 114/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0741 - mean_squared_error: 0.0741 - mean_absolute_error: 0.2058 - val_loss: 0.9228 - val_mean_squared_error: 0.9228 - val_mean_absolute_error: 0.6789\n",
      "Epoch 115/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - mean_absolute_error: 0.2063 - val_loss: 0.9173 - val_mean_squared_error: 0.9173 - val_mean_absolute_error: 0.6765\n",
      "Epoch 116/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0741 - mean_squared_error: 0.0741 - mean_absolute_error: 0.2057 - val_loss: 0.9309 - val_mean_squared_error: 0.9309 - val_mean_absolute_error: 0.6785\n",
      "Epoch 117/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.0718 - mean_squared_error: 0.0718 - mean_absolute_error: 0.2026 - val_loss: 0.9272 - val_mean_squared_error: 0.9272 - val_mean_absolute_error: 0.6831\n",
      "Epoch 118/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0713 - mean_squared_error: 0.0713 - mean_absolute_error: 0.2024 - val_loss: 0.9228 - val_mean_squared_error: 0.9228 - val_mean_absolute_error: 0.6821\n",
      "Epoch 119/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0722 - mean_squared_error: 0.0722 - mean_absolute_error: 0.2032 - val_loss: 0.9207 - val_mean_squared_error: 0.9207 - val_mean_absolute_error: 0.6805\n",
      "Epoch 120/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0716 - mean_squared_error: 0.0716 - mean_absolute_error: 0.2020 - val_loss: 0.9330 - val_mean_squared_error: 0.9330 - val_mean_absolute_error: 0.6856\n",
      "Epoch 121/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0721 - mean_squared_error: 0.0721 - mean_absolute_error: 0.2027 - val_loss: 0.9247 - val_mean_squared_error: 0.9247 - val_mean_absolute_error: 0.6807\n",
      "Epoch 122/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0707 - mean_squared_error: 0.0707 - mean_absolute_error: 0.2011 - val_loss: 0.9385 - val_mean_squared_error: 0.9385 - val_mean_absolute_error: 0.6902\n",
      "Epoch 123/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0725 - mean_squared_error: 0.0725 - mean_absolute_error: 0.2026 - val_loss: 0.9280 - val_mean_squared_error: 0.9280 - val_mean_absolute_error: 0.6838\n",
      "Epoch 124/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0687 - mean_squared_error: 0.0687 - mean_absolute_error: 0.1983 - val_loss: 0.9278 - val_mean_squared_error: 0.9278 - val_mean_absolute_error: 0.6804\n",
      "Epoch 125/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0681 - mean_squared_error: 0.0681 - mean_absolute_error: 0.1977 - val_loss: 0.9452 - val_mean_squared_error: 0.9452 - val_mean_absolute_error: 0.6895\n",
      "Epoch 126/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0710 - mean_squared_error: 0.0710 - mean_absolute_error: 0.2005 - val_loss: 0.9395 - val_mean_squared_error: 0.9395 - val_mean_absolute_error: 0.6855\n",
      "Epoch 127/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0694 - mean_squared_error: 0.0694 - mean_absolute_error: 0.1989 - val_loss: 0.9593 - val_mean_squared_error: 0.9593 - val_mean_absolute_error: 0.6915\n",
      "Epoch 128/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0687 - mean_squared_error: 0.0687 - mean_absolute_error: 0.1973 - val_loss: 0.9296 - val_mean_squared_error: 0.9296 - val_mean_absolute_error: 0.6850\n",
      "Epoch 129/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0682 - mean_squared_error: 0.0682 - mean_absolute_error: 0.1971 - val_loss: 0.9407 - val_mean_squared_error: 0.9407 - val_mean_absolute_error: 0.6877\n",
      "Epoch 130/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0701 - mean_squared_error: 0.0701 - mean_absolute_error: 0.1995 - val_loss: 0.9294 - val_mean_squared_error: 0.9294 - val_mean_absolute_error: 0.6811\n",
      "Epoch 131/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0674 - mean_squared_error: 0.0674 - mean_absolute_error: 0.1961 - val_loss: 0.9219 - val_mean_squared_error: 0.9219 - val_mean_absolute_error: 0.6783\n",
      "Epoch 132/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0666 - mean_squared_error: 0.0666 - mean_absolute_error: 0.1949 - val_loss: 0.9432 - val_mean_squared_error: 0.9432 - val_mean_absolute_error: 0.6908\n",
      "Epoch 133/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0693 - mean_squared_error: 0.0693 - mean_absolute_error: 0.1971 - val_loss: 0.9257 - val_mean_squared_error: 0.9257 - val_mean_absolute_error: 0.6800\n",
      "Epoch 134/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0664 - mean_squared_error: 0.0664 - mean_absolute_error: 0.1940 - val_loss: 0.9326 - val_mean_squared_error: 0.9326 - val_mean_absolute_error: 0.6851\n",
      "Epoch 135/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0670 - mean_squared_error: 0.0670 - mean_absolute_error: 0.1948 - val_loss: 0.9398 - val_mean_squared_error: 0.9398 - val_mean_absolute_error: 0.6851\n",
      "Epoch 136/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0668 - mean_squared_error: 0.0668 - mean_absolute_error: 0.1944 - val_loss: 0.9484 - val_mean_squared_error: 0.9484 - val_mean_absolute_error: 0.6868\n",
      "Epoch 137/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0668 - mean_squared_error: 0.0668 - mean_absolute_error: 0.1944 - val_loss: 0.9393 - val_mean_squared_error: 0.9393 - val_mean_absolute_error: 0.6884\n",
      "Epoch 138/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0656 - mean_squared_error: 0.0656 - mean_absolute_error: 0.1919 - val_loss: 0.9214 - val_mean_squared_error: 0.9214 - val_mean_absolute_error: 0.6787\n",
      "Epoch 139/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0645 - mean_squared_error: 0.0645 - mean_absolute_error: 0.1911 - val_loss: 0.9389 - val_mean_squared_error: 0.9389 - val_mean_absolute_error: 0.6847\n",
      "Epoch 140/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0647 - mean_squared_error: 0.0647 - mean_absolute_error: 0.1913 - val_loss: 0.9266 - val_mean_squared_error: 0.9266 - val_mean_absolute_error: 0.6823\n",
      "Epoch 141/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0652 - mean_squared_error: 0.0652 - mean_absolute_error: 0.1921 - val_loss: 0.9310 - val_mean_squared_error: 0.9310 - val_mean_absolute_error: 0.6836\n",
      "Epoch 142/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0638 - mean_squared_error: 0.0638 - mean_absolute_error: 0.1900 - val_loss: 0.9287 - val_mean_squared_error: 0.9287 - val_mean_absolute_error: 0.6827\n",
      "Epoch 143/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0646 - mean_squared_error: 0.0646 - mean_absolute_error: 0.1904 - val_loss: 0.9427 - val_mean_squared_error: 0.9427 - val_mean_absolute_error: 0.6875\n",
      "Epoch 144/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0645 - mean_squared_error: 0.0645 - mean_absolute_error: 0.1911 - val_loss: 0.9450 - val_mean_squared_error: 0.9450 - val_mean_absolute_error: 0.6865\n",
      "Epoch 145/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0627 - mean_squared_error: 0.0627 - mean_absolute_error: 0.1883 - val_loss: 0.9172 - val_mean_squared_error: 0.9172 - val_mean_absolute_error: 0.6810\n",
      "Epoch 146/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.0625 - mean_squared_error: 0.0625 - mean_absolute_error: 0.1881 - val_loss: 0.9366 - val_mean_squared_error: 0.9366 - val_mean_absolute_error: 0.6837\n",
      "Epoch 147/150\n",
      "144338/144338 [==============================] - 214s 1ms/step - loss: 0.0643 - mean_squared_error: 0.0643 - mean_absolute_error: 0.1901 - val_loss: 0.9358 - val_mean_squared_error: 0.9358 - val_mean_absolute_error: 0.6824\n",
      "Epoch 148/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0619 - mean_squared_error: 0.0619 - mean_absolute_error: 0.1874 - val_loss: 0.9344 - val_mean_squared_error: 0.9344 - val_mean_absolute_error: 0.6859\n",
      "Epoch 149/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0634 - mean_squared_error: 0.0634 - mean_absolute_error: 0.1890 - val_loss: 0.9363 - val_mean_squared_error: 0.9363 - val_mean_absolute_error: 0.6855\n",
      "Epoch 150/150\n",
      "144338/144338 [==============================] - 213s 1ms/step - loss: 0.0633 - mean_squared_error: 0.0633 - mean_absolute_error: 0.1881 - val_loss: 0.9338 - val_mean_squared_error: 0.9338 - val_mean_absolute_error: 0.6807\n",
      "EndTime : 2019-05-12 08:04:09.374007\n"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "\n",
    "StartTime8 = datetime.now()\n",
    "print(\"StartTime :\", StartTime8)\n",
    "with K.tf.device('/GPU:0'):\n",
    "    model_train = model.fit(train_X, training_label_array, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                        validation_data=(test_X, test_label_array))\n",
    "\n",
    "EndTime8 = datetime.now()\n",
    "print(\"EndTime :\", EndTime8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture and its weight\n",
    "\n",
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"C://Users//a//Desktop//Ronny_TF//Ronny_Deep_vs_CDRscan//DeepIC50v2_epoch_150\"\n",
    "# Option 1: Save Weights + Architecture\n",
    "model.save_weights(workdir+ '//model_fix_v3.h5')\n",
    "with open(workdir + '//model_architecture_fix_v3.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "# Option 1: Load Weights + Architecture\n",
    "# with open('model_architecture.json', 'r') as f:\n",
    "#     new_model_1 = model_from_json(f.read())\n",
    "# new_model_1.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Save/Load the Entire Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save(workdir + '//model_fix_2080ti_v3.h5')\n",
    "\n",
    "# Deletes the existing model\n",
    "# del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16037/16037 [==============================] - 8s 478us/step\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(test_X, test_label_array, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.933780104284268, 0.933780104284268, 0.6807030336907538]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse and loss monitor\n",
    "\n",
    "accuracy = model_train.history['mean_squared_error']\n",
    "val_accuracy = model_train.history['val_mean_squared_error']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "\n",
    "np_acc = np.array(accuracy)\n",
    "np_val_acc = np.array(val_accuracy)\n",
    "np_loss = np.array(loss)\n",
    "np_val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '//190510_DeepIC50v2_fix_2080ti_v3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-654fbea32f80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//190510_DeepIC50v2_fix_2080ti_v3.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//190510_DeepIC50v2_fixval_acc_cls3_fix_2080ti_v3.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp_val_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//190510_DeepIC50v2_fixloss_cls3_fix_2080ti_v3.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//190510_DeepIC50v2_fixval_loss_cls3_fix_2080ti_v3.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp_val_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1305\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m         \u001b[1;31m# datasource doesn't support creating a new file ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m         \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1308\u001b[0m         \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[0mown_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '//190510_DeepIC50v2_fix_2080ti_v3.csv'"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"190510_DeepIC50v2_fix_2080ti_v3.csv\", np_acc, delimiter=\",\")\n",
    "np.savetxt(\"190510_DeepIC50v2_fixval_acc_cls3_fix_2080ti_v3.csv\", np_val_acc, delimiter=\",\")\n",
    "np.savetxt(\"190510_DeepIC50v2_fixloss_cls3_fix_2080ti_v3.csv\", np_loss, delimiter=\",\")\n",
    "np.savetxt(\"190510_DeepIC50v2_fixval_loss_cls3_fix_2080ti_v3.csv\", np_val_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcFNW5//HPwy6MiCwKArLFlW0cBhXF3SgYt6sokDERRTGYmOQa7y8qxhivZr+4JC5xvVEQI3qNxrjEhRiXRAUEFJCAOCirMCrIKsM8vz9ONdMM3TM9Mz3T093f9+vVr+6uqq56urr7qdPnnDpl7o6IiOSWZpkOQERE0k/JXUQkBym5i4jkICV3EZEcpOQuIpKDlNxFRHKQkrvsxsyam9lGM9s/nctmkpl9zczS3u/XzE42s9K454vM7JhUlq3Dtu4zs2vr+nrJLy0yHYDUn5ltjHvaFtgG7IieX+buU2uzPnffARSke9l84O4HpWM9ZnYJcIG7Hx+37kvSsW7JD0ruOcDddybXqGR4ibu/lGx5M2vh7uWNEZuIZIaqZfKAmd1kZn8ys2lm9iVwgZkNM7N/mdkXZrbKzG43s5bR8i3MzM2sd/R8SjT/OTP70sz+aWZ9artsNH+kmf3bzNab2e/M7A0zG5ck7lRivMzMlpjZ52Z2e9xrm5vZLWZWZmYfAiOq2T/XmdmjVabdYWaTo8eXmNnC6P18GJWqk61ruZkdHz1ua2YPR7HNB4Yk2O7SaL3zzezMaPpA4PfAMVGV17q4fXtD3Ou/E733MjP7s5l1S2XfJIj5JjN7NPp+bDSzuWbWL4pvrZl9bGYnxy0/3sxKo7iXmtmYuHmXmNkH0TafM7OeybYrDczddcuhG1AKnFxl2k3AV8AZhAP6HsBQ4AjCv7e+wL+B70XLtwAc6B09nwKsA4qBlsCfgCl1WHYf4EvgrGjelcB2YFyS95JKjE8BewG9gc9i7x34HjAf6AF0Av4Rvu4Jt9MX2Ai0i1v3p0Bx9PyMaBkDTgS2AIOieScDpXHrWg4cHz3+LfB3YG+gF7CgyrLnA92iz+SbUQz7RvMuAf5eJc4pwA3R41OiGAuBNsCdwCup7JsE7/+m6D2dHL32EeAj4Oro+URgcbRse2A9cED0vBtwaPR4FLAIOCh63Q3Aa5n+TeTrTSX3/PG6u//F3SvcfYu7v+Pub7l7ubsvBe4Bjqvm9Y+7+0x33w5MJSSV2i57OjDH3Z+K5t1COBAklGKMv3D39e5eSkiksW2dD9zi7svdvQz4ZTXbWQq8TzjoAHwd+MLdZ0bz/+LuSz14BXgZSNhoWsX5wE3u/rm7LyOUxuO3+5i7r4o+k0cIB+biFNYLUALc5+5z3H0rIREfZ2Y94pZJtm8S+bu7v+Shum460BH4dfT8UeBrZhar/nNggJm1ieJfEE2/DPi5uy+KXncTcLiZdU/xPUkaKbnnj0/in5jZwWb2VzNbbWYbgBuBztW8fnXc481U34iabNn94uNwdyeUdBNKMcaUtgUsqyZeCKXVsdHjbxIOSrE4Tjezt8zsMzP7glBqrm5fxXSrLgYzGxdVgXwRrffgFNcL4f3tXJ+7bwA+B+ITaW0+szVxj7cAa929Iu45QEG0nbHAd4HVZvaMmR0Yze8F3BH3ftYBFYR/T9LIlNzzR9VugH8glFa/5u7tgesJ1Q4NaRVxP3QzM3ZNRlXVJ8ZVQHx9b01dNf8EnByVfM8iJHvMbA/gceAXhCqTDsDfUoxjdbIYzKwvcBehyqNTtN4P4tZbU7fNlYRkGlvfnoTqnxUpxFUv7v6cu59MOHgtIXxOEA5k4929Q9xtD3d/q6Fjkt0pueevPQl1p5vM7BDCX+qG9gxQZGZnmFkL4AdAlwaK8THgh2bW3cw6AT+ubmF3XwO8DjwILHL3xdGs1kArYC2ww8xOB06qRQzXmlkHC+cBfC9uXgEhga8lHOcuIZTcY9YAPWINyAlMA8ab2SAza004+Lzm7kn/CaWDmXWLPr+2hHacTVR2u70bmBR9VkTve1RDxiPJKbnnrx8BFxIaOP9AKLk2qCiBjgYmA2VAP+BdQr/8dMd4F6Fu/D3gHULpuyaPEBoVH4mL+QvgP4EnCY2SowgHqVT8lPAPohR4Dngobr3zgNuBt6NlDgbiS7gvAouBNWYWX70Se/3zhGqqJ6PX70+oh29ozYH/irZZBhxFdNBy9+mEz3Z6VI02Dzi1EWKSBCxUe4o0PjNrTqheGOXur2U6HpFcopK7NCozG2Fme0VVCT8BygmlVxFJoxqTu5n1NLMZ0Ukc883sBwmWOd7CSSlzotv1DROu5IDhwFJCT4oRwNnunqxaRkTqqMZqmeist27uPjtqkZ9F+EEuiFvmeOAqdz+9IYMVEZHU1Fhyj05SmB09/hJYSPXd10REJMNqNXCYhfFDDmPXVv2YYWY2l9BAdpW7z0/w+gnABIB27doNOfjgg6suIiIi1Zg1a9Y6d6+uCzFQi94y0anHrwI3u/v/VZnXHqhw941mdhpwm7sfUN36iouLfebMmSltW0REAjOb5e41DlORUm+Z6ESKJ4CpVRM7hFOf3X1j9PhZoKWZpXoatYiIpFkqvWUMuB9Y6O6TkyzTNVoOMzs8Wm9ZOgMVEZHUpVLnfjTwLeA9M5sTTbuWaJwMd7+bcNbeRDMrJwwyNMZ1dpSISMbUmNzd/XVqGCTJ3X9PleFMRaTp2L59O8uXL2fr1q2ZDkVS1KZNG3r06EHLlsmGF6qeLrMnkgeWL1/OnnvuSe/evYlqUKUJc3fKyspYvnw5ffr0qfkFCWTV8ANTp0Lv3tCsWbifWqvLPovkr61bt9KpUycl9ixhZnTq1Kle/7SypuQ+dSpMmACbN4fny5aF5wAljTEWnkiWU2LPLvX9vLKm5D5pUmVij9m8OUwXEZFdZU1y//jj2k0XkaahrKyMwsJCCgsL6dq1K927d9/5/KuvvkppHRdddBGLFi2qdpk77riDqaqr3SlrqmX23z9UxSSaLiLpNXVq+Ff88cfhN3bzzXWv/uzUqRNz5oRe1DfccAMFBQVcddVVuyzj7rg7zZolLm8++OCDNW7nu9/9bt0CzFFZU3K/+WZo23bXaW3bhukikj6x9q1ly8C9sn0r3YXiJUuWMGDAAL7zne9QVFTEqlWrmDBhAsXFxfTv358bb7xx57LDhw9nzpw5lJeX06FDB66++moGDx7MsGHD+PTTTwG47rrruPXWW3cuf/XVV3P44Ydz0EEH8eabbwKwadMmzj33XAYPHszYsWMpLi7eeeCJ16NHDyZNmsSRRx7J0KFDmT17Nqeccgr9+vXj3nvvBWDFihUMHz6cwsJCBgwYsHMbzz33HMOGDaOoqIjRo0ezadOm9O64FGVNci8pgXvugV69wCzc33OPGlNF0q0x27cWLFjA+PHjeffdd+nevTu//OUvmTlzJnPnzuXFF19kwYIFu71m/fr1HHfcccydO5dhw4bxwAMPJFy3u/P222/zm9/8ZueB4ne/+x1du3Zl7ty5XH311bz77rtJY+vduzf/+te/OPLIIxk/fjxPPvkkb775Jj/5yU8AmDJlCmeccQZz5sxh7ty5DBo0iE8//ZRf/vKXvPzyy8yePZtBgwZx2223pWFP1V7WVMtASORK5iINqzHbt/r168fQoUN3Pp82bRr3338/5eXlrFy5kgULFnDooYfu8po99tiDkSNHAjBkyBBeey3xFRrPOeecncuUlpYC8Prrr/PjH4drpQ8ePJj+/fsnje3MM88EYODAgZSXl9OuXTvatWtHs2bN2LhxI0OHDuWyyy5j69atnH322QwePJiXXnqJBQsWcNRRRwHw1VdfMXz48DrsmfrLquQuIg2vMdu32rVrt/Px4sWLue2223j77bfp0KEDF1xwQcJ+3q1atdr5uHnz5pSXlydcd+vWrXdbpjajosRe36xZs52PY8/Ly8s58cQT+fvf/85f//pXSkpKuOaaa2jbti0jRozg4YcfTnk7DSVrqmVEpHFkqn1rw4YN7LnnnrRv355Vq1bxwgsvpH0bw4cP57HHHgPgvffeS1jtk6ply5bRtWtXJkyYwLhx43j33Xc56qijePXVV1m6dCkQ6vgXL16clthrSyV3EdlFrOozXb1lUlVUVMShhx7KgAED6Nu3L0cffXTat3HFFVfw7W9/m0GDBlFUVMSAAQPYa6+96rSul19+mcmTJ9OyZUsKCgqYMmUK++67L/fffz+jR4/e2c3z5z//OQccUO3lLRpEyhfrSDddrEOk8SxcuJBDDjkk02FkXHl5OeXl5bRp04bFixdzyimnsHjxYlq0aJrl3ESfW6oX62ia70hEpAFs3LiRk046ifLyctydP/zhD002sddXbr4rEZEEOnTowKxZszIdRqNQg6qISA5SchcRyUFK7iIiOUjJXUQkBym5i0iDO/7443c7KenWW2/l8ssvr/Z1BQUFAKxcuZJRo0YlXXdN3apvvfVWNscNmHPaaafxxRdfpBJ61lJyF5EGN3bsWB599NFdpj366KOMHTs2pdfvt99+PP7443XeftXk/uyzz9KhQ4c6ry8bKLmLSIMbNWoUzzzzDNu2bQOgtLSUlStXMnz48J19z4uKihg4cCBPPfXUbq8vLS1lwIABAGzZsoUxY8YwaNAgRo8ezZYtW3YuN3HixJ1DBv/0pz8F4Pbbb2flypWccMIJnHDCCUAY8XHdunUATJ48mQEDBjBgwICdQwaXlpZyyCGHcOmll9K/f39OOeWUXbYTM27cOCZOnMgJJ5xA3759efXVV7n44os55JBDGDduHAA7duxg3LhxDBgwgIEDB3LLLbcA8OGHHzJixAiGDBnCMcccwwcffJCOXb2T+rmL5Jkf/hASDGFeL4WFEOXFhDp16sThhx/O888/z1lnncWjjz7K6NGjMTPatGnDk08+Sfv27Vm3bh1HHnkkZ555ZtJriN511120bduWefPmMW/ePIqKinbOu/nmm+nYsSM7duzgpJNOYt68eXz/+99n8uTJzJgxg86dO++yrlmzZvHggw/y1ltv4e4cccQRHHfccey9994sXryYadOmce+993L++efzxBNPcMEFF+wWz+eff84rr7zC008/zRlnnMEbb7zBfffdx9ChQ5kzZw47duxgxYoVvP/++wA7q4MmTJjA3XffzQEHHMBbb73F5ZdfziuvvFLbXZ+USu4i0ijiq2biq2TcnWuvvZZBgwZx8skns2LFCtasWZN0Pf/4xz92JtlBgwYxaNCgnfMee+wxioqKOOyww5g/f36NA4O9/vrr/Md//Aft2rWjoKCAc845Z+cQwn369KGwsBDYddjgqs444wzMjIEDB7LvvvsycOBAmjVrRv/+/SktLaVv374sXbqUK664gueff5727duzceNG3nzzTc477zwKCwu57LLLWLVqVWo7MkUquYvkmepK2A3p7LPP5sorr2T27Nls2bJlZ4l76tSprF27llmzZtGyZUt69+6dcKjfeIlK9R999BG//e1veeedd9h7770ZN25cjeupbmyt+GF+mzdvnrBaJn65ZEMD77333sydO5cXXniBO+64g8cee4xbb72VDh06JLwKVLqo5C4ijaKgoIDjjz+eiy++eJeG1PXr17PPPvvQsmVLZsyYwbJEg8nHOfbYY3deCPv9999n3rx5QBgyuF27duy1116sWbOG5557budr9txzT7788suE6/rzn//M5s2b2bRpE08++STHHHNMOt7uTuvWraOiooJzzz2X//7v/2b27Nm0b9+ePn36MH36dCAcZObOnZvW7arkLiKNZuzYsZxzzjm79JwpKSnhjDPOoLi4mMLCQg4++OBq1zFx4kQuuugiBg0aRGFhIYcffjgQrqx02GGH0b9//92GDJ4wYQIjR46kW7duzJgxY+f0oqIixo0bt3Mdl1xyCYcddljSKpi6WLFiBRdddBEVFRUA/OIXvwDCP5aJEydy0003sX37dsaMGcPgwYPTtl0N+SuSBzTkb3aqz5C/qpYREclBSu4iIjlIyV0kT2SqClbqpr6fl5K7SB5o06YNZWVlSvBZwt0pKyujTZs2dV6HesuI5IEePXqwfPly1q5dm+lQJEVt2rShR48edX69krtIHmjZsiV9+vTJdBjSiGqsljGznmY2w8wWmtl8M/tBgmXMzG43syVmNs/MihKtS0REGkcqJfdy4EfuPtvM9gRmmdmL7h4/aMNI4IDodgRwV3QvIiIZUGPJ3d1Xufvs6PGXwEKge5XFzgIe8uBfQAcz65b2aEVEJCW16i1jZr2Bw4C3qszqDnwS93w5ux8AMLMJZjbTzGaqYUdEpOGknNzNrAB4Avihu2+oOjvBS3brc+Xu97h7sbsXd+nSpXaRiohIylJK7mbWkpDYp7r7/yVYZDnQM+55D2Bl/cMTEZG6SKW3jAH3AwvdfXKSxZ4Gvh31mjkSWO/u6R15XkREUpZKb5mjgW8B75lZbGT5a4H9Adz9buBZ4DRgCbAZuCj9oYqISKpqTO7u/jqJ69Tjl3Hgu+kKSkRE6kdjy4iI5CAldxGRHKTkLiKSg5TcRURykJK7iEgOUnIXEclBSu4iIjlIyV1EJAcpuYuI5CAldxGRHKTkLiKSg7IuuX/5JcyeDdu2ZToSEZGmK+uS+zPPwJAh0KcPNGsGvXvD1KmZjkpEpGlJZcjfJmVBdFnuVdFo8cuWwYQJ4XFJSWZiEhFparKu5P7AA7tP27wZJk1q/FhERJqqrEvuK5NcvO/jjxs3DhGRpizrknuvXomn779/48YhItKUZV1yv/lmsCrXhWrbNkwXEZEg65J7SQkMGACtWoUk36sX3HOPGlNFROJlXW8ZgOJiKCuDFSsyHYmISNOUdSV3gO7dYfVqKC/PdCQiIk1T1ib3igpYsybTkYiINE1Zm9xB1TIiIskouYuI5KCsTO777Rfuk53QJCKS77Iyue+zD7RooZK7iEgyWZncmzWDbt2U3EVEksnK5A6h3l3JXUQksaxN7vvtpzp3EZFksja5x0ruU6eGC3bowh0iIpWycvgBCMl9wwa49FLYsiVM04U7RESCrC65Q2Vij9GFO0REsji5H3po8nm6cIeI5Lsak7uZPWBmn5rZ+0nmH29m681sTnS7Pv1h7u6ww6B588TzdOEOEcl3qZTc/xcYUcMyr7l7YXS7sf5h1cwMRo7cfbou3CEikkJyd/d/AJ81Qiy19tOfhvtOnXThDhGReOnqLTPMzOYCK4Gr3H1+ooXMbAIwAWD/NNSdDBkSuj8efDA891y9VycikjPS0aA6G+jl7oOB3wF/Tragu9/j7sXuXtylS5d6b9gMzj8fXnopXJlJRESCeid3d9/g7hujx88CLc2sc70jS9HZZ4crMs2Y0VhbFBFp+uqd3M2sq5lZ9PjwaJ2NVo4uKgoXy37rrcbaoohI01djnbuZTQOOBzqb2XLgp0BLAHe/GxgFTDSzcmALMMbdvcEirqJ169AtUsldRKRSjcnd3cfWMP/3wO/TFlEdHHEE3HdfqJ5pkbUDKoiIpE/WnqEa74gjwrAD+++vAcRERCCLBw6Lt3p1uF+1KtxrADERyXc5UXK/7bbdp2kAMRHJZzmR3D/5JPF0DSAmIvkqJ5J7spNdNYCYiOSrnEjuN98cukTG0wBiIpLPciK5l5TAXXeFnjKgAcRERHKitwzARRfBwoUweTK88UbllZpERPJRTpTcYy67DCoqwglNIiL5LKeSe79+MGJEqJLZvj3T0YiIZE5OJXeAyy+HlSs1vruI5LecS+6nngoFBUruIpLfci65t2wJJ54If/tbpiMREcmcnEvuU6fC66/D0qWhx4wGEBORfJQzXSEhJPIJE8K4MhDq3jWAmIjko5wquU+aVJnYYzSAmIjko5xK7skGCtMAYiKSb3IquWsAMRGRIKeS+803hwHD4pnB1VdnJh4RkUzJqeReUhLOTu3VKyT1ffcN11R95BHYti3T0YmINJ6cSu4QEnxpaRhjZvVqeOgheO01+NnPMh2ZiEjjybnkXtWYMfCtb8H//E/o+y4ikg9yPrkD/OIX4czVq67KdCQiIo0jZ5P71KnQu3e4gMfRR8Npp8GTT8KMGZmOTESk4eXUGaoxVc9UXbYMPv0UOnSA3/wGTjghs/GJiDS0nCy5JzpTdcsWcA+jRS5enJm4REQaS04m92RnpK5fH+re77yzceMREWlsOZnck52R2qsXjBoFDzwAGzc2bkwiIo0pJ5N7ojNV27YN06+4AjZsCN0jX3stVNWIiOSanEzuVc9U7dUrPC8pgSOPDMMRvPQSHHss7L23Lu4hIrnHPENF1+LiYp85c2ZGtg2waVPoGvnGG/D887B2Lbz1FvTvn7GQRERqZGaz3L24xuXyNbnHW7kSioqgfXt45x3Ya69MRyQikliqyT0nq2Vqa7/9YPp0+OgjOPBAGD8e/vGP5Ms//TT8+Mfw+9/DokWNF6eISKpyPrnHn6nau3fya6oec0yonjnxRHjiCTjuODjlFJg3r3KZDRvgwgvhrLPgt78NjbNHHrl7n3oRkUyrMbmb2QNm9qmZvZ9kvpnZ7Wa2xMzmmVlR+sOsm9iZqsuWhV4xy5aF58kS/EknwbRpsGpVGGhs9mwYNiyc+DRvXqi6mToVrr8+nBT13HPwxRfw+OON+75ERGpSY527mR0LbAQecvcBCeafBlwBnAYcAdzm7kfUtOHGqHPv3Tsk9Kp69QrDAtdk9eowJs28edCqVRi+YPr0MFYNhAPGQQdB167VV+OIiKRLqnXuNY4t4+7/MLPe1SxyFiHxO/AvM+tgZt3cfVXK0TaQ+l5TtWtX+Pvf4YILQkn94YfDtBgzuPhiuOYa+Pe/Q/J/9dVwgZD994chQ+r9FkRE6iQdde7dgU/ini+Ppu3GzCaY2Uwzm7l27do0bLp66bimavv2oQH1xRd3TewxF14IzZvDZZeFUvz558M550BxMXz3u5Vj2mzfXrf3ICJSF+lI7pZgWsK6Hne/x92L3b24S5cuadh09ao7UzVdunWDb3wjlPAHD4bXX4d334Urrwxj2PTsCQUFsOeeoQF2+fLKZP/++/DUU/DPf4bumBUVqW/388/hq6/S9z5EJLekY8jf5UDPuOc9gJVpWG+9lZSE+0mTQlXM/vuHxB6bni533hkaak87LVTVABQWht42Dz8cruX62Wdw992h+ySE3jtVk3mrVuFgsP/+oV2gc+dwBm2rVtCmDYweDV26hHaEwYND9c+3vhUOJD17IpI35s4NbWo6JyW5lE5iiurcn0nSoPoN4HtUNqje7u6H17TOxj6JaerUhk/yNVm6NDTIbtoUSu8HHwwHHADr1oWEHX/7+GMoK4OtWytfP2hQqNM/91x4+2049dRQZdSlS6g2OvTQsNyOHeFs227doE+fXWMoLw8HlmZ1/M+2YwfMnw8DB1YeyPLRyy+H/d2tW6YjyQ+bN4dCTvPm8POfw3XXwdChoSNDmzZ1W6d7+Je9enXoKde6de3X8dVX4Tfavn3dYqiLVBtUcfdqb8A0YBWwnVBKHw98B/hONN+AO4APgfeA4prW6e4MGTLEG8uUKe5t27qHjzPc2rYN05u6LVvcN2xw/+tf3Vu0cO/ZM8R/zz1h/nvvuXft6t6pk/uVV7qPGuXeuXNYplUr91/9yv3f/3a/8073s892b98+LP/II+4VFWEd5eXuL74Ypm3bljyWigr3Sy4J6/7RjypfX5OlS923b6/ffmhKXn017IOjjkp9H+SiP/7R/b/+K3x/6ir+e7FypftvfuP+z39WTquocP/d79xbt3YvKHAfODDs++OPD/cXXug+d677ZZe5T5rkvnp15WvXr3c/80z3k092X7YsTCsvD+u/7jr3gw6qzAcdO4b3snlzWG72bPcbbnBfvnz3mLdtc//1r9332y+8tnlz93vvDfN27HB/8kn3qVPdn3rK/eWXw/b+9jf3adPcn3nG/d133T//vO77DJjpKeTYGhdoqFtjJvdevXZN7LFbr16NFkJaPPRQiHvEiF2TypIl4Yvapo37gQe6f/Ob4Yt0zjm7v99LL3UvLg7PDzjA/eij3bt3r1ymb1/3++8PP4aqievmm8MyhYWVP6xf/cr92mvdS0vDMu++Gw4i11/vPnOme0lJWPbUU92//LJyXRUV7p984v7ZZ+H5/Pnh4HTjje4rVtRt/1RUuG/dWrfXpmrz5rDfYoWFRx4J0z/6KCSE9esrl92+3f2VV9zfeCPEtnZt+GyOPdb9tddS296aNeHAvmlT8mW++iokjSuvDNur7oBTXu4+fbr7s89WJjL3sP7p00MySvb6zZtD8iwvd//JTyq/M5dfHl6zaZP7Bx+E+Z9/HgoAX/taSMSXXBK+K088EZLxnDnu553nbuZ+xBHuV1wRkndsncXF7mPHuh9zTHg+cmTYzhFHhMRaURGSb2z5PfYI62rTxv2CC8LnUlgYCkQFBe4dOriPGVNZ8GnePMR1zz1h/55/fpg+cGBYb8uW4Xnr1u6jR7sPH+7eo4f74MGV+eTUU8OyJ5wQ1jd9uvvppyfONVVvP/pRap9/Iqkm97wYW6ZZs8RD+5rVrhGzKZg5M1TnFBTsOj32/uKrStzhL3+BTz6Br389VAGZhaqVe+8NJ2F9+WXowjlmTGhsvvZaeO+98Pp99w2v6dQpVCm99x5885uhHeGaa+DXv67cZrt2cNFFYb2tW4ezed3DX+lRo+DRR0PX0JEjQ0Pyv/4VGpEhVCutXRuW/eqr8Ne7R48QW/v2MCCqDJw7N2xnwoRQJbVhQxiXv6IC5syB++4LQ0gce2w4F2Hr1rDM+vXhfsOG8F2YODFUbT3+eDgbefDg8Le8X79wMZcHH4QpU8I29947vJ+WLeFrXwt/4adNC6OI/vjHIe6LLgoXYS8vD6/p3Bn69g37bN26MG3w4PDazz6Djh1hzZrQRjN+fDhR7qOPwqUgW7QIMW7ZEqrW7rgjVEl06BD2Y0FB+PzKy8P7++ij8LmUlYXPwT2sr7AwNOLHGvN79gzruO66sO8hVGcceGDY/++8E/YPwCGHhE4C++4b1rl2LcyaFYbI3rYtfD71Nm7oAAAOv0lEQVQ7doT33bFjOOHvlFPCejdsCJ9Zs2Zhv48YEe4XLw7riVdQEL5P77wTqkfOOgt+9rPQKeF//ze8LvZ5ff/7u1cDVlSE99OuXVimrCycOT59euhw0K5d+Hz79YNvfzt0Vx4xIry3U08Nscd7/vnQhrVuXYjl+utDG9lf/xp+B337hvVu3RrauUaODK/bsCGc4T5vXvj8Jk8O+2PjxnDbtCl8Bh07hmVXrgzrOuywan/qSWngsDj1PZkpn1RUhB/aP/8ZztD98MPwo+nbN5yhe801lXWTK1aEL+1nn8Ell4R66BNPDMlv8+Zw8Dj55PDDePrpcADZti2sa+jQkIS2boWFC0M30vHjww/6vvvCD2DPPcO2YwebwYPD5/Xmm4ljP/rosN6//Q0WLAjJq3370OjWvn24rVwZxgNq2zbEuM8+IelU/RkMGxYOarFeSdu2hQS1ZUt4r/feG5LdsceG5UtKQkL46KOwz5YuDUnz3HPDOu66K8Rz110h2dxyS0jcq1cn/yzMQvIbNQr+9Cd49tkwvXnzcGvdOny3DzwQzj47XBv4oYfCNtasCQfHbdt2XWenTiH57LsvvPBCiHX16rD/L7ww9Oa6885wII29tmXL8Bmeemr47FasCG05l14a9tuFF4Yket55MHx4+N588UU4+BUWVm57/fqwvcWLw3fmvPPCgRBCAmzXrrpvZuq2bw8Hmp49w/6Jca+5nWjlyhD/N75RuzalTz6Bq66Cyy8PQ5c0JCX3OFUvmA3hxx0b413qzz2U7goLQ+klkY0bw7y6NoDFzJ0bSv8dO4bSX/PmIVn161e5THl54jgqKuCxx8LB5rzzQkL+7LMw9PPy5eHx6acnLlWVl4ek3adPSHgQkny3buE1tVVeHg6IixaFfwXduoVpFRWwxx7h4FDfBtvt20Np8eOPw+2oo8J6a+JeWZJv3776ROdR195WreoXq6RGyb2KptBbRkSkvtI2/ECuKClRMheR/JHzQ/6KiOSjvEvuqY7vLiKSzfKmWgZ2b1iNje8OqrIRkdySVyX3SZN2v2rS5s1huohILsmr5F7f8d1FRLJFXiX3dIzvLiKSDfIquTfG+O4iIk1BXiX3kpJwVmqvXuGMu169dJaqiOSmvEruEBJ5aWkY/ArCQEHqEikiuSavukLGqEukiOS6vCu5g7pEikjuy8vkri6RIpLr8jK5q0ukiOS6vEzu6hIpIrkuL5O7ukSKSK7Ly+QO6hIpIrktL7tCxqhLpIjkqrwtuYO6RIpI7srr5K4ukSKSq/I6uatLpIjkqrxO7om6RAJs3KiGVRHJbnmd3GNdIjt12nV6WVloWFWCF5FsldfJHUKCLyjYfboaVkUkm+V9cgc1rIpI7lFyJ3kDarNmqpoRkeyk5E7yhtUdO1T3LiLZScmdyobV5s13n6e6dxHJRkrukZISqKhIPE917yKSbVJK7mY2wswWmdkSM7s6wfxxZrbWzOZEt0vSH2rD00lNIpIrakzuZtYcuAMYCRwKjDWzQxMs+id3L4xu96U5zkahk5pEJFekUnI/HFji7kvd/SvgUeCshg0rM3RSk4jkilSSe3fgk7jny6NpVZ1rZvPM7HEz65mW6DJAJzWJSC5IJblbgmle5flfgN7uPgh4CfhjwhWZTTCzmWY2c+3atbWLtBEla0BdtkyldxHJDqkk9+VAfEm8B7AyfgF3L3P3bdHTe4EhiVbk7ve4e7G7F3fp0qUu8TaK6hpQVT0jItkgleT+DnCAmfUxs1bAGODp+AXMrFvc0zOBhekLsfEla1gFVc+ISHaoMbm7eznwPeAFQtJ+zN3nm9mNZnZmtNj3zWy+mc0Fvg+Ma6iAG0OsYTUZVc+ISFNn7lWrzxtHcXGxz5w5MyPbTlXv3iGRJ9K2bTgA6FqrItKYzGyWuxfXtJzOUK2GqmdEJFspuVdD1TMikq2U3GtQUgK9eiWfr94zItIUKbmnoKbqmQsvVIIXkaZFyT0FNVXP7NgBF1wAnTsryYtI06DknqKaqmdAY9CISNOh5F4L1VXPxKgXjYg0BUrutVDdFZviqReNiGSaknstlZTAH/9YcwledfAikklK7nWQbNz3qsrKlORFJDOU3OuopATWrYMpU2peVkleRBqbkns9pdKLJkZJXkQai5J7GqTSiyaeukyKSENTck+DVOvg423eHErxZmH0SSV6EUknJfc0ia+Dr02Sh9B18lvfUqIXkfRRck+zuib52LD6y5apXl5E6k/JvYHUpyQPlY2vzZurRC8itafk3sDik3xNZ7YmUlER7mMleiV7EUmFknsjSfXM1poo2YtIKpTcG1GsV02sX3ysJG9W93UmS/YtWux6r+Qvkl+U3BtZSQmUloYG1PLycP/ww3Wrl08klux37Nj1PlnyV9IXyU1K7k1AfRtfa6Nq8lfSF8lNSu5NSHySj1Xd1KfKpjZSTfpK/iLZQcm9CYqvuqmoyEyyj6mpmqegIPTJT3QASHavA4NIw1NyzwJNKdlXtWlT6JMPux8Akt3X9K8g0cHg8svDfbNmOjiIpELJPQtVl+xjPXDS0ROnoSX7V5DoYHDXXeHevfYHBx0sJB8pueeARD1wYvfJkn9TTvqpSvXgkMrBIja2T20PFKqCkqZKyT0PJEr+uZz06yI2tk9tDxTproKq7X3nzrVv89A/mPyg5J7HapP08z3511dd/2XUdF9WVvs2j4aq7mrMA1N9DmA1Pc+VA5x5rMjSyIqLi33mzJkZ2bbUz9SpMGkSfPwxdOwYppWVhaSwY0fye7PKErJIU9asWTgg1/Sdjp2Xksr3v+p9r17hQj8lJbWLzcxmuXtxje+hLm9c8lusxF9REfrlr1uXuL4/1fr/ZPf6lyCZkuo/rfr+c2rIK7IpuUujqq7xt7qDgVm4nzgx9YODDhbS1G3eHP4FNwQld2nS4v8llJbCnXemfnBI5WAxZUrt/k3oQCLp9vHHDbNe1bmLNJBY28SyZbWvj031vi51vmr7aFp69QoFllSltc7dzEaY2SIzW2JmVyeY39rM/hTNf8vMeqceqkhuqk0VVF3va9Pm0VDVXXW979Sp8uCU7nVnyz+ntm1Do2pDqDG5m1lz4A5gJHAoMNbMDq2y2Hjgc3f/GnAL8Kt0Byoi6ZPO6q7GPDCl4wBW03NonANUr17h+g617S2TqhYpLHM4sMTdlwKY2aPAWcCCuGXOAm6IHj8O/N7MzDNV5yMiea+kpOESZzZIpVqmO/BJ3PPl0bSEy7h7ObAe2G1kcjObYGYzzWzm2rVr6xaxiIjUKJXknqj2qmqJPJVlcPd73L3Y3Yu7dOmSSnwiIlIHqST35UDPuOc9gJXJljGzFsBewGfpCFBERGovleT+DnCAmfUxs1bAGODpKss8DVwYPR4FvKL6dhGRzKmxQdXdy83se8ALQHPgAXefb2Y3AjPd/WngfuBhM1tCKLGPacigRUSkehk7icnM1gLL6vjyzsC6NIbTEBRjeijG9FCM9ddU4uvl7jU2WmYsudeHmc1M5QytTFKM6aEY00Mx1l9Tj68qjS0jIpKDlNxFRHJQtib3ezIdQAoUY3ooxvRQjPXX1OPbRVbWuYuISPWyteQuIiLVUHIXEclBWZfcaxpbPhPMrKeZzTCzhWY238x+EE3vaGYvmtni6H7vDMfZ3MzeNbNnoud9ovH3F0fj8bfKcHwdzOxxM/sg2pfDmuA+/M/oM37fzKaZWZtM70cze8DMPjWz9+OmJdxvFtwe/X7mmVlRBmP8TfRZzzOzJ82sQ9y8a6IYF5nZqZmKMW7eVWbmZtY5ep6R/VgbWZXcUxxbPhPKgR+5+yHAkcB3o7iuBl529wOAl6PnmfQDYGHc818Bt0TxfU4Ylz+TbgOed/eDgcGEWJvMPjSz7sD3gWJ3H0A4Y3sMmd+P/wuMqDIt2X4bCRwQ3SYAd2UwxheBAe4+CPg3cA1A9NsZA/SPXnNn9NvPRIyYWU/g60D8BfEytR9T5+5ZcwOGAS/EPb8GuCbTcSWI8ynCl2ER0C2a1g1YlMGYehB+5CcCzxBG8lwHtEi0bzMQX3vgI6JG/rjpTWkfxoa27kgYuuMZ4NSmsB+B3sD7Ne034A/A2ETLNXaMVeb9BzA1erzL75ow9MmwTMVIuEbFYKAU6Jzp/ZjqLatK7qQ2tnxGRZcYPAx4C9jX3VcBRPf7ZC4ybgX+H1ARPe8EfOFh/H3I/L7sC6wFHoyqju4zs3Y0oX3o7iuA3xJKcKsI1y2YRdPajzHJ9ltT/Q1dDDwXPW4yMZrZmcAKd59bZVaTiTGZbEvuKY0bnylmVgA8AfzQ3TdkOp4YMzsd+NTdZ8VPTrBoJvdlC6AIuMvdDwM2kflqrF1E9dZnAX2A/YB2hL/nVTWZ72QCTe1zx8wmEao2p8YmJVis0WM0s7bAJOD6RLMTTGtSn3u2JfdUxpbPCDNrSUjsU939/6LJa8ysWzS/G/BphsI7GjjTzEqBRwlVM7cCHaLx9yHz+3I5sNzd34qeP05I9k1lHwKcDHzk7mvdfTvwf8BRNK39GJNsvzWp35CZXQicDpR4VL9B04mxH+FAPjf67fQAZptZV5pOjEllW3JPZWz5RmdmRhj2eKG7T46bFT/O/YWEuvhG5+7XuHsPd+9N2GevuHsJMIMw/n5G4wNw99XAJ2Z2UDTpJMJ1epvEPox8DBxpZm2jzzwWY5PZj3GS7bengW9HvT2OBNbHqm8am5mNAH4MnOnum+NmPQ2MMbPWZtaH0Gj5dmPH5+7vufs+7t47+u0sB4qi72qT2Y9JZbrSvw4NHqcRWtY/BCZlOp4opuGEv2TzgDnR7TRCvfbLwOLovmMTiPV44JnocV/Cj2YJMB1oneHYCoGZ0X78M7B3U9uHwM+AD4D3gYeB1pnej8A0QhvAdkICGp9svxGqE+6Ifj/vEXr+ZCrGJYR669hv5u645SdFMS4CRmYqxirzS6lsUM3IfqzNTcMPiIjkoGyrlhERkRQouYuI5CAldxGRHKTkLiKSg5TcRURykJK7iEgOUnIXEclB/x+0mojWwWfU7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2467f5b3828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VPW9//HXh10IiCwKArKoVQFZYqpYUHCpgnstKhgUrYpLd+v9iWKteq/31uWqxa1Vq60SoS61WutSrdyitkXZEZGiAhJZDFH2RUI+vz++J2QIk2SSTDKZmffz8ZjHzJxz5pzPnJn5nO98v9/zPebuiIhIZmmS6gBERCT5lNxFRDKQkruISAZSchcRyUBK7iIiGUjJXUQkAym5S1xm1tTMNpvZQclcNpXM7BAzS3rfXzM72cyWxzxfYmbHJbJsLbb1mJndWNvXV7He/zKz3yV7vZI6zVIdgCSHmW2Oedoa2AHsip5f6e4FNVmfu+8CcpK9bDZw98OSsR4zuxwY5+4jYtZ9eTLWLZlPyT1DuPvu5BqVDC939zcrW97Mmrl7SUPEJiINT9UyWSL62/0HM5tqZpuAcWZ2rJn9y8zWm9lqM5tsZs2j5ZuZmZtZr+j5lGj+q2a2ycz+aWa9a7psNH+Umf3bzDaY2f1m9q6ZXVJJ3InEeKWZfWxmX5nZ5JjXNjWze82s2Mw+AUZWsX9uMrNpFaY9aGb3RI8vN7PF0fv5JCpVV7auQjMbET1ubWZPRbEtAo6Ks91Po/UuMrOzoulHAg8Ax0VVXuti9u0tMa+/KnrvxWb2JzPrmsi+qY6ZnRPFs97M3jKzw2Lm3Whmq8xso5l9FPNeh5jZnGj6WjO7K9HtST1wd90y7AYsB06uMO2/gK+BMwkH9X2AbwLHEP7B9QH+DfwgWr4Z4ECv6PkUYB2QBzQH/gBMqcWy+wObgLOjedcCO4FLKnkvicT4IrAv0Av4suy9Az8AFgHdgY7AjPCVj7udPsBmoE3Mur8A8qLnZ0bLGHAisA0YEM07GVges65CYET0+G7g/4D9gJ7AhxWWPR/oGn0mF0YxHBDNuxz4vwpxTgFuiR6fEsU4CGgFPAS8lci+ifP+/wv4XfT4iCiOE6PP6MZovzcH+gErgC7Rsr2BPtHj94Gx0eO2wDGp/i1k800l9+zyjrv/2d1L3X2bu7/v7jPdvcTdPwUeAYZX8frn3H2Wu+8ECghJpabLngHMc/cXo3n3Eg4EcSUY4/+4+wZ3X05IpGXbOh+4190L3b0Y+GUV2/kU+IBw0AH4NrDe3WdF8//s7p968BbwNyBuo2kF5wP/5e5fufsKQmk8drvPuPvq6DN5mnBgzktgvQD5wGPuPs/dtwMTgeFm1j1mmcr2TVXGAC+5+1vRZ/RLoB3hIFtCOJD0i6r2lkX7DsJB+lAz6+jum9x9ZoLvQ+qBknt2WRn7xMwON7O/mNkaM9sI3AZ0quL1a2Ieb6XqRtTKlj0wNg53d0JJN64EY0xoW4QSZ1WeBsZGjy8kHJTK4jjDzGaa2Zdmtp5Qaq5qX5XpWlUMZnaJmc2Pqj/WA4cnuF4I72/3+tx9I/AV0C1mmZp8ZpWtt5TwGXVz9yXAzwifwxdRNV+XaNFLgb7AEjN7z8xOS/B9SD1Qcs8uFbsB/oZQWj3E3dsBNxOqHerTakI1CQBmZuyZjCqqS4yrgR4xz6vrqvkH4OSo5Hs2IdljZvsAzwH/Q6gyaQ/8NcE41lQWg5n1AR4GrgY6Ruv9KGa91XXbXEWo6ilbX1tC9c/nCcRVk/U2IXxmnwO4+xR3H0qokmlK2C+4+xJ3H0Ooevtf4Hkza1XHWKSWlNyzW1tgA7DFzI4ArmyAbb4M5JrZmWbWDPgx0LmeYnwG+ImZdTOzjsD1VS3s7muBd4AngCXuvjSa1RJoARQBu8zsDOCkGsRwo5m1t3AewA9i5uUQEngR4Th3OaHkXmYt0L2sATmOqcBlZjbAzFoSkuzb7l7pP6EaxHyWmY2Itv0fhHaSmWZ2hJmdEG1vW3TbRXgDF5lZp6ikvyF6b6V1jEVqSck9u/0MGE/44f6GUHKtV1ECvQC4BygGDgbmEvrlJzvGhwl14wsJjX3PJfCapwkNpE/HxLwe+CnwAqFRcjThIJWIXxD+QSwHXgWejFnvAmAy8F60zOFAbD31G8BSYK2ZxVavlL3+NUL1yAvR6w8i1MPXibsvIuzzhwkHnpHAWVH9e0vgTkI7yRrCP4WbopeeBiy20BvrbuACd/+6rvFI7Vio8hRJDTNrSqgGGO3ub6c6HpFMoZK7NDgzG2lm+0Z/7X9O6IHxXorDEsko1SZ3M+thZtOjEzgWmdmP4ywzwsIJKfOi2831E65kiGHAp4S/9iOBc9y9smoZEamFaqtlojPeurr7nKg1fjbhx/hhzDIjgOvc/Yz6DFZERBJTbck9OsFiTvR4E7CYqruuiYhIitVo4DALY4cMZs8W/TLHmtl8QuPYdVGLe8XXTwAmALRp0+aoww8/vOIiIiJShdmzZ69z96q6DwM16C1jZjnA34Hb3f2PFea1A0rdfXN0Vtqv3P3QqtaXl5fns2bNSmjbIiISmNlsd692iIqEestEJzI8DxRUTOwQTnt2983R41eA5maW6CnUIiKSZIn0ljHgt8Bid7+nkmW6RMthZkdH6y1OZqAiIpK4ROrchwIXAQvNbF407UaiMTLc/deEM/auNrMSwunIY1xnR4mIpEy1yd3d36GaAZLc/QEqDGUqIo3Lzp07KSwsZPv27akORRLQqlUrunfvTvPmlQ0tVDVdZk8kSxQWFtK2bVt69epFVIsqjZS7U1xcTGFhIb17967+BXGk1fADBQXQqxc0aRLuC2p0yWeR7LZ9+3Y6duyoxJ4GzIyOHTvW6V9W2pTcCwpgwgTYujU8X7EiPAfIr/M4eCLZQYk9fdT1s0qbkvukSeWJvczWrWG6iIjsKW2S+2ef1Wy6iDQuxcXFDBo0iEGDBtGlSxe6deu2+/nXXyc27Pull17KkiVLqlzmwQcfpCBJdbbDhg1j3rx51S/YCKVNtcxBB4WqmHjTRST5CgrCP+PPPgu/s9tvr1sVaMeOHXcnyltuuYWcnByuu+66PZZxd9ydJk3ilzufeOKJarfz/e9/v/ZBZpC0Kbnffju0br3ntNatw3QRSa6yNq4VK8C9vI2rPjoxfPzxx/Tv35+rrrqK3NxcVq9ezYQJE8jLy6Nfv37cdtttu5ctK0mXlJTQvn17Jk6cyMCBAzn22GP54osvALjpppu47777di8/ceJEjj76aA477DD+8Y9/ALBlyxa++93vMnDgQMaOHUteXl61JfQpU6Zw5JFH0r9/f2688UYASkpKuOiii3ZPnzx5MgD33nsvffv2ZeDAgYwbNy7p+ywRaZPc8/PhkUegZ08wC/ePPKLGVJH60NBtXB9++CGXXXYZc+fOpVu3bvzyl79k1qxZzJ8/nzfeeIMPP/xwr9ds2LCB4cOHM3/+fI499lgef/zxuOt2d9577z3uuuuu3QeK+++/ny5dujB//nwmTpzI3Llzq4yvsLCQm266ienTpzN37lzeffddXn75ZWbPns26detYuHAhH3zwARdffDEAd955J/PmzWP+/Pk88EBqTgFKm+QOIZEvXw6lpeFeiV2kfjR0G9fBBx/MN7/5zd3Pp06dSm5uLrm5uSxevDhuct9nn30YNWoUAEcddRTLly+Pu+5zzz13r2XeeecdxowZA8DAgQPp169flfHNnDmTE088kU6dOtG8eXMuvPBCZsyYwSGHHMKSJUv48Y9/zOuvv86+++4LQL9+/Rg3bhwFBQW1PgmprtIquYtIw6isLau+2rjatGmz+/HSpUv51a9+xVtvvcWCBQsYOXJk3P7eLVq02P24adOmlJSUxF13y5Yt91qmpqOjVLZ8x44dWbBgAcOGDWPy5MlceeWVALz++utcddVVvPfee+Tl5bFr164abS8ZlNxFZC+pbOPauHEjbdu2pV27dqxevZrXX3896dsYNmwYzzzzDAALFy6M+88g1pAhQ5g+fTrFxcWUlJQwbdo0hg8fTlFREe7Oeeedx6233sqcOXPYtWsXhYWFnHjiidx1110UFRWxtWIdVwNIm94yItJwyqo8k9lbJlG5ubn07duX/v3706dPH4YOHZr0bfzwhz/k4osvZsCAAeTm5tK/f//dVSrxdO/endtuu40RI0bg7px55pmcfvrpzJkzh8suuwx3x8y44447KCkp4cILL2TTpk2UlpZy/fXX07Zt26S/h+okfLGOZNPFOkQa1uLFizniiCNSHUajUFJSQklJCa1atWLp0qWccsopLF26lGbNGld5N95nlujFOhrXOxERaQCbN2/mpJNOoqSkBHfnN7/5TaNL7HWVWe9GRCQB7du3Z/bs2akOo16pQVVEJAMpuYuIZCAldxGRDKTkLiKSgZTcRaRBjBgxYq8Tku677z6uueaaKl+Xk5MDwKpVqxg9enSl666ua/V99923x8lEp512GuvXr08k9Crdcsst3H333XVeT7IpuYtIgxg7dizTpk3bY9q0adMYO3ZsQq8/8MADee6552q9/YrJ/ZVXXqF9+/a1Xl9jp+QuIg1i9OjRvPzyy+zYsQOA5cuXs2rVKoYNG7a733lubi5HHnkkL7744l6vX758Of379wdg27ZtjBkzhgEDBnDBBRewbdu23ctdffXVu4cL/sUvfgHA5MmTWbVqFSeccAInnHACAL169WLdunUA3HPPPfTv35/+/fvvHi54+fLlHHHEEVxxxRX069ePU045ZY/txDNv3jyGDBnCgAED+M53vsNXX321e/t9+/ZlwIABuwcs+/vf/777YiWDBw9m06ZNtd638aifu0gW+slPINkXGBo0CKK8GFfHjh05+uijee211zj77LOZNm0aF1xwAWZGq1ateOGFF2jXrh3r1q1jyJAhnHXWWZVeR/Thhx+mdevWLFiwgAULFpCbm7t73u23306HDh3YtWsXJ510EgsWLOBHP/oR99xzD9OnT6dTp057rGv27Nk88cQTzJw5E3fnmGOOYfjw4ey3334sXbqUqVOn8uijj3L++efz/PPPVzk++8UXX8z999/P8OHDufnmm7n11lu57777+OUvf8myZcto2bLl7qqgu+++mwcffJChQ4eyefNmWrVqVYO9XT2V3EWkwcRWzcRWybg7N954IwMGDODkk0/m888/Z+3atZWuZ8aMGbuT7IABAxgwYMDuec888wy5ubkMHjyYRYsWVTso2DvvvMN3vvMd2rRpQ05ODueeey5vv/02AL1792bQoEFA1cMKQxhffv369QwfPhyA8ePHM2PGjN0x5ufnM2XKlN1nwg4dOpRrr72WyZMns379+qSfIauSu0gWqqqEXZ/OOeccrr32WubMmcO2bdt2l7gLCgooKipi9uzZNG/enF69esUd5jdWvFL9smXLuPvuu3n//ffZb7/9uOSSS6pdT1Xja5UNFwxhyODqqmUq85e//IUZM2bw0ksv8Z//+Z8sWrSIiRMncvrpp/PKK68wZMgQ3nzzTQ4//PBarT8eldxFpMHk5OQwYsQIvve97+3RkLphwwb2339/mjdvzvTp01kR74LJMY4//vjdF8H+4IMPWLBgARCGC27Tpg377rsva9eu5dVXX939mrZt28at1z7++OP505/+xNatW9myZQsvvPACxx13XI3f27777st+++23u9T/1FNPMXz4cEpLS1m5ciUnnHACd955J+vXr2fz5s188sknHHnkkVx//fXk5eXx0Ucf1XibVVHJXUQa1NixYzn33HP36DmTn5/PmWeeSV5eHoMGDaq2BHv11Vdz6aWXMmDAAAYNGsTRRx8NhKsqDR48mH79+u01XPCECRMYNWoUXbt2Zfr06bun5+bmcskll+xex+WXX87gwYOrrIKpzO9//3uuuuoqtm7dSp8+fXjiiSfYtWsX48aNY8OGDbg7P/3pT2nfvj0///nPmT59Ok2bNqVv3767ryqVLBryVyRLaMjf9FOXIX9VLSMikoGU3EVEMpCSu0gWSVU1rNRcXT8rJXeRLNGqVSuKi4uV4NOAu1NcXFynE5vUW0YkS3Tv3p3CwkKKiopSHYokoFWrVnTv3r3Wr1dyF8kSzZs3p3fv3qkOQxpItdUyZtbDzKab2WIzW2RmP46zjJnZZDP72MwWmFluvHWJiEjDSKTkXgL8zN3nmFlbYLaZveHusQM2jAIOjW7HAA9H9yIikgLVltzdfbW7z4kebwIWA90qLHY28KQH/wLam1nXpEcrIiIJqVFvGTPrBQwGZlaY1Q1YGfO8kL0PAJjZBDObZWaz1KgjIlJ/Ek7uZpYDPA/8xN03Vpwd5yV79bdy90fcPc/d8zp37lyzSEVEJGEJJXcza05I7AXu/sc4ixQCPWKedwdW1T08ERGpjUR6yxjwW2Cxu99TyWIvARdHvWaGABvcfXUS4xQRkRpIpLfMUOAiYKGZlV2Y60bgIAB3/zXwCnAa8DGwFbg0+aGKiEiiqk3u7v4O8evUY5dx4PvJCkpEROpGY8uIiGQgJXcRkQyk5C4ikoGU3EVEMpCSu4hIBlJyFxHJQEruIiIZSMldRCQDKbmLiGQgJXcRkQyk5C4ikoHSLrlv2gRz5sCOHamORESk8Uq75P7yy3DUUdC7NzRpAr16QUFBqqMSEWlcEhnyt1H5MLos9+potPgVK2DChPA4Pz81MYmINDZpV3J//PG9p23dCpMmNXwsIiKNVdol91WVXLzvs88aNg4RkcYs7ZJ7z57xpx90UMPGISLSmKVdcr/9drAK14Vq3TpMFxGRIO2Se34+9O8PLVqEJN+zJzzyiBpTRURipV1vGYC8PCguhs8/T3UkIiKNU9qV3AG6dYM1a6CkJNWRiIg0Tmmb3EtLYe3aVEciItI4pW1yB1XLiIhURsldRCQDpWVyP/DAcF/ZCU0iItkuLZP7/vtDs2YquYuIVCYtk3uTJtC1q5K7iEhl0jK5Q6h3V3IXEYkvbZP7gQeqzl1EpDJpm9zLSu4FBeGCHbpwh4hIubQcfgBCct+4Ea64ArZtC9N04Q4RkSCtS+5QntjL6MIdIiJpnNz79q18ni7cISLZrtrkbmaPm9kXZvZBJfNHmNkGM5sX3W5Ofph7GzwYmjaNP08X7hCRbJdIyf13wMhqlnnb3QdFt9vqHlb1zGDUqL2n68IdIiIJJHd3nwF82QCx1NgvfhHuO3bUhTtERGIlq7fMsWY2H1gFXOfui+ItZGYTgAkAByWh7uSoo0L3x8MPh1dfrfPqREQyRjIaVOcAPd19IHA/8KfKFnT3R9w9z93zOnfuXOcNm8H558Obb4YrM4mISFDn5O7uG919c/T4FaC5mXWqc2QJOueccEWm6dMbaosiIo1fnZO7mXUxM4seHx2ts8HK0bm54WLZM2c21BZFRBq/auvczWwqMALoZGaFwC+A5gDu/mtgNHC1mZUA24Ax7u71FnEFLVuGbpFK7iIi5apN7u4+tpr5DwAPJC2iWjjmGHjssVA90yxtB1QQEUmetD1DNdYxx4RhBw46SAOIiYhAGg8cFmvNmnC/enW41wBiIpLtMqLk/qtf7T1NA4iJSDbLiOS+cmX86RpATESyVUYk98pOdtUAYiKSrTIiud9+e+gSGUsDiIlINsuI5J6fDw8/HHrKgAYQExHJiN4yAJdeCosXwz33wLvvll+pSUQkG2VEyb3MlVdCaWk4oUlEJJtlVHI/+GAYOTJUyezcmepoRERSJ6OSO8A118CqVRrfXUSyW8Yl91NPhZwcJXcRyW4Zl9ybN4cTT4S//jXVkYiIpE7GJfeCAnjnHfj009BjRgOIiUg2ypiukBAS+YQJYVwZCHXvGkBMRLJRRpXcJ00qT+xlNICYiGSjjErulQ0UpgHERCTbZFRy1wBiIiJBRiX3228PA4bFMoOJE1MTj4hIqmRUcs/PD2en9uwZkvoBB4Rrqj79NOzYkeroREQaTkYldwgJfvnyMMbMmjXw5JPw9ttw662pjkxEpOFkXHKvaMwYuOgi+N//DX3fRUSyQcYnd4D/+Z9w5up116U6EhGRhpGxyb2gAHr1ChfwGDoUTjsNXngBpk9PdWQiIvUvo85QLVPxTNUVK+CLL6B9e7jrLjjhhNTGJyJS3zKy5B7vTNVt28A9jBa5dGlq4hIRaSgZmdwrOyN1w4ZQ9/7QQw0bj4hIQ8vI5F7ZGak9e8Lo0fD447B5c8PGJCLSkDIyucc7U7V16zD9hz+EjRtD98i33w5VNSIimSYjk3vFM1V79gzP8/NhyJAwHMGbb8Lxx8N+++niHiKSecxTVHTNy8vzWbNmpWTbAFu2hK6R774Lr70GRUUwcyb065eykEREqmVms909r9rlsjW5x1q1CnJzoV07eP992HffVEckIhJfosk9I6tlaurAA+HZZ2HZMvjGN+Cyy2DGjMqXf+kluP56eOABWLKk4eIUEUlUxif32DNVe/Wq/Jqqxx0XqmdOPBGefx6GD4dTToEFC8qX2bgRxo+Hs8+Gu+8OjbNDhuzdp15EJNWqTe5m9riZfWFmH1Qy38xsspl9bGYLzCw3+WHWTtmZqitWhF4xK1aE55Ul+JNOgqlTYfXqMNDYnDlw7LHhxKcFC0LVTUEB3HxzOCnq1Vdh/Xp47rmGfV8iItWpts7dzI4HNgNPunv/OPNPA34InAYcA/zK3Y+pbsMNUefeq1dI6BX17BmGBa7OmjVhTJoFC6BFizB8wbPPhrFqIBwwDjsMunSpuhpHRCRZEq1zr3ZsGXefYWa9qljkbELid+BfZtbezLq6++qEo60ndb2mapcu8H//B+PGhZL6U0+FaWXM4HvfgxtugH//OyT/v/89XCDkoIPgqKPq/BZERGolGXXu3YCVMc8Lo2l7MbMJZjbLzGYVFRUlYdNVS8Y1Vdu1Cw2ob7yxZ2IvM348NG0KV14ZSvHnnw/nngt5efD975ePabNzZ+3eg4hIbSQjuVucaXHretz9EXfPc/e8zp07J2HTVavqTNVk6doVTj89lPAHDoR33oG5c+Haa8MYNj16QE4OtG0bGmALC8uT/QcfwIsvwj//GbpjlpYmvt2vvoKvv07e+xCRzJKMIX8LgR4xz7sDq5Kw3jrLzw/3kyaFqpiDDgqJvWx6sjz0UGioPe20UFUDMGhQ6G3z1FPhWq5ffgm//nXoPgmh907FZN6iRTgYHHRQaBfo1CmcQduiBbRqBRdcAJ07h3aEgQND9c9FF4UDSY8eiGSN+fNDm5rOSalcQicxRXXuL1fSoHo68APKG1Qnu/vR1a2zoU9iKiio/yRfnU8/DQ2yW7aE0vvhh8Ohh8K6dSFhx94++wyKi2H79vLXDxgQ6vS/+1147z049dRQZdS5c6g26ts3LLdrVzjbtmtX6N17zxhKSsKBpUkt/7Pt2gWLFsGRR5YfyLLR3/4W9nfXrqmOJDts3RoKOU2bwn//N9x0E3zzm6EjQ6tWtVune/iXvWZN6CnXsmXN1/H11+E32q5d7WKojUQbVHH3Km/AVGA1sJNQSr8MuAq4KppvwIPAJ8BCIK+6dbo7Rx11lDeUKVPcW7d2Dx9nuLVuHaY3dtu2uW/c6P6Xv7g3a+beo0eI/5FHwvyFC927dHHv2NH92mvdR49279QpLNOihfsdd7j/+9/uDz3kfs457u3aheWfftq9tDSso6TE/Y03wrQdOyqPpbTU/fLLw7p/9rPy11fn00/dd+6s235oTP7+97APvvWtxPdBJvr9793/4z/C96e2Yr8Xq1a533WX+z//WT6ttNT9/vvdW7Z0z8lxP/LIsO9HjAj348e7z5/vfuWV7pMmua9ZU/7aDRvczzrL/eST3VesCNNKSsL6b7rJ/bDDyvNBhw7hvWzdGpabM8f9llvcCwv3jnnHDvc773Q/8MDw2qZN3R99NMzbtcv9hRfcCwrcX3zR/W9/C9v761/dp051f/ll97lz3b/6qvb7DJjlCeTYaheor1tDJveePfdM7GW3nj0bLISkePLJEPfIkXsmlY8/Dl/UVq3cv/EN9wsvDF+kc8/d+/1ecYV7Xl54fuih7kOHunfrVr5Mnz7uv/1t+DFUTFy33x6WGTSo/Id1xx3uN97ovnx5WGbu3HAQuflm91mz3PPzw7Knnuq+aVP5ukpL3VeudP/yy/B80aJwcLrtNvfPP6/d/iktdd++vXavTdTWrWG/lRUWnn46TF+2LCSEDRvKl9250/2tt9zffTfEVlQUPpvjj3d/++3Etrd2bTiwb9lS+TJffx2SxrXXhu1VdcApKXF/9ln3V14pT2TuYf3PPhuSUWWv37o1JM+SEvef/7z8O3PNNeE1W7a4f/RRmP/VV6EAcMghIRFffnn4rjz/fEjG8+a5n3eeu5n7Mce4//CHIXmXrTMvz33sWPfjjgvPR40K2znmmJBYS0tD8i1bfp99wrpatXIfNy58LoMGhQJRTo57+/buY8aUF3yaNg1xPfJI2L/nnx+mH3lkWG/z5uF5y5buF1zgPmyYe/fu7gMHlueTU08Ny55wQljfs8+6n3FG/FxT8faznyX2+ceTaHLPirFlmjSJP7SvWc0aMRuDWbNCdU5Ozp7Ty95fbFWJO/z5z7ByJXz726EKyCxUrTz6aDgJa9Om0IVzzJjQ2HzjjbBwYXj9AQeE13TsGKqUFi6ECy8M7Qg33AB33lm+zTZt4NJLw3pbtgxn87qHv9KjR8O0aaFr6KhRoSH5X/8KjcgQqpWKisKyX38d/np37x5ia9cO+keVgfPnh+1MmBCqpDZuDOPyl5bCvHnw2GNhCInjjw/nImzfHpbZsCHcb9wYvgtXXx2qtp57LpyNPHBg+Ft+8MHhYi5PPAFTpoRt7rdfeD/Nm8Mhh4S/8FOnhlFEr78+xH3ppeEi7CUl4TWdOkGfPmGfrVsXpg0cGF775ZfQoQOsXRvaaC67LJwot2xZuBRks2Yhxm3bQtXagw+GKon27cN+zMkJn19JSXh/y5aFz6W4OHwO7mF9gwaFRvyyxvwePcI6brop7HsI1Rnf+EbY/++/H/YPwBFHhE4CBxwQ1llUBLNnhyHKc+JOAAAOyklEQVSyd+wIn8+uXeF9d+gQTvg75ZSw3o0bw2fWpEnY7yNHhvulS8N6YuXkhO/T+++H6pGzz4Zbbw2dEn73u/C6ss/rRz/auxqwtDS8nzZtwjLFxeHM8WefDR0O2rQJn+/BB8PFF4fuyiNHhvd26qkh9livvRbasNatC7HcfHNoI/vLX8LvoE+fsN7t20M716hR4XUbN4Yz3BcsCJ/fPfeE/bF5c7ht2RI+gw4dwrKrVoV1DR5c5U+9Uho4LEZdT2bKJqWl4Yf2z3+GM3Q/+ST8aPr0CWfo3nBDed3k55+HL+2XX8Lll4d66BNPDMlv69Zw8Dj55PDDeOmlcADZsSOs65vfDElo+3ZYvDh0I73ssvCDfuyx8ANo2zZsu+xgM3Bg+Lz+8Y/4sQ8dGtb717/Chx+G5NWuXWh0a9cu3FatCuMBtW4dYtx//5B0Kv4Mjj02HNTKeiXt2BES1LZt4b0++mhIdscfH5bPzw8JYdmysM8+/TQkze9+N6zj4YdDPA8/HJLNvfeGxL1mTeWfhVlIfqNHwx/+AK+8EqY3bRpuLVuG7/Y3vgHnnBOuDfzkk2Eba9eGg+OOHXuus2PHkHwOOABefz3EumZN2P/jx4feXA89FA6kZa9t3jx8hqeeGj67zz8PbTlXXBH22/jxIYmedx4MGxa+N+vXh4PfoEHl296wIWxv6dLwnTnvvHAghJAA27Sp6puZuJ07w4GmR4+wf8q4V99OtGpViP/002vWprRyJVx3HVxzTRi6pD4puceoeMFsCD/usjHepe7cQ+lu0KBQeoln8+Ywr7YNYGXmzw+l/w4dQumvadOQrA4+uHyZkpL4cZSWwjPPhIPNeeeFhPzll2Ho58LC8PiMM+KXqkpKQtLu3TskPAhJvmvX8JqaKikJB8QlS8K/gq5dw7TSUthnn3BwqGuD7c6dobT42Wfh9q1vhfVWx728JN+uXdWJzqOuvS1a1C1WSYySewWNobeMiEhdJW34gUyRn69kLiLZI+OH/BURyUZZl9wTHd9dRCSdZU21DOzdsFo2vjuoykZEMktWldwnTdr7qklbt4bpIiKZJKuSe13HdxcRSRdZldyTMb67iEg6yKrk3hDju4uINAZZldzz88NZqT17hjPuevbUWaoikpmyKrlDSOTLl4fBryAMFKQukSKSabKqK2QZdYkUkUyXdSV3UJdIEcl8WZnc1SVSRDJdViZ3dYkUkUyXlcldXSJFJNNlZXJXl0gRyXRZmdxBXSJFJLNlZVfIMuoSKSKZKmtL7qAukSKSubI6uatLpIhkqqxO7uoSKSKZKquTe7wukQCbN6thVUTSW1Yn97IukR077jm9uDg0rCrBi0i6yurkDiHB5+TsPV0NqyKSzrI+uYMaVkUk8yi5U3kDapMmqpoRkfSk5E7lDau7dqnuXUTSk5I75Q2rTZvuPU917yKSjpTcI/n5UFoaf57q3kUk3SSU3M1spJktMbOPzWxinPmXmFmRmc2LbpcnP9T6p5OaRCRTVJvczawp8CAwCugLjDWzvnEW/YO7D4pujyU5zgahk5pEJFMkUnI/GvjY3T9196+BacDZ9RtWauikJhHJFIkk927AypjnhdG0ir5rZgvM7Dkz65GU6FJAJzWJSCZIJLlbnGle4fmfgV7uPgB4E/h93BWZTTCzWWY2q6ioqGaRNqDKGlBXrFDpXUTSQyLJvRCILYl3B1bFLuDuxe6+I3r6KHBUvBW5+yPunufueZ07d65NvA2iqgZUVc+ISDpIJLm/DxxqZr3NrAUwBngpdgEz6xrz9CxgcfJCbHiVNayCqmdEJD1Um9zdvQT4AfA6IWk/4+6LzOw2MzsrWuxHZrbIzOYDPwIuqa+AG0JZw2plVD0jIo2duVesPm8YeXl5PmvWrJRsO1G9eoVEHk/r1uEAoGutikhDMrPZ7p5X3XI6Q7UKqp4RkXSl5F4FVc+ISLpScq9Gfj707Fn5fPWeEZHGSMk9AdVVz4wfrwQvIo2LknsCqque2bULxo2DTp2U5EWkcVByT1B11TOgMWhEpPFQcq+BqqpnyqgXjYg0BkruNVDVFZtiqReNiKSaknsN5efD739ffQledfAikkpK7rVQ2bjvFRUXK8mLSGoouddSfj6sWwdTplS/rJK8iDQ0Jfc6SqQXTRkleRFpKEruSZBIL5pY6jIpIvVNyT0JEq2Dj7V1ayjFm4XRJ5XoRSSZlNyTJLYOviZJHkLXyYsuUqIXkeRRck+y2ib5smH1V6xQvbyI1J2Sez2pS0keyhtfmzZViV5Eak7JvZ7FJvnqzmyNp7Q03JeV6JXsRSQRSu4NJNEzW6ujZC8iiVByb0BlvWrK+sWXleTNar/OypJ9s2Z73iv5i2QXJfcGlp8Py5eHBtSSknD/1FO1q5ePpyzZ79q1531lyV9JXyQzKbk3AnVtfK2JislfSV8kMym5NyKxSb6s6qYuVTY1kWjSV/IXSQ9K7o1QbNVNaWlqkn2Z6qp5cnJCn/x4B4DK7nVgEKl/Su5poDEl+4q2bAl98mHvA0Bl99X9K4h3MLjmmnDfpIkODiKJUHJPQ1Ul+7IeOMnoiVPfKvtXEO9g8PDD4d695gcHHSwkGym5Z4B4PXDK7itL/o056Scq0YNDIgeLsrF9anqgUBWUNFZK7lkgXvLP5KRfG2Vj+9T0QJHsKqia3nfqVPM2D/2DyQ5K7lmsJkk/25N/XdX2X0Z198XFNW/zqK/qroY8MNXlAFbd80w5wJmXFVkaWF5ens+aNSsl25a6KSiASZPgs8+gQ4cwrbg4JIVduyq/NysvIYs0Zk2ahANydd/psvNSEvn+V7zv2TNc6Cc/v2axmdlsd8+r9j3U5o1Ldisr8ZeWhn7569bFr+9PtP6/snv9S5BUSfSfVl3/OdXnFdmU3KVBVdX4W9XBwCzcX3114gcHHSyksdu6NfwLrg9K7tKoxf5LWL4cHnoo8YNDIgeLKVNq9m9CBxJJts8+q5/1qs5dpJ6UtU2sWFHz+thE72tT56u2j8alZ89QYElUUuvczWykmS0xs4/NbGKc+S3N7A/R/Jlm1ivxUEUyU02qoGp7X5M2j/qq7qrtfceO5QenZK87Xf45tW4dGlXrQ7XJ3cyaAg8Co4C+wFgz61thscuAr9z9EOBe4I5kByoiyZPM6q6GPDAl4wBW3XNomANUz57h+g417S2TqGYJLHM08LG7fwpgZtOAs4EPY5Y5G7glevwc8ICZmaeqzkdEsl5+fv0lznSQSLVMN2BlzPPCaFrcZdy9BNgA7DUyuZlNMLNZZjarqKiodhGLiEi1Eknu8WqvKpbIE1kGd3/E3fPcPa9z586JxCciIrWQSHIvBHrEPO8OrKpsGTNrBuwLfJmMAEVEpOYSSe7vA4eaWW8zawGMAV6qsMxLwPjo8WjgLdW3i4ikTrUNqu5eYmY/AF4HmgKPu/siM7sNmOXuLwG/BZ4ys48JJfYx9Rm0iIhULWUnMZlZEbCili/vBKxLYjj1QTEmh2JMDsVYd40lvp7uXm2jZcqSe12Y2axEztBKJcWYHIoxORRj3TX2+CrS2DIiIhlIyV1EJAOla3J/JNUBJEAxJodiTA7FWHeNPb49pGWdu4iIVC1dS+4iIlIFJXcRkQyUdsm9urHlU8HMepjZdDNbbGaLzOzH0fQOZvaGmS2N7vdLcZxNzWyumb0cPe8djb+/NBqPv0WK42tvZs+Z2UfRvjy2Ee7Dn0af8QdmNtXMWqV6P5rZ42b2hZl9EDMt7n6zYHL0+1lgZrkpjPGu6LNeYGYvmFn7mHk3RDEuMbNTUxVjzLzrzMzNrFP0PCX7sSbSKrknOLZ8KpQAP3P3I4AhwPejuCYCf3P3Q4G/Rc9T6cfA4pjndwD3RvF9RRiXP5V+Bbzm7ocDAwmxNpp9aGbdgB8Bee7en3DG9hhSvx9/B4ysMK2y/TYKODS6TQAeTmGMbwD93X0A8G/gBoDotzMG6Be95qHot5+KGDGzHsC3gdgL4qVqPybO3dPmBhwLvB7z/AbghlTHFSfOFwlfhiVA12haV2BJCmPqTviRnwi8TBjJcx3QLN6+TUF87YBlRI38MdMb0z4sG9q6A2HojpeBUxvDfgR6AR9Ut9+A3wBj4y3X0DFWmPcdoCB6vMfvmjD0ybGpipFwjYqBwHKgU6r3Y6K3tCq5k9jY8ikVXWJwMDATOMDdVwNE9/unLjLuA/4fUBo97wis9zD+PqR+X/YBioAnoqqjx8ysDY1oH7r758DdhBLcasJ1C2bTuPZjmcr2W2P9DX0PeDV63GhiNLOzgM/dfX6FWY0mxsqkW3JPaNz4VDGzHOB54CfuvjHV8ZQxszOAL9x9duzkOIumcl82A3KBh919MLCF1Fdj7SGqtz4b6A0cCLQh/D2vqNF8J+NobJ87ZjaJULVZUDYpzmINHqOZtQYmATfHmx1nWqP63NMtuScytnxKmFlzQmIvcPc/RpPXmlnXaH5X4IsUhTcUOMvMlgPTCFUz9wHto/H3IfX7shAodPeZ0fPnCMm+sexDgJOBZe5e5O47gT8C36Jx7ccyle23RvUbMrPxwBlAvkf1GzSeGA8mHMjnR7+d7sAcM+tC44mxUumW3BMZW77BmZkRhj1e7O73xMyKHed+PKEuvsG5+w3u3t3dexH22Vvung9MJ4y/n9L4ANx9DbDSzA6LJp1EuE5vo9iHkc+AIWbWOvrMy2JsNPsxRmX77SXg4qi3xxBgQ1n1TUMzs5HA9cBZ7r41ZtZLwBgza2lmvQmNlu81dHzuvtDd93f3XtFvpxDIjb6rjWY/VirVlf61aPA4jdCy/gkwKdXxRDENI/wlWwDMi26nEeq1/wYsje47NIJYRwAvR4/7EH40HwPPAi1THNsgYFa0H/8E7NfY9iFwK/AR8AHwFNAy1fsRmEpoA9hJSECXVbbfCNUJD0a/n4WEnj+pivFjQr112W/m1zHLT4piXAKMSlWMFeYvp7xBNSX7sSY3DT8gIpKB0q1aRkREEqDkLiKSgZTcRUQykJK7iEgGUnIXEclASu4iIhlIyV1EJAP9f4AurJQSwXz1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2467f608be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy = model_train.history['acc']\n",
    "# val_accuracy = model_train.history['val_acc']\n",
    "# loss = model_train.history['loss']\n",
    "# val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training mse')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation mse')\n",
    "plt.title('Training and validation mse')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(workdir + '//mse_loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test validation\n",
    "predicted_classes = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_label_array)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(workdir + '//190510_DeepIC50v2_epoch_150_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.967704</td>\n",
       "      <td>1.158653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.843003</td>\n",
       "      <td>5.321962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.800345</td>\n",
       "      <td>3.624203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.667946</td>\n",
       "      <td>3.054980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.658939</td>\n",
       "      <td>-3.985187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.385154</td>\n",
       "      <td>5.948850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.599374</td>\n",
       "      <td>3.928832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.885066</td>\n",
       "      <td>-2.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.478412</td>\n",
       "      <td>4.139350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.056967</td>\n",
       "      <td>1.180256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.378699</td>\n",
       "      <td>3.678348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.852033</td>\n",
       "      <td>3.533262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.413807</td>\n",
       "      <td>4.628557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.802703</td>\n",
       "      <td>6.239514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.293597</td>\n",
       "      <td>-1.004656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.686392</td>\n",
       "      <td>4.429204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.876898</td>\n",
       "      <td>9.838015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.326474</td>\n",
       "      <td>5.823503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.431539</td>\n",
       "      <td>-0.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.796180</td>\n",
       "      <td>2.979083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.654342</td>\n",
       "      <td>5.686556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-2.753475</td>\n",
       "      <td>-1.276596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.640921</td>\n",
       "      <td>1.999530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-4.204585</td>\n",
       "      <td>-2.882183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.843412</td>\n",
       "      <td>7.627765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.767828</td>\n",
       "      <td>3.297893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.282358</td>\n",
       "      <td>5.114267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.539549</td>\n",
       "      <td>3.152258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.306800</td>\n",
       "      <td>4.477687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.440038</td>\n",
       "      <td>3.634297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16007</th>\n",
       "      <td>5.125562</td>\n",
       "      <td>5.132930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16008</th>\n",
       "      <td>-0.999901</td>\n",
       "      <td>-0.837246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16009</th>\n",
       "      <td>2.879771</td>\n",
       "      <td>2.955796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16010</th>\n",
       "      <td>0.439721</td>\n",
       "      <td>0.432553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16011</th>\n",
       "      <td>1.361276</td>\n",
       "      <td>2.325718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16012</th>\n",
       "      <td>1.635171</td>\n",
       "      <td>2.201551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16013</th>\n",
       "      <td>6.249751</td>\n",
       "      <td>6.475007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16014</th>\n",
       "      <td>0.371725</td>\n",
       "      <td>0.405655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16015</th>\n",
       "      <td>4.544520</td>\n",
       "      <td>4.897543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16016</th>\n",
       "      <td>1.890278</td>\n",
       "      <td>1.802193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16017</th>\n",
       "      <td>3.818258</td>\n",
       "      <td>3.885305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16018</th>\n",
       "      <td>1.708903</td>\n",
       "      <td>1.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16019</th>\n",
       "      <td>0.725155</td>\n",
       "      <td>0.991735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16020</th>\n",
       "      <td>0.180909</td>\n",
       "      <td>-1.091555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>3.556114</td>\n",
       "      <td>6.043038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16022</th>\n",
       "      <td>4.223333</td>\n",
       "      <td>3.850022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>-1.633211</td>\n",
       "      <td>-1.201109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16024</th>\n",
       "      <td>-1.147235</td>\n",
       "      <td>-0.788625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16025</th>\n",
       "      <td>3.212679</td>\n",
       "      <td>3.514015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16026</th>\n",
       "      <td>3.860270</td>\n",
       "      <td>6.153076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16027</th>\n",
       "      <td>-3.771966</td>\n",
       "      <td>-2.760126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16028</th>\n",
       "      <td>1.915854</td>\n",
       "      <td>1.983585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16029</th>\n",
       "      <td>-2.201700</td>\n",
       "      <td>-2.551189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16030</th>\n",
       "      <td>-1.122744</td>\n",
       "      <td>-0.956153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16031</th>\n",
       "      <td>2.106364</td>\n",
       "      <td>2.756135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16032</th>\n",
       "      <td>4.103848</td>\n",
       "      <td>4.306719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16033</th>\n",
       "      <td>4.037104</td>\n",
       "      <td>4.289366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16034</th>\n",
       "      <td>-3.819445</td>\n",
       "      <td>-4.639442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16035</th>\n",
       "      <td>8.788931</td>\n",
       "      <td>10.133803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16036</th>\n",
       "      <td>0.462222</td>\n",
       "      <td>-1.151680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16037 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted       Test\n",
       "0       0.967704   1.158653\n",
       "1       4.843003   5.321962\n",
       "2       2.800345   3.624203\n",
       "3       4.667946   3.054980\n",
       "4      -3.658939  -3.985187\n",
       "5       7.385154   5.948850\n",
       "6       3.599374   3.928832\n",
       "7      -2.885066  -2.823335\n",
       "8       4.478412   4.139350\n",
       "9       1.056967   1.180256\n",
       "10      3.378699   3.678348\n",
       "11      3.852033   3.533262\n",
       "12      4.413807   4.628557\n",
       "13      5.802703   6.239514\n",
       "14     -0.293597  -1.004656\n",
       "15      3.686392   4.429204\n",
       "16      7.876898   9.838015\n",
       "17      4.326474   5.823503\n",
       "18     -0.431539  -0.215900\n",
       "19      2.796180   2.979083\n",
       "20      5.654342   5.686556\n",
       "21     -2.753475  -1.276596\n",
       "22      2.640921   1.999530\n",
       "23     -4.204585  -2.882183\n",
       "24      6.843412   7.627765\n",
       "25      2.767828   3.297893\n",
       "26      4.282358   5.114267\n",
       "27      2.539549   3.152258\n",
       "28      4.306800   4.477687\n",
       "29      3.440038   3.634297\n",
       "...          ...        ...\n",
       "16007   5.125562   5.132930\n",
       "16008  -0.999901  -0.837246\n",
       "16009   2.879771   2.955796\n",
       "16010   0.439721   0.432553\n",
       "16011   1.361276   2.325718\n",
       "16012   1.635171   2.201551\n",
       "16013   6.249751   6.475007\n",
       "16014   0.371725   0.405655\n",
       "16015   4.544520   4.897543\n",
       "16016   1.890278   1.802193\n",
       "16017   3.818258   3.885305\n",
       "16018   1.708903   1.237600\n",
       "16019   0.725155   0.991735\n",
       "16020   0.180909  -1.091555\n",
       "16021   3.556114   6.043038\n",
       "16022   4.223333   3.850022\n",
       "16023  -1.633211  -1.201109\n",
       "16024  -1.147235  -0.788625\n",
       "16025   3.212679   3.514015\n",
       "16026   3.860270   6.153076\n",
       "16027  -3.771966  -2.760126\n",
       "16028   1.915854   1.983585\n",
       "16029  -2.201700  -2.551189\n",
       "16030  -1.122744  -0.956153\n",
       "16031   2.106364   2.756135\n",
       "16032   4.103848   4.306719\n",
       "16033   4.037104   4.289366\n",
       "16034  -3.819445  -4.639442\n",
       "16035   8.788931  10.133803\n",
       "16036   0.462222  -1.151680\n",
       "\n",
       "[16037 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16037, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2467f7369b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot as test validation\n",
    "plt.scatter(test_label_array,predicted_value,c='blue')\n",
    "plt.xlabel('test_IC50_value')\n",
    "plt.ylabel('predicted_IC50_value')\n",
    "plt.savefig(workdir + '//190510_DeepIC50v2_epoch_150_test_scatterplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rmse value is = 0.9663229722378357\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "\n",
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared value\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_value = r2_score(b, a) \n",
    "print(r2_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
