{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15405390674130322329\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 18038862643\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13802916558440498921\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "# 출처: https://3months.tistory.com/206 [Deep Play]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < Important note > [ Please download input data from https://mega.nz/#F!CeYGDKyS!uqkmWJ4E2XSGJp_C2VO2gg]\n",
    "# IC50evaluation//Dataset//Scenario6_MDC-9K_minmax\n",
    "\n",
    "dataset = np.load(workdir + \"//190510_ccle_cell_gdsc_mut_drug_info.npz\") # input file\n",
    "ss0 = np.load(workdir + '//190510_ccle_cell_gdsc_mut_drug_info_r0_9_1.npz') # split for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['x']\n",
    "y = dataset['y']\n",
    "# y_linear = dataset['y_lnIC50']\n",
    "ss0_train = ss0['train']\n",
    "ss0_test = ss0['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_array, training_label_array = x[ss0_train], y[ss0_train]\n",
    "test_image_array, test_label_array = x[ss0_test], y[ss0_test]\n",
    "\n",
    "# # In[9]:\n",
    "# ori = training_image_array\n",
    "# bat = np.zeros((ori.shape[0],178))\n",
    "# cat = np.hstack([ori,bat])\n",
    "# training_image_array = cat\n",
    "\n",
    "# # In[8]:\n",
    "# training_image_array.shape\n",
    "\n",
    "# # In[10]:\n",
    "# ori2 = test_image_array\n",
    "# bat2 = np.zeros((ori2.shape[0],178))\n",
    "# cat2 = np.hstack([ori2,bat2])\n",
    "# test_image_array = cat2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    }
   ],
   "source": [
    "# In[15]:\n",
    "ab =[]\n",
    "for i in range(100,300):\n",
    "    ab.append(len(training_image_array) % i)\n",
    "    \n",
    "print(min(ab), ab.index(min(ab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8727, 23538)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7855, 23538)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[21]:\n",
    "\n",
    "num_classes = 1\n",
    "learning_rate = 0.0002\n",
    "training_epochs = 150\n",
    "batch_size = 100\n",
    "# img_rows, img_cols = 154, 154\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = training_image_array, training_label_array, test_image_array, test_label_array\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     train_X = train_X.reshape(train_X.shape[0], 1, img_rows, img_cols)\n",
    "#     test_X = test_X.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "# else:\n",
    "#     train_X = train_X.reshape(train_X.shape[0], img_rows, img_cols, 1)\n",
    "#     test_X = test_X.reshape(test_X.shape[0], img_rows, img_cols, 1)\n",
    "#     input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1],1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1],1)\n",
    "#input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7855, 23538, 1) (7855,) (872, 23538, 1) (872,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (7855, 23538, 1)\n",
      "7855 train samples\n",
      "872 test samples\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "# train_X /= 255\n",
    "# test_X /= 255\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7855, 23538)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 23538, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 11769, 16)    64          inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 2353, 16)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2353, 16)     64          max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2353, 16)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 2353, 16)     784         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2353, 16)     64          conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2353, 16)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 2353, 16)     784         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2353, 16)     64          conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2353, 16)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 2353, 16)     784         activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 2353, 16)     64          conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2353, 16)     0           batch_normalization_31[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2353, 16)     0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 2353, 16)     784         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 2353, 16)     64          conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2353, 16)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 2353, 16)     784         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 2353, 16)     64          conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2353, 16)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 2353, 16)     784         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 2353, 16)     64          conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2353, 16)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 2353, 16)     784         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 2353, 16)     64          conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2353, 16)     0           batch_normalization_35[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2353, 16)     0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1177, 32)     1568        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1177, 32)     128         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1177, 32)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1177, 32)     3104        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1177, 32)     3104        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1177, 32)     128         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 1177, 32)     0           batch_normalization_37[0][0]     \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1177, 32)     0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1177, 32)     3104        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1177, 32)     128         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1177, 32)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1177, 32)     3104        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1177, 32)     128         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1177, 32)     0           batch_normalization_39[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1177, 32)     0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1177, 32)     3104        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 1177, 32)     128         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1177, 32)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1177, 32)     3104        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1177, 32)     128         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1177, 32)     0           batch_normalization_41[0][0]     \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1177, 32)     0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 589, 64)      6208        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 589, 64)      256         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 589, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 589, 64)      12352       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 589, 64)      12352       conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 589, 64)      256         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 589, 64)      0           batch_normalization_43[0][0]     \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 589, 64)      0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 589, 64)      12352       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 589, 64)      256         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 589, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 589, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 589, 64)      256         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 589, 64)      0           batch_normalization_45[0][0]     \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 589, 64)      0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 589, 64)      12352       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 589, 64)      256         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 589, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 589, 64)      12352       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 589, 64)      256         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 589, 64)      0           batch_normalization_47[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 589, 64)      0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 37696)        0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 2048)         77203456    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 2048)         8192        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 2048)         0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2048)         0           dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense5 (Dense)                  (None, 1024)         2098176     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 1024)         4096        dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout5 (Dropout)              (None, 1024)         0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1024)         0           dropout5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense6 (Dense)                  (None, 512)          524800      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 512)          2048        dense6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout6 (Dropout)              (None, 512)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 512)          0           dropout6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense7 (Dense)                  (None, 1024)         525312      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1024)         4096        dense7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout7 (Dropout)              (None, 1024)         0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 1024)         0           dropout7[0][0]                   \n",
      "                                                                 batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 1024)         0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense8 (Dense)                  (None, 512)          524800      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 512)          2048        dense8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout8 (Dropout)              (None, 512)          0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 512)          0           dropout8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense9 (Dense)                  (None, 256)          131328      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 256)          1024        dense9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout9 (Dropout)              (None, 256)          0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 256)          0           dropout9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense10 (Dense)                 (None, 128)          32896       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 128)          512         dense10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout10 (Dropout)             (None, 128)          0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 128)          0           dropout10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            129         activation_54[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 81,171,793\n",
      "Trainable params: 81,159,377\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# In[10]:\n",
    "with K.tf.device('/GPU:0'):\n",
    "    inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     y = x\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#     x = AveragePooling1D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=2048, name='dense1'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout1') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#    x = Reshape((300,1))(x)\n",
    "\n",
    "#    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "#    x = MaxPooling1D(pool_size=2)(x)\n",
    "#    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense5'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout5') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=512, name='dense6'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout6') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense7'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout7') (x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=512, name='dense8'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout8') (x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=256, name='dense9'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout9') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=128, name='dense10'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout10') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "#     predictions = Dense(1, activation='linear', name='predictions')(x)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN20190327')\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                  metrics=['mse','mae'])\n",
    "\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2019-05-12 13:54:44.460000\n",
      "Train on 7855 samples, validate on 872 samples\n",
      "Epoch 1/150\n",
      "7855/7855 [==============================] - 25s 3ms/step - loss: 4.7121 - mean_squared_error: 4.7121 - mean_absolute_error: 1.9712 - val_loss: 4.7097 - val_mean_squared_error: 4.7097 - val_mean_absolute_error: 1.9492\n",
      "Epoch 2/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.6851 - mean_squared_error: 4.6851 - mean_absolute_error: 1.9627 - val_loss: 4.6892 - val_mean_squared_error: 4.6892 - val_mean_absolute_error: 1.9420\n",
      "Epoch 3/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.6589 - mean_squared_error: 4.6589 - mean_absolute_error: 1.9544 - val_loss: 4.6695 - val_mean_squared_error: 4.6695 - val_mean_absolute_error: 1.9349\n",
      "Epoch 4/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.6337 - mean_squared_error: 4.6337 - mean_absolute_error: 1.9462 - val_loss: 4.6503 - val_mean_squared_error: 4.6503 - val_mean_absolute_error: 1.9279\n",
      "Epoch 5/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.6092 - mean_squared_error: 4.6092 - mean_absolute_error: 1.9381 - val_loss: 4.6321 - val_mean_squared_error: 4.6321 - val_mean_absolute_error: 1.9210\n",
      "Epoch 6/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.5853 - mean_squared_error: 4.5853 - mean_absolute_error: 1.9301 - val_loss: 4.6143 - val_mean_squared_error: 4.6143 - val_mean_absolute_error: 1.9143\n",
      "Epoch 7/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.5619 - mean_squared_error: 4.5619 - mean_absolute_error: 1.9223 - val_loss: 4.5972 - val_mean_squared_error: 4.5972 - val_mean_absolute_error: 1.9076\n",
      "Epoch 8/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.5394 - mean_squared_error: 4.5394 - mean_absolute_error: 1.9145 - val_loss: 4.5807 - val_mean_squared_error: 4.5807 - val_mean_absolute_error: 1.9010\n",
      "Epoch 9/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.5175 - mean_squared_error: 4.5175 - mean_absolute_error: 1.9069 - val_loss: 4.5647 - val_mean_squared_error: 4.5647 - val_mean_absolute_error: 1.8945\n",
      "Epoch 10/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.4962 - mean_squared_error: 4.4962 - mean_absolute_error: 1.8993 - val_loss: 4.5492 - val_mean_squared_error: 4.5492 - val_mean_absolute_error: 1.8880\n",
      "Epoch 11/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.4753 - mean_squared_error: 4.4753 - mean_absolute_error: 1.8918 - val_loss: 4.5343 - val_mean_squared_error: 4.5343 - val_mean_absolute_error: 1.8817\n",
      "Epoch 12/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.4552 - mean_squared_error: 4.4552 - mean_absolute_error: 1.8844 - val_loss: 4.5197 - val_mean_squared_error: 4.5197 - val_mean_absolute_error: 1.8753\n",
      "Epoch 13/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.4356 - mean_squared_error: 4.4356 - mean_absolute_error: 1.8771 - val_loss: 4.5060 - val_mean_squared_error: 4.5060 - val_mean_absolute_error: 1.8692\n",
      "Epoch 14/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.4165 - mean_squared_error: 4.4165 - mean_absolute_error: 1.8700 - val_loss: 4.4926 - val_mean_squared_error: 4.4926 - val_mean_absolute_error: 1.8632\n",
      "Epoch 15/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.3980 - mean_squared_error: 4.3980 - mean_absolute_error: 1.8628 - val_loss: 4.4796 - val_mean_squared_error: 4.4796 - val_mean_absolute_error: 1.8571\n",
      "Epoch 16/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.3800 - mean_squared_error: 4.3800 - mean_absolute_error: 1.8558 - val_loss: 4.4674 - val_mean_squared_error: 4.4674 - val_mean_absolute_error: 1.8513\n",
      "Epoch 17/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.3625 - mean_squared_error: 4.3625 - mean_absolute_error: 1.8488 - val_loss: 4.4553 - val_mean_squared_error: 4.4553 - val_mean_absolute_error: 1.8454\n",
      "Epoch 18/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.3455 - mean_squared_error: 4.3455 - mean_absolute_error: 1.8419 - val_loss: 4.4439 - val_mean_squared_error: 4.4439 - val_mean_absolute_error: 1.8397\n",
      "Epoch 19/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.3290 - mean_squared_error: 4.3290 - mean_absolute_error: 1.8350 - val_loss: 4.4327 - val_mean_squared_error: 4.4327 - val_mean_absolute_error: 1.8340\n",
      "Epoch 20/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.3130 - mean_squared_error: 4.3130 - mean_absolute_error: 1.8283 - val_loss: 4.4221 - val_mean_squared_error: 4.4221 - val_mean_absolute_error: 1.8283\n",
      "Epoch 21/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2974 - mean_squared_error: 4.2974 - mean_absolute_error: 1.8217 - val_loss: 4.4119 - val_mean_squared_error: 4.4119 - val_mean_absolute_error: 1.8228\n",
      "Epoch 22/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2823 - mean_squared_error: 4.2823 - mean_absolute_error: 1.8151 - val_loss: 4.4020 - val_mean_squared_error: 4.4020 - val_mean_absolute_error: 1.8173\n",
      "Epoch 23/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2677 - mean_squared_error: 4.2677 - mean_absolute_error: 1.8086 - val_loss: 4.3926 - val_mean_squared_error: 4.3926 - val_mean_absolute_error: 1.8120\n",
      "Epoch 24/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2536 - mean_squared_error: 4.2536 - mean_absolute_error: 1.8022 - val_loss: 4.3838 - val_mean_squared_error: 4.3838 - val_mean_absolute_error: 1.8068\n",
      "Epoch 25/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2398 - mean_squared_error: 4.2398 - mean_absolute_error: 1.7958 - val_loss: 4.3750 - val_mean_squared_error: 4.3750 - val_mean_absolute_error: 1.8015\n",
      "Epoch 26/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2265 - mean_squared_error: 4.2265 - mean_absolute_error: 1.7896 - val_loss: 4.3669 - val_mean_squared_error: 4.3669 - val_mean_absolute_error: 1.7965\n",
      "Epoch 27/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2136 - mean_squared_error: 4.2136 - mean_absolute_error: 1.7833 - val_loss: 4.3589 - val_mean_squared_error: 4.3589 - val_mean_absolute_error: 1.7914\n",
      "Epoch 28/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.2011 - mean_squared_error: 4.2011 - mean_absolute_error: 1.7772 - val_loss: 4.3514 - val_mean_squared_error: 4.3514 - val_mean_absolute_error: 1.7865\n",
      "Epoch 29/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1891 - mean_squared_error: 4.1891 - mean_absolute_error: 1.7711 - val_loss: 4.3444 - val_mean_squared_error: 4.3444 - val_mean_absolute_error: 1.7817\n",
      "Epoch 30/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1774 - mean_squared_error: 4.1774 - mean_absolute_error: 1.7651 - val_loss: 4.3376 - val_mean_squared_error: 4.3376 - val_mean_absolute_error: 1.7770\n",
      "Epoch 31/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1662 - mean_squared_error: 4.1662 - mean_absolute_error: 1.7591 - val_loss: 4.3311 - val_mean_squared_error: 4.3311 - val_mean_absolute_error: 1.7722\n",
      "Epoch 32/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1553 - mean_squared_error: 4.1553 - mean_absolute_error: 1.7533 - val_loss: 4.3250 - val_mean_squared_error: 4.3250 - val_mean_absolute_error: 1.7676\n",
      "Epoch 33/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1449 - mean_squared_error: 4.1449 - mean_absolute_error: 1.7476 - val_loss: 4.3193 - val_mean_squared_error: 4.3193 - val_mean_absolute_error: 1.7631\n",
      "Epoch 34/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1348 - mean_squared_error: 4.1348 - mean_absolute_error: 1.7419 - val_loss: 4.3140 - val_mean_squared_error: 4.3140 - val_mean_absolute_error: 1.7587\n",
      "Epoch 35/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1250 - mean_squared_error: 4.1250 - mean_absolute_error: 1.7364 - val_loss: 4.3089 - val_mean_squared_error: 4.3089 - val_mean_absolute_error: 1.7542\n",
      "Epoch 36/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1156 - mean_squared_error: 4.1156 - mean_absolute_error: 1.7308 - val_loss: 4.3040 - val_mean_squared_error: 4.3040 - val_mean_absolute_error: 1.7499\n",
      "Epoch 37/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.1066 - mean_squared_error: 4.1066 - mean_absolute_error: 1.7253 - val_loss: 4.2994 - val_mean_squared_error: 4.2994 - val_mean_absolute_error: 1.7455\n",
      "Epoch 38/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0978 - mean_squared_error: 4.0978 - mean_absolute_error: 1.7201 - val_loss: 4.2953 - val_mean_squared_error: 4.2953 - val_mean_absolute_error: 1.7414\n",
      "Epoch 39/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0895 - mean_squared_error: 4.0895 - mean_absolute_error: 1.7147 - val_loss: 4.2913 - val_mean_squared_error: 4.2913 - val_mean_absolute_error: 1.7372\n",
      "Epoch 40/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0814 - mean_squared_error: 4.0814 - mean_absolute_error: 1.7095 - val_loss: 4.2876 - val_mean_squared_error: 4.2876 - val_mean_absolute_error: 1.7330\n",
      "Epoch 41/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0736 - mean_squared_error: 4.0736 - mean_absolute_error: 1.7044 - val_loss: 4.2842 - val_mean_squared_error: 4.2842 - val_mean_absolute_error: 1.7290\n",
      "Epoch 42/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0662 - mean_squared_error: 4.0662 - mean_absolute_error: 1.6994 - val_loss: 4.2811 - val_mean_squared_error: 4.2811 - val_mean_absolute_error: 1.7251\n",
      "Epoch 43/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0592 - mean_squared_error: 4.0592 - mean_absolute_error: 1.6943 - val_loss: 4.2781 - val_mean_squared_error: 4.2781 - val_mean_absolute_error: 1.7211\n",
      "Epoch 44/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0524 - mean_squared_error: 4.0524 - mean_absolute_error: 1.6896 - val_loss: 4.2756 - val_mean_squared_error: 4.2756 - val_mean_absolute_error: 1.7174\n",
      "Epoch 45/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0459 - mean_squared_error: 4.0459 - mean_absolute_error: 1.6848 - val_loss: 4.2731 - val_mean_squared_error: 4.2731 - val_mean_absolute_error: 1.7137\n",
      "Epoch 46/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0396 - mean_squared_error: 4.0396 - mean_absolute_error: 1.6799 - val_loss: 4.2710 - val_mean_squared_error: 4.2710 - val_mean_absolute_error: 1.7101\n",
      "Epoch 47/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0336 - mean_squared_error: 4.0336 - mean_absolute_error: 1.6754 - val_loss: 4.2690 - val_mean_squared_error: 4.2690 - val_mean_absolute_error: 1.7066\n",
      "Epoch 48/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0280 - mean_squared_error: 4.0280 - mean_absolute_error: 1.6708 - val_loss: 4.2673 - val_mean_squared_error: 4.2673 - val_mean_absolute_error: 1.7031\n",
      "Epoch 49/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0226 - mean_squared_error: 4.0226 - mean_absolute_error: 1.6664 - val_loss: 4.2658 - val_mean_squared_error: 4.2658 - val_mean_absolute_error: 1.6998\n",
      "Epoch 50/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0175 - mean_squared_error: 4.0175 - mean_absolute_error: 1.6617 - val_loss: 4.2644 - val_mean_squared_error: 4.2644 - val_mean_absolute_error: 1.6963\n",
      "Epoch 51/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0125 - mean_squared_error: 4.0125 - mean_absolute_error: 1.6576 - val_loss: 4.2633 - val_mean_squared_error: 4.2633 - val_mean_absolute_error: 1.6931\n",
      "Epoch 52/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0079 - mean_squared_error: 4.0079 - mean_absolute_error: 1.6534 - val_loss: 4.2623 - val_mean_squared_error: 4.2623 - val_mean_absolute_error: 1.6899\n",
      "Epoch 53/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 4.0035 - mean_squared_error: 4.0035 - mean_absolute_error: 1.6491 - val_loss: 4.2615 - val_mean_squared_error: 4.2615 - val_mean_absolute_error: 1.6867\n",
      "Epoch 54/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9993 - mean_squared_error: 3.9993 - mean_absolute_error: 1.6451 - val_loss: 4.2609 - val_mean_squared_error: 4.2609 - val_mean_absolute_error: 1.6836\n",
      "Epoch 55/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9953 - mean_squared_error: 3.9953 - mean_absolute_error: 1.6410 - val_loss: 4.2605 - val_mean_squared_error: 4.2605 - val_mean_absolute_error: 1.6807\n",
      "Epoch 56/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9916 - mean_squared_error: 3.9916 - mean_absolute_error: 1.6370 - val_loss: 4.2601 - val_mean_squared_error: 4.2601 - val_mean_absolute_error: 1.6776\n",
      "Epoch 57/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9881 - mean_squared_error: 3.9881 - mean_absolute_error: 1.6335 - val_loss: 4.2600 - val_mean_squared_error: 4.2600 - val_mean_absolute_error: 1.6749\n",
      "Epoch 58/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9848 - mean_squared_error: 3.9848 - mean_absolute_error: 1.6297 - val_loss: 4.2600 - val_mean_squared_error: 4.2600 - val_mean_absolute_error: 1.6720\n",
      "Epoch 59/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9817 - mean_squared_error: 3.9817 - mean_absolute_error: 1.6258 - val_loss: 4.2601 - val_mean_squared_error: 4.2601 - val_mean_absolute_error: 1.6691\n",
      "Epoch 60/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9787 - mean_squared_error: 3.9787 - mean_absolute_error: 1.6223 - val_loss: 4.2603 - val_mean_squared_error: 4.2603 - val_mean_absolute_error: 1.6665\n",
      "Epoch 61/150\n",
      "7855/7855 [==============================] - 11s 1ms/step - loss: 3.9760 - mean_squared_error: 3.9760 - mean_absolute_error: 1.6188 - val_loss: 4.2606 - val_mean_squared_error: 4.2606 - val_mean_absolute_error: 1.6639\n",
      "Epoch 62/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9735 - mean_squared_error: 3.9735 - mean_absolute_error: 1.6155 - val_loss: 4.2610 - val_mean_squared_error: 4.2610 - val_mean_absolute_error: 1.6614\n",
      "Epoch 63/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9711 - mean_squared_error: 3.9711 - mean_absolute_error: 1.6121 - val_loss: 4.2616 - val_mean_squared_error: 4.2616 - val_mean_absolute_error: 1.6588\n",
      "Epoch 64/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9688 - mean_squared_error: 3.9688 - mean_absolute_error: 1.6088 - val_loss: 4.2622 - val_mean_squared_error: 4.2622 - val_mean_absolute_error: 1.6563\n",
      "Epoch 65/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9668 - mean_squared_error: 3.9668 - mean_absolute_error: 1.6057 - val_loss: 4.2629 - val_mean_squared_error: 4.2629 - val_mean_absolute_error: 1.6540\n",
      "Epoch 66/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9648 - mean_squared_error: 3.9648 - mean_absolute_error: 1.6027 - val_loss: 4.2636 - val_mean_squared_error: 4.2636 - val_mean_absolute_error: 1.6517\n",
      "Epoch 67/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9630 - mean_squared_error: 3.9630 - mean_absolute_error: 1.6000 - val_loss: 4.2644 - val_mean_squared_error: 4.2644 - val_mean_absolute_error: 1.6496\n",
      "Epoch 68/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9614 - mean_squared_error: 3.9614 - mean_absolute_error: 1.5970 - val_loss: 4.2653 - val_mean_squared_error: 4.2653 - val_mean_absolute_error: 1.6473\n",
      "Epoch 69/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9599 - mean_squared_error: 3.9599 - mean_absolute_error: 1.5942 - val_loss: 4.2663 - val_mean_squared_error: 4.2663 - val_mean_absolute_error: 1.6453\n",
      "Epoch 70/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9585 - mean_squared_error: 3.9585 - mean_absolute_error: 1.5917 - val_loss: 4.2672 - val_mean_squared_error: 4.2672 - val_mean_absolute_error: 1.6434\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9572 - mean_squared_error: 3.9572 - mean_absolute_error: 1.5888 - val_loss: 4.2682 - val_mean_squared_error: 4.2682 - val_mean_absolute_error: 1.6415\n",
      "Epoch 72/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9560 - mean_squared_error: 3.9560 - mean_absolute_error: 1.5866 - val_loss: 4.2691 - val_mean_squared_error: 4.2691 - val_mean_absolute_error: 1.6398\n",
      "Epoch 73/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9549 - mean_squared_error: 3.9549 - mean_absolute_error: 1.5840 - val_loss: 4.2702 - val_mean_squared_error: 4.2702 - val_mean_absolute_error: 1.6380\n",
      "Epoch 74/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9540 - mean_squared_error: 3.9540 - mean_absolute_error: 1.5816 - val_loss: 4.2713 - val_mean_squared_error: 4.2713 - val_mean_absolute_error: 1.6362\n",
      "Epoch 75/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9530 - mean_squared_error: 3.9530 - mean_absolute_error: 1.5796 - val_loss: 4.2724 - val_mean_squared_error: 4.2724 - val_mean_absolute_error: 1.6346\n",
      "Epoch 76/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9522 - mean_squared_error: 3.9522 - mean_absolute_error: 1.5777 - val_loss: 4.2734 - val_mean_squared_error: 4.2734 - val_mean_absolute_error: 1.6331\n",
      "Epoch 77/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9514 - mean_squared_error: 3.9514 - mean_absolute_error: 1.5754 - val_loss: 4.2745 - val_mean_squared_error: 4.2745 - val_mean_absolute_error: 1.6315\n",
      "Epoch 78/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9508 - mean_squared_error: 3.9508 - mean_absolute_error: 1.5733 - val_loss: 4.2756 - val_mean_squared_error: 4.2756 - val_mean_absolute_error: 1.6300\n",
      "Epoch 79/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9502 - mean_squared_error: 3.9502 - mean_absolute_error: 1.5717 - val_loss: 4.2765 - val_mean_squared_error: 4.2765 - val_mean_absolute_error: 1.6289\n",
      "Epoch 80/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9496 - mean_squared_error: 3.9496 - mean_absolute_error: 1.5699 - val_loss: 4.2776 - val_mean_squared_error: 4.2776 - val_mean_absolute_error: 1.6276\n",
      "Epoch 81/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9491 - mean_squared_error: 3.9491 - mean_absolute_error: 1.5684 - val_loss: 4.2785 - val_mean_squared_error: 4.2785 - val_mean_absolute_error: 1.6265\n",
      "Epoch 82/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9487 - mean_squared_error: 3.9487 - mean_absolute_error: 1.5667 - val_loss: 4.2796 - val_mean_squared_error: 4.2796 - val_mean_absolute_error: 1.6252\n",
      "Epoch 83/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9483 - mean_squared_error: 3.9483 - mean_absolute_error: 1.5650 - val_loss: 4.2805 - val_mean_squared_error: 4.2805 - val_mean_absolute_error: 1.6242\n",
      "Epoch 84/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9479 - mean_squared_error: 3.9479 - mean_absolute_error: 1.5636 - val_loss: 4.2815 - val_mean_squared_error: 4.2815 - val_mean_absolute_error: 1.6231\n",
      "Epoch 85/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9476 - mean_squared_error: 3.9476 - mean_absolute_error: 1.5621 - val_loss: 4.2824 - val_mean_squared_error: 4.2824 - val_mean_absolute_error: 1.6221\n",
      "Epoch 86/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9473 - mean_squared_error: 3.9473 - mean_absolute_error: 1.5607 - val_loss: 4.2835 - val_mean_squared_error: 4.2835 - val_mean_absolute_error: 1.6209\n",
      "Epoch 87/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9470 - mean_squared_error: 3.9470 - mean_absolute_error: 1.5596 - val_loss: 4.2842 - val_mean_squared_error: 4.2842 - val_mean_absolute_error: 1.6202\n",
      "Epoch 88/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9468 - mean_squared_error: 3.9468 - mean_absolute_error: 1.5582 - val_loss: 4.2851 - val_mean_squared_error: 4.2851 - val_mean_absolute_error: 1.6193\n",
      "Epoch 89/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9466 - mean_squared_error: 3.9466 - mean_absolute_error: 1.5573 - val_loss: 4.2859 - val_mean_squared_error: 4.2859 - val_mean_absolute_error: 1.6184\n",
      "Epoch 90/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9464 - mean_squared_error: 3.9464 - mean_absolute_error: 1.5561 - val_loss: 4.2867 - val_mean_squared_error: 4.2867 - val_mean_absolute_error: 1.6177\n",
      "Epoch 91/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9463 - mean_squared_error: 3.9463 - mean_absolute_error: 1.5549 - val_loss: 4.2875 - val_mean_squared_error: 4.2875 - val_mean_absolute_error: 1.6169\n",
      "Epoch 92/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9462 - mean_squared_error: 3.9462 - mean_absolute_error: 1.5541 - val_loss: 4.2880 - val_mean_squared_error: 4.2880 - val_mean_absolute_error: 1.6164\n",
      "Epoch 93/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9461 - mean_squared_error: 3.9461 - mean_absolute_error: 1.5531 - val_loss: 4.2888 - val_mean_squared_error: 4.2888 - val_mean_absolute_error: 1.6157\n",
      "Epoch 94/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9459 - mean_squared_error: 3.9459 - mean_absolute_error: 1.5526 - val_loss: 4.2893 - val_mean_squared_error: 4.2893 - val_mean_absolute_error: 1.6152\n",
      "Epoch 95/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9458 - mean_squared_error: 3.9458 - mean_absolute_error: 1.5516 - val_loss: 4.2900 - val_mean_squared_error: 4.2900 - val_mean_absolute_error: 1.6145\n",
      "Epoch 96/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9457 - mean_squared_error: 3.9457 - mean_absolute_error: 1.5510 - val_loss: 4.2906 - val_mean_squared_error: 4.2906 - val_mean_absolute_error: 1.6140\n",
      "Epoch 97/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9457 - mean_squared_error: 3.9457 - mean_absolute_error: 1.5505 - val_loss: 4.2912 - val_mean_squared_error: 4.2912 - val_mean_absolute_error: 1.6135\n",
      "Epoch 98/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9456 - mean_squared_error: 3.9456 - mean_absolute_error: 1.5496 - val_loss: 4.2917 - val_mean_squared_error: 4.2917 - val_mean_absolute_error: 1.6130\n",
      "Epoch 99/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9455 - mean_squared_error: 3.9455 - mean_absolute_error: 1.5489 - val_loss: 4.2922 - val_mean_squared_error: 4.2922 - val_mean_absolute_error: 1.6126\n",
      "Epoch 100/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9455 - mean_squared_error: 3.9455 - mean_absolute_error: 1.5484 - val_loss: 4.2926 - val_mean_squared_error: 4.2926 - val_mean_absolute_error: 1.6122\n",
      "Epoch 101/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9455 - mean_squared_error: 3.9455 - mean_absolute_error: 1.5478 - val_loss: 4.2931 - val_mean_squared_error: 4.2931 - val_mean_absolute_error: 1.6118\n",
      "Epoch 102/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9454 - mean_squared_error: 3.9454 - mean_absolute_error: 1.5475 - val_loss: 4.2934 - val_mean_squared_error: 4.2934 - val_mean_absolute_error: 1.6115\n",
      "Epoch 103/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9454 - mean_squared_error: 3.9454 - mean_absolute_error: 1.5469 - val_loss: 4.2939 - val_mean_squared_error: 4.2939 - val_mean_absolute_error: 1.6111\n",
      "Epoch 104/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9454 - mean_squared_error: 3.9454 - mean_absolute_error: 1.5467 - val_loss: 4.2942 - val_mean_squared_error: 4.2942 - val_mean_absolute_error: 1.6109\n",
      "Epoch 105/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9454 - mean_squared_error: 3.9454 - mean_absolute_error: 1.5461 - val_loss: 4.2946 - val_mean_squared_error: 4.2946 - val_mean_absolute_error: 1.6105\n",
      "Epoch 106/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5459 - val_loss: 4.2946 - val_mean_squared_error: 4.2946 - val_mean_absolute_error: 1.6105\n",
      "Epoch 107/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5455 - val_loss: 4.2951 - val_mean_squared_error: 4.2951 - val_mean_absolute_error: 1.6101\n",
      "Epoch 108/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5454 - val_loss: 4.2953 - val_mean_squared_error: 4.2953 - val_mean_absolute_error: 1.6099\n",
      "Epoch 109/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5451 - val_loss: 4.2955 - val_mean_squared_error: 4.2955 - val_mean_absolute_error: 1.6098\n",
      "Epoch 110/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5445 - val_loss: 4.2959 - val_mean_squared_error: 4.2959 - val_mean_absolute_error: 1.6094\n",
      "Epoch 111/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5443 - val_loss: 4.2961 - val_mean_squared_error: 4.2961 - val_mean_absolute_error: 1.6092\n",
      "Epoch 112/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5438 - val_loss: 4.2963 - val_mean_squared_error: 4.2963 - val_mean_absolute_error: 1.6091\n",
      "Epoch 113/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5438 - val_loss: 4.2966 - val_mean_squared_error: 4.2966 - val_mean_absolute_error: 1.6089\n",
      "Epoch 114/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5438 - val_loss: 4.2967 - val_mean_squared_error: 4.2967 - val_mean_absolute_error: 1.6088\n",
      "Epoch 115/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5438 - val_loss: 4.2967 - val_mean_squared_error: 4.2967 - val_mean_absolute_error: 1.6088\n",
      "Epoch 116/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5435 - val_loss: 4.2969 - val_mean_squared_error: 4.2969 - val_mean_absolute_error: 1.6086\n",
      "Epoch 117/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5432 - val_loss: 4.2970 - val_mean_squared_error: 4.2970 - val_mean_absolute_error: 1.6085\n",
      "Epoch 118/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5427 - val_loss: 4.2973 - val_mean_squared_error: 4.2973 - val_mean_absolute_error: 1.6083\n",
      "Epoch 119/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5430 - val_loss: 4.2972 - val_mean_squared_error: 4.2972 - val_mean_absolute_error: 1.6084\n",
      "Epoch 120/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5426 - val_loss: 4.2975 - val_mean_squared_error: 4.2975 - val_mean_absolute_error: 1.6081\n",
      "Epoch 121/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5427 - val_loss: 4.2974 - val_mean_squared_error: 4.2974 - val_mean_absolute_error: 1.6082\n",
      "Epoch 122/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5424 - val_loss: 4.2977 - val_mean_squared_error: 4.2977 - val_mean_absolute_error: 1.6080\n",
      "Epoch 123/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5420 - val_loss: 4.2979 - val_mean_squared_error: 4.2979 - val_mean_absolute_error: 1.6078\n",
      "Epoch 124/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5425 - val_loss: 4.2976 - val_mean_squared_error: 4.2976 - val_mean_absolute_error: 1.6081\n",
      "Epoch 125/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5421 - val_loss: 4.2978 - val_mean_squared_error: 4.2978 - val_mean_absolute_error: 1.6078\n",
      "Epoch 126/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5419 - val_loss: 4.2979 - val_mean_squared_error: 4.2979 - val_mean_absolute_error: 1.6078\n",
      "Epoch 127/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5421 - val_loss: 4.2979 - val_mean_squared_error: 4.2979 - val_mean_absolute_error: 1.6078\n",
      "Epoch 128/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5422 - val_loss: 4.2979 - val_mean_squared_error: 4.2979 - val_mean_absolute_error: 1.6078\n",
      "Epoch 129/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5419 - val_loss: 4.2982 - val_mean_squared_error: 4.2982 - val_mean_absolute_error: 1.6076\n",
      "Epoch 130/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5421 - val_loss: 4.2980 - val_mean_squared_error: 4.2980 - val_mean_absolute_error: 1.6077\n",
      "Epoch 131/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5422 - val_loss: 4.2981 - val_mean_squared_error: 4.2981 - val_mean_absolute_error: 1.6076\n",
      "Epoch 132/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5416 - val_loss: 4.2984 - val_mean_squared_error: 4.2984 - val_mean_absolute_error: 1.6074\n",
      "Epoch 133/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5418 - val_loss: 4.2983 - val_mean_squared_error: 4.2983 - val_mean_absolute_error: 1.6075\n",
      "Epoch 134/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5413 - val_loss: 4.2984 - val_mean_squared_error: 4.2984 - val_mean_absolute_error: 1.6074\n",
      "Epoch 135/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5413 - val_loss: 4.2987 - val_mean_squared_error: 4.2987 - val_mean_absolute_error: 1.6071\n",
      "Epoch 136/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5416 - val_loss: 4.2984 - val_mean_squared_error: 4.2984 - val_mean_absolute_error: 1.6074\n",
      "Epoch 137/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5415 - val_loss: 4.2985 - val_mean_squared_error: 4.2985 - val_mean_absolute_error: 1.6073\n",
      "Epoch 138/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5414 - val_loss: 4.2987 - val_mean_squared_error: 4.2987 - val_mean_absolute_error: 1.6072\n",
      "Epoch 139/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5415 - val_loss: 4.2987 - val_mean_squared_error: 4.2987 - val_mean_absolute_error: 1.6071\n",
      "Epoch 140/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5416 - val_loss: 4.2988 - val_mean_squared_error: 4.2988 - val_mean_absolute_error: 1.6071\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9453 - mean_squared_error: 3.9453 - mean_absolute_error: 1.5408 - val_loss: 4.2990 - val_mean_squared_error: 4.2990 - val_mean_absolute_error: 1.6069\n",
      "Epoch 142/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5413 - val_loss: 4.2988 - val_mean_squared_error: 4.2988 - val_mean_absolute_error: 1.6071\n",
      "Epoch 143/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5412 - val_loss: 4.2987 - val_mean_squared_error: 4.2987 - val_mean_absolute_error: 1.6071\n",
      "Epoch 144/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5414 - val_loss: 4.2985 - val_mean_squared_error: 4.2985 - val_mean_absolute_error: 1.6073\n",
      "Epoch 145/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5410 - val_loss: 4.2989 - val_mean_squared_error: 4.2989 - val_mean_absolute_error: 1.6070\n",
      "Epoch 146/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5410 - val_loss: 4.2989 - val_mean_squared_error: 4.2989 - val_mean_absolute_error: 1.6070\n",
      "Epoch 147/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5412 - val_loss: 4.2986 - val_mean_squared_error: 4.2986 - val_mean_absolute_error: 1.6072\n",
      "Epoch 148/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5414 - val_loss: 4.2985 - val_mean_squared_error: 4.2985 - val_mean_absolute_error: 1.6073\n",
      "Epoch 149/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5413 - val_loss: 4.2986 - val_mean_squared_error: 4.2986 - val_mean_absolute_error: 1.6072\n",
      "Epoch 150/150\n",
      "7855/7855 [==============================] - 10s 1ms/step - loss: 3.9452 - mean_squared_error: 3.9452 - mean_absolute_error: 1.5415 - val_loss: 4.2987 - val_mean_squared_error: 4.2987 - val_mean_absolute_error: 1.6072\n",
      "EndTime : 2019-05-12 14:19:58.994000\n"
     ]
    }
   ],
   "source": [
    "StartTime8 = datetime.now()\n",
    "print(\"StartTime :\", StartTime8)\n",
    "with K.tf.device('/GPU:0'):\n",
    "    model_train = model.fit(train_X, training_label_array, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                        validation_data=(test_X, test_label_array))\n",
    "\n",
    "EndTime8 = datetime.now()\n",
    "print(\"EndTime :\", EndTime8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"E://Ronny_TF//Ronny_IC50_RMSE//method_comparison//deepIC50v2like_mut_drug\"\n",
    "# Option 1: Save Weights + Architecture\n",
    "model.save_weights(workdir+ '//model_fix_v3.h5')\n",
    "with open(workdir + '//model_architecture_fix_v3.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "# Option 1: Load Weights + Architecture\n",
    "# with open('model_architecture.json', 'r') as f:\n",
    "#     new_model_1 = model_from_json(f.read())\n",
    "# new_model_1.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Save/Load the Entire Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save(workdir + '//model_fix_2080ti_v3.h5')\n",
    "\n",
    "# Deletes the existing model\n",
    "# del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872/872 [==============================] - 1s 579us/step\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(test_X, test_label_array, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.298693649265744, 4.298693649265744, 1.6071542709245594]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['mean_squared_error']\n",
    "val_accuracy = model_train.history['val_mean_squared_error']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "\n",
    "np_acc = np.array(accuracy)\n",
    "np_val_acc = np.array(val_accuracy)\n",
    "np_loss = np.array(loss)\n",
    "np_val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"190511_deep_ic50like_mut_drug_acc_cls3_fix_2080ti_v3.csv\", np_acc, delimiter=\",\")\n",
    "np.savetxt(\"190511_deep_ic50like_mut_drug_val_acc_cls3_fix_2080ti_v3.csv\", np_val_acc, delimiter=\",\")\n",
    "np.savetxt(\"190511_deep_ic50like_mut_drug_loss_cls3_fix_2080ti_v3.csv\", np_loss, delimiter=\",\")\n",
    "np.savetxt(\"190511_deep_ic50like_mut_drug_val_loss_cls3_fix_2080ti_v3.csv\", np_val_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy = model_train.history['acc']\n",
    "# val_accuracy = model_train.history['val_acc']\n",
    "# loss = model_train.history['loss']\n",
    "# val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training mse')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation mse')\n",
    "plt.title('Training and validation mse')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(workdir + '//mse_loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_label_array)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(workdir + '//190511_deepic50v2_like_mut_drug_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.941970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.225864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-4.869996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-0.246987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.729042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.510771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-0.252917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.076232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.996950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-2.794141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-0.518891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-3.814410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-0.090420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-5.388595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.570184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-0.988193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.251442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-0.294071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-0.788214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-4.513064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.791661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.873937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>-1.710367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.596290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.816348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>1.499250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.862872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.570138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted      Test\n",
       "0     0.883288  0.941970\n",
       "1     0.883288  0.225864\n",
       "2     0.883288  1.677600\n",
       "3     0.883288 -4.869996\n",
       "4     0.883288 -0.246987\n",
       "5     0.883288  1.729042\n",
       "6     0.883288  2.079442\n",
       "7     0.883288  1.510771\n",
       "8     0.883288  2.079442\n",
       "9     0.883288  2.079442\n",
       "10    0.883288 -0.252917\n",
       "11    0.883288  1.076232\n",
       "12    0.883288  0.996950\n",
       "13    0.883288  2.079442\n",
       "14    0.883288 -2.794141\n",
       "15    0.883288  2.079442\n",
       "16    0.883288 -0.518891\n",
       "17    0.883288  2.079442\n",
       "18    0.883288 -3.814410\n",
       "19    0.883288 -0.090420\n",
       "20    0.883288  2.079442\n",
       "21    0.883288  2.079442\n",
       "22    0.883288  2.079442\n",
       "23    0.883288 -5.388595\n",
       "24    0.883288  2.079442\n",
       "25    0.883288  2.079442\n",
       "26    0.883288  0.570184\n",
       "27    0.883288 -0.988193\n",
       "28    0.883288  0.251442\n",
       "29    0.883288 -0.294071\n",
       "..         ...       ...\n",
       "842   0.883288  2.079442\n",
       "843   0.883288  1.294400\n",
       "844   0.883288 -0.788214\n",
       "845   0.883288 -4.513064\n",
       "846   0.883288  1.791661\n",
       "847   0.883288  2.079442\n",
       "848   0.883288  2.079442\n",
       "849   0.883288  2.079442\n",
       "850   0.883288  1.873937\n",
       "851   0.883288  2.079442\n",
       "852   0.883288  2.079442\n",
       "853   0.883288  2.079442\n",
       "854   0.883288  2.079442\n",
       "855   0.883288  2.079442\n",
       "856   0.883288 -1.710367\n",
       "857   0.883288  2.079442\n",
       "858   0.883288  1.596290\n",
       "859   0.883288  2.079442\n",
       "860   0.883288  2.079442\n",
       "861   0.883288  2.079442\n",
       "862   0.883288  2.079442\n",
       "863   0.883288  1.816348\n",
       "864   0.883288  2.079442\n",
       "865   0.883288  1.499250\n",
       "866   0.883288  0.862872\n",
       "867   0.883288  0.570138\n",
       "868   0.883288  2.079442\n",
       "869   0.883288  2.079442\n",
       "870   0.883288  2.079442\n",
       "871   0.883288  2.079442\n",
       "\n",
       "[872 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_label_array,predicted_value,c='blue')\n",
    "plt.xlabel('test_IC50_value')\n",
    "plt.ylabel('predicted_IC50_value')\n",
    "plt.savefig(workdir + '//190511_deepic50_like_mut_drug_info_test_scatterplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rmse value is = 2.0733291431090093\n"
     ]
    }
   ],
   "source": [
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
