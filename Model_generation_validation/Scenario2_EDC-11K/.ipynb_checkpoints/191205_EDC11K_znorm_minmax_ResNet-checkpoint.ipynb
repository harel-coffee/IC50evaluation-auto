{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "workdir = \"E://Ronny_TF//DrugResponsivenessGuidelines//Experiments//191205_rerun//ResNet//Dataset//EDC11K_Znorm\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5862985973200739500\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 18038862643\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2145781590978971121\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "# 출처: https://3months.tistory.com/206 [Deep Play]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(workdir + \"//191204_EDC11K_z_norm_minmax.npz\")\n",
    "ss0 = np.load(workdir + '//191204_EDC11K_z_norm_minmax_r0_9_1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['x']\n",
    "y = dataset['y']\n",
    "# y_linear = dataset['y_lnIC50']\n",
    "ss0_train = ss0['train']\n",
    "ss0_test = ss0['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_array, training_label_array = x[ss0_train], y[ss0_train]\n",
    "test_image_array, test_label_array = x[ss0_test], y[ss0_test]\n",
    "\n",
    "# # In[9]:\n",
    "# ori = training_image_array\n",
    "# bat = np.zeros((ori.shape[0],178))\n",
    "# cat = np.hstack([ori,bat])\n",
    "# training_image_array = cat\n",
    "\n",
    "# # In[8]:\n",
    "# training_image_array.shape\n",
    "\n",
    "# # In[10]:\n",
    "# ori2 = test_image_array\n",
    "# bat2 = np.zeros((ori2.shape[0],178))\n",
    "# cat2 = np.hstack([ori2,bat2])\n",
    "# test_image_array = cat2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42\n"
     ]
    }
   ],
   "source": [
    "# In[15]:\n",
    "ab =[]\n",
    "for i in range(100,300):\n",
    "    ab.append(len(training_image_array) % i)\n",
    "    \n",
    "print(min(ab), ab.index(min(ab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11360, 21313)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10224, 21313)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[21]:\n",
    "\n",
    "num_classes = 1\n",
    "learning_rate = 0.0002\n",
    "training_epochs = 150\n",
    "batch_size = 100\n",
    "# img_rows, img_cols = 154, 154\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = training_image_array, training_label_array, test_image_array, test_label_array\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     train_X = train_X.reshape(train_X.shape[0], 1, img_rows, img_cols)\n",
    "#     test_X = test_X.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "# else:\n",
    "#     train_X = train_X.reshape(train_X.shape[0], img_rows, img_cols, 1)\n",
    "#     test_X = test_X.reshape(test_X.shape[0], img_rows, img_cols, 1)\n",
    "#     input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1],1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1],1)\n",
    "#input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10224, 21313, 1) (10224,) (1136, 21313, 1) (1136,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (10224, 21313, 1)\n",
      "10224 train samples\n",
      "1136 test samples\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "# train_X /= 255\n",
    "# test_X /= 255\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10224, 21313)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ronnytf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ronnytf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 21313, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 10657, 16)    64          inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 2131, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2131, 16)     64          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2131, 16)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2131, 16)     784         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2131, 16)     64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2131, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2131, 16)     784         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2131, 16)     64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2131, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2131, 16)     784         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2131, 16)     64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2131, 16)     0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2131, 16)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2131, 16)     784         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2131, 16)     64          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2131, 16)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 2131, 16)     784         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2131, 16)     64          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2131, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2131, 16)     784         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2131, 16)     64          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 2131, 16)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 2131, 16)     784         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2131, 16)     64          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2131, 16)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2131, 16)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1066, 32)     1568        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1066, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1066, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1066, 32)     3104        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1066, 32)     3104        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1066, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1066, 32)     0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1066, 32)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1066, 32)     3104        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1066, 32)     128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1066, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1066, 32)     3104        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1066, 32)     128         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1066, 32)     0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1066, 32)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1066, 32)     3104        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1066, 32)     128         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1066, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1066, 32)     3104        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1066, 32)     128         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1066, 32)     0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1066, 32)     0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 533, 64)      6208        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 533, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 533, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 533, 64)      12352       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 533, 64)      12352       conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 533, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 533, 64)      0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 533, 64)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 533, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 533, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 533, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 533, 64)      12352       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 533, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 533, 64)      0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 533, 64)      0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 533, 64)      12352       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 533, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 533, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 533, 64)      12352       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 533, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 533, 64)      0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 533, 64)      0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 34112)        0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 2048)         69863424    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2048)         8192        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 2048)         0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2048)         0           dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense5 (Dense)                  (None, 1024)         2098176     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1024)         4096        dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout5 (Dropout)              (None, 1024)         0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1024)         0           dropout5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense6 (Dense)                  (None, 512)          524800      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512)          2048        dense6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout6 (Dropout)              (None, 512)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512)          0           dropout6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense7 (Dense)                  (None, 1024)         525312      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1024)         4096        dense7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout7 (Dropout)              (None, 1024)         0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1024)         0           dropout7[0][0]                   \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1024)         0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense8 (Dense)                  (None, 512)          524800      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 512)          2048        dense8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout8 (Dropout)              (None, 512)          0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512)          0           dropout8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense9 (Dense)                  (None, 256)          131328      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256)          1024        dense9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout9 (Dropout)              (None, 256)          0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256)          0           dropout9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense10 (Dense)                 (None, 128)          32896       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128)          512         dense10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout10 (Dropout)             (None, 128)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128)          0           dropout10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            129         activation_27[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 73,831,761\n",
      "Trainable params: 73,819,345\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# In[10]:\n",
    "with K.tf.device('/GPU:0'):\n",
    "    inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     y = x\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#     x = AveragePooling1D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=2048, name='dense1'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout1') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#    x = Reshape((300,1))(x)\n",
    "\n",
    "#    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "#    x = MaxPooling1D(pool_size=2)(x)\n",
    "#    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense5'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout5') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=512, name='dense6'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout6') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense7'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout7') (x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=512, name='dense8'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout8') (x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=256, name='dense9'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout9') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=128, name='dense10'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout10') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "#     predictions = Dense(1, activation='linear', name='predictions')(x)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN20190327')\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                  metrics=['mse','mae'])\n",
    "\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2019-12-05 14:50:54.489000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ronnytf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10224 samples, validate on 1136 samples\n",
      "Epoch 1/150\n",
      "10224/10224 [==============================] - 22s 2ms/step - loss: 4.7099 - mean_squared_error: 4.7099 - mean_absolute_error: 1.9709 - val_loss: 4.7448 - val_mean_squared_error: 4.7448 - val_mean_absolute_error: 1.9670\n",
      "Epoch 2/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.6765 - mean_squared_error: 4.6765 - mean_absolute_error: 1.9603 - val_loss: 4.7130 - val_mean_squared_error: 4.7130 - val_mean_absolute_error: 1.9564\n",
      "Epoch 3/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.6443 - mean_squared_error: 4.6443 - mean_absolute_error: 1.9500 - val_loss: 4.6825 - val_mean_squared_error: 4.6825 - val_mean_absolute_error: 1.9460\n",
      "Epoch 4/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.6131 - mean_squared_error: 4.6131 - mean_absolute_error: 1.9397 - val_loss: 4.6530 - val_mean_squared_error: 4.6530 - val_mean_absolute_error: 1.9359\n",
      "Epoch 5/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.5831 - mean_squared_error: 4.5831 - mean_absolute_error: 1.9296 - val_loss: 4.6244 - val_mean_squared_error: 4.6244 - val_mean_absolute_error: 1.9258\n",
      "Epoch 6/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.5543 - mean_squared_error: 4.5543 - mean_absolute_error: 1.9196 - val_loss: 4.5973 - val_mean_squared_error: 4.5973 - val_mean_absolute_error: 1.9160\n",
      "Epoch 7/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.5266 - mean_squared_error: 4.5266 - mean_absolute_error: 1.9098 - val_loss: 4.5710 - val_mean_squared_error: 4.5710 - val_mean_absolute_error: 1.9063\n",
      "Epoch 8/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.4998 - mean_squared_error: 4.4998 - mean_absolute_error: 1.9004 - val_loss: 4.5459 - val_mean_squared_error: 4.5459 - val_mean_absolute_error: 1.8967\n",
      "Epoch 9/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.4740 - mean_squared_error: 4.4740 - mean_absolute_error: 1.8909 - val_loss: 4.5214 - val_mean_squared_error: 4.5214 - val_mean_absolute_error: 1.8872\n",
      "Epoch 10/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.4491 - mean_squared_error: 4.4491 - mean_absolute_error: 1.8816 - val_loss: 4.4982 - val_mean_squared_error: 4.4982 - val_mean_absolute_error: 1.8780\n",
      "Epoch 11/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.4252 - mean_squared_error: 4.4252 - mean_absolute_error: 1.8725 - val_loss: 4.4756 - val_mean_squared_error: 4.4756 - val_mean_absolute_error: 1.8687\n",
      "Epoch 12/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.4021 - mean_squared_error: 4.4021 - mean_absolute_error: 1.8634 - val_loss: 4.4539 - val_mean_squared_error: 4.4539 - val_mean_absolute_error: 1.8597\n",
      "Epoch 13/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.3798 - mean_squared_error: 4.3798 - mean_absolute_error: 1.8545 - val_loss: 4.4329 - val_mean_squared_error: 4.4329 - val_mean_absolute_error: 1.8507\n",
      "Epoch 14/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.3586 - mean_squared_error: 4.3586 - mean_absolute_error: 1.8458 - val_loss: 4.4131 - val_mean_squared_error: 4.4131 - val_mean_absolute_error: 1.8420\n",
      "Epoch 15/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.3382 - mean_squared_error: 4.3382 - mean_absolute_error: 1.8372 - val_loss: 4.3942 - val_mean_squared_error: 4.3942 - val_mean_absolute_error: 1.8335\n",
      "Epoch 16/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.3185 - mean_squared_error: 4.3185 - mean_absolute_error: 1.8287 - val_loss: 4.3757 - val_mean_squared_error: 4.3757 - val_mean_absolute_error: 1.8249\n",
      "Epoch 17/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.2995 - mean_squared_error: 4.2995 - mean_absolute_error: 1.8202 - val_loss: 4.3579 - val_mean_squared_error: 4.3579 - val_mean_absolute_error: 1.8164\n",
      "Epoch 18/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.2813 - mean_squared_error: 4.2813 - mean_absolute_error: 1.8120 - val_loss: 4.3410 - val_mean_squared_error: 4.3410 - val_mean_absolute_error: 1.8082\n",
      "Epoch 19/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.2639 - mean_squared_error: 4.2639 - mean_absolute_error: 1.8040 - val_loss: 4.3250 - val_mean_squared_error: 4.3250 - val_mean_absolute_error: 1.8002\n",
      "Epoch 20/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.2473 - mean_squared_error: 4.2473 - mean_absolute_error: 1.7960 - val_loss: 4.3096 - val_mean_squared_error: 4.3096 - val_mean_absolute_error: 1.7922\n",
      "Epoch 21/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.2314 - mean_squared_error: 4.2314 - mean_absolute_error: 1.7882 - val_loss: 4.2948 - val_mean_squared_error: 4.2948 - val_mean_absolute_error: 1.7843\n",
      "Epoch 22/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.2161 - mean_squared_error: 4.2161 - mean_absolute_error: 1.7805 - val_loss: 4.2809 - val_mean_squared_error: 4.2809 - val_mean_absolute_error: 1.7766\n",
      "Epoch 23/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.2016 - mean_squared_error: 4.2016 - mean_absolute_error: 1.7729 - val_loss: 4.2674 - val_mean_squared_error: 4.2674 - val_mean_absolute_error: 1.7690\n",
      "Epoch 24/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1877 - mean_squared_error: 4.1877 - mean_absolute_error: 1.7655 - val_loss: 4.2548 - val_mean_squared_error: 4.2548 - val_mean_absolute_error: 1.7617\n",
      "Epoch 25/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1744 - mean_squared_error: 4.1744 - mean_absolute_error: 1.7581 - val_loss: 4.2425 - val_mean_squared_error: 4.2425 - val_mean_absolute_error: 1.7544\n",
      "Epoch 26/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1617 - mean_squared_error: 4.1617 - mean_absolute_error: 1.7511 - val_loss: 4.2311 - val_mean_squared_error: 4.2311 - val_mean_absolute_error: 1.7474\n",
      "Epoch 27/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1497 - mean_squared_error: 4.1497 - mean_absolute_error: 1.7440 - val_loss: 4.2201 - val_mean_squared_error: 4.2201 - val_mean_absolute_error: 1.7404\n",
      "Epoch 28/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1383 - mean_squared_error: 4.1383 - mean_absolute_error: 1.7369 - val_loss: 4.2096 - val_mean_squared_error: 4.2096 - val_mean_absolute_error: 1.7334\n",
      "Epoch 29/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1273 - mean_squared_error: 4.1273 - mean_absolute_error: 1.7302 - val_loss: 4.1998 - val_mean_squared_error: 4.1998 - val_mean_absolute_error: 1.7267\n",
      "Epoch 30/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1168 - mean_squared_error: 4.1168 - mean_absolute_error: 1.7236 - val_loss: 4.1904 - val_mean_squared_error: 4.1904 - val_mean_absolute_error: 1.7201\n",
      "Epoch 31/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.1070 - mean_squared_error: 4.1070 - mean_absolute_error: 1.7170 - val_loss: 4.1816 - val_mean_squared_error: 4.1816 - val_mean_absolute_error: 1.7136\n",
      "Epoch 32/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0976 - mean_squared_error: 4.0976 - mean_absolute_error: 1.7106 - val_loss: 4.1733 - val_mean_squared_error: 4.1733 - val_mean_absolute_error: 1.7073\n",
      "Epoch 33/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0888 - mean_squared_error: 4.0888 - mean_absolute_error: 1.7042 - val_loss: 4.1654 - val_mean_squared_error: 4.1654 - val_mean_absolute_error: 1.7011\n",
      "Epoch 34/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0805 - mean_squared_error: 4.0805 - mean_absolute_error: 1.6981 - val_loss: 4.1582 - val_mean_squared_error: 4.1582 - val_mean_absolute_error: 1.6952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "10224/10224 [==============================] - 13s 1ms/step - loss: 4.0728 - mean_squared_error: 4.0728 - mean_absolute_error: 1.6921 - val_loss: 4.1514 - val_mean_squared_error: 4.1514 - val_mean_absolute_error: 1.6894\n",
      "Epoch 36/150\n",
      "10224/10224 [==============================] - 13s 1ms/step - loss: 4.0655 - mean_squared_error: 4.0655 - mean_absolute_error: 1.6862 - val_loss: 4.1449 - val_mean_squared_error: 4.1449 - val_mean_absolute_error: 1.6837\n",
      "Epoch 37/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0588 - mean_squared_error: 4.0588 - mean_absolute_error: 1.6806 - val_loss: 4.1390 - val_mean_squared_error: 4.1390 - val_mean_absolute_error: 1.6782\n",
      "Epoch 38/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0524 - mean_squared_error: 4.0524 - mean_absolute_error: 1.6750 - val_loss: 4.1336 - val_mean_squared_error: 4.1336 - val_mean_absolute_error: 1.6729\n",
      "Epoch 39/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0465 - mean_squared_error: 4.0465 - mean_absolute_error: 1.6697 - val_loss: 4.1284 - val_mean_squared_error: 4.1284 - val_mean_absolute_error: 1.6676\n",
      "Epoch 40/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0409 - mean_squared_error: 4.0409 - mean_absolute_error: 1.6644 - val_loss: 4.1238 - val_mean_squared_error: 4.1238 - val_mean_absolute_error: 1.6626\n",
      "Epoch 41/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0357 - mean_squared_error: 4.0357 - mean_absolute_error: 1.6593 - val_loss: 4.1193 - val_mean_squared_error: 4.1193 - val_mean_absolute_error: 1.6576\n",
      "Epoch 42/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0309 - mean_squared_error: 4.0309 - mean_absolute_error: 1.6542 - val_loss: 4.1154 - val_mean_squared_error: 4.1154 - val_mean_absolute_error: 1.6529\n",
      "Epoch 43/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0265 - mean_squared_error: 4.0265 - mean_absolute_error: 1.6493 - val_loss: 4.1117 - val_mean_squared_error: 4.1117 - val_mean_absolute_error: 1.6482\n",
      "Epoch 44/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0223 - mean_squared_error: 4.0223 - mean_absolute_error: 1.6445 - val_loss: 4.1080 - val_mean_squared_error: 4.1080 - val_mean_absolute_error: 1.6433\n",
      "Epoch 45/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0185 - mean_squared_error: 4.0185 - mean_absolute_error: 1.6398 - val_loss: 4.1051 - val_mean_squared_error: 4.1051 - val_mean_absolute_error: 1.6391\n",
      "Epoch 46/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0149 - mean_squared_error: 4.0149 - mean_absolute_error: 1.6357 - val_loss: 4.1023 - val_mean_squared_error: 4.1023 - val_mean_absolute_error: 1.6348\n",
      "Epoch 47/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0117 - mean_squared_error: 4.0117 - mean_absolute_error: 1.6313 - val_loss: 4.0997 - val_mean_squared_error: 4.0997 - val_mean_absolute_error: 1.6306\n",
      "Epoch 48/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0088 - mean_squared_error: 4.0088 - mean_absolute_error: 1.6272 - val_loss: 4.0974 - val_mean_squared_error: 4.0974 - val_mean_absolute_error: 1.6266\n",
      "Epoch 49/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0062 - mean_squared_error: 4.0062 - mean_absolute_error: 1.6232 - val_loss: 4.0953 - val_mean_squared_error: 4.0953 - val_mean_absolute_error: 1.6225\n",
      "Epoch 50/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0037 - mean_squared_error: 4.0037 - mean_absolute_error: 1.6191 - val_loss: 4.0935 - val_mean_squared_error: 4.0935 - val_mean_absolute_error: 1.6189\n",
      "Epoch 51/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 4.0016 - mean_squared_error: 4.0016 - mean_absolute_error: 1.6157 - val_loss: 4.0919 - val_mean_squared_error: 4.0919 - val_mean_absolute_error: 1.6154\n",
      "Epoch 52/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9996 - mean_squared_error: 3.9996 - mean_absolute_error: 1.6120 - val_loss: 4.0904 - val_mean_squared_error: 4.0904 - val_mean_absolute_error: 1.6119\n",
      "Epoch 53/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9978 - mean_squared_error: 3.9978 - mean_absolute_error: 1.6086 - val_loss: 4.0892 - val_mean_squared_error: 4.0892 - val_mean_absolute_error: 1.6089\n",
      "Epoch 54/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9963 - mean_squared_error: 3.9963 - mean_absolute_error: 1.6055 - val_loss: 4.0882 - val_mean_squared_error: 4.0882 - val_mean_absolute_error: 1.6058\n",
      "Epoch 55/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9948 - mean_squared_error: 3.9948 - mean_absolute_error: 1.6023 - val_loss: 4.0872 - val_mean_squared_error: 4.0872 - val_mean_absolute_error: 1.6028\n",
      "Epoch 56/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9935 - mean_squared_error: 3.9935 - mean_absolute_error: 1.5992 - val_loss: 4.0863 - val_mean_squared_error: 4.0863 - val_mean_absolute_error: 1.5998\n",
      "Epoch 57/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9924 - mean_squared_error: 3.9924 - mean_absolute_error: 1.5965 - val_loss: 4.0856 - val_mean_squared_error: 4.0856 - val_mean_absolute_error: 1.5972\n",
      "Epoch 58/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9915 - mean_squared_error: 3.9915 - mean_absolute_error: 1.5937 - val_loss: 4.0851 - val_mean_squared_error: 4.0851 - val_mean_absolute_error: 1.5947\n",
      "Epoch 59/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9906 - mean_squared_error: 3.9906 - mean_absolute_error: 1.5914 - val_loss: 4.0846 - val_mean_squared_error: 4.0846 - val_mean_absolute_error: 1.5924\n",
      "Epoch 60/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9898 - mean_squared_error: 3.9898 - mean_absolute_error: 1.5890 - val_loss: 4.0842 - val_mean_squared_error: 4.0842 - val_mean_absolute_error: 1.5901\n",
      "Epoch 61/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9892 - mean_squared_error: 3.9892 - mean_absolute_error: 1.5868 - val_loss: 4.0838 - val_mean_squared_error: 4.0838 - val_mean_absolute_error: 1.5878\n",
      "Epoch 62/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9886 - mean_squared_error: 3.9886 - mean_absolute_error: 1.5847 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5859\n",
      "Epoch 63/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9881 - mean_squared_error: 3.9881 - mean_absolute_error: 1.5830 - val_loss: 4.0833 - val_mean_squared_error: 4.0833 - val_mean_absolute_error: 1.5843\n",
      "Epoch 64/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9877 - mean_squared_error: 3.9877 - mean_absolute_error: 1.5810 - val_loss: 4.0832 - val_mean_squared_error: 4.0832 - val_mean_absolute_error: 1.5823\n",
      "Epoch 65/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9874 - mean_squared_error: 3.9874 - mean_absolute_error: 1.5793 - val_loss: 4.0831 - val_mean_squared_error: 4.0831 - val_mean_absolute_error: 1.5808\n",
      "Epoch 66/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9871 - mean_squared_error: 3.9871 - mean_absolute_error: 1.5777 - val_loss: 4.0830 - val_mean_squared_error: 4.0830 - val_mean_absolute_error: 1.5794\n",
      "Epoch 67/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9868 - mean_squared_error: 3.9868 - mean_absolute_error: 1.5764 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5781\n",
      "Epoch 68/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9866 - mean_squared_error: 3.9866 - mean_absolute_error: 1.5750 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5768\n",
      "Epoch 69/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9864 - mean_squared_error: 3.9864 - mean_absolute_error: 1.5741 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5756\n",
      "Epoch 70/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9863 - mean_squared_error: 3.9863 - mean_absolute_error: 1.5727 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5745\n",
      "Epoch 71/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9862 - mean_squared_error: 3.9862 - mean_absolute_error: 1.5715 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5736\n",
      "Epoch 72/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9861 - mean_squared_error: 3.9861 - mean_absolute_error: 1.5711 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5725\n",
      "Epoch 73/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9859 - mean_squared_error: 3.9859 - mean_absolute_error: 1.5699 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5718\n",
      "Epoch 74/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9858 - mean_squared_error: 3.9858 - mean_absolute_error: 1.5687 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.5709\n",
      "Epoch 75/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9858 - mean_squared_error: 3.9858 - mean_absolute_error: 1.5680 - val_loss: 4.0830 - val_mean_squared_error: 4.0830 - val_mean_absolute_error: 1.5703\n",
      "Epoch 76/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9857 - mean_squared_error: 3.9857 - mean_absolute_error: 1.5669 - val_loss: 4.0830 - val_mean_squared_error: 4.0830 - val_mean_absolute_error: 1.5692\n",
      "Epoch 77/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9857 - mean_squared_error: 3.9857 - mean_absolute_error: 1.5668 - val_loss: 4.0831 - val_mean_squared_error: 4.0831 - val_mean_absolute_error: 1.5690\n",
      "Epoch 78/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9856 - mean_squared_error: 3.9856 - mean_absolute_error: 1.5664 - val_loss: 4.0831 - val_mean_squared_error: 4.0831 - val_mean_absolute_error: 1.5685\n",
      "Epoch 79/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9856 - mean_squared_error: 3.9856 - mean_absolute_error: 1.5655 - val_loss: 4.0831 - val_mean_squared_error: 4.0831 - val_mean_absolute_error: 1.5677\n",
      "Epoch 80/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9856 - mean_squared_error: 3.9856 - mean_absolute_error: 1.5653 - val_loss: 4.0832 - val_mean_squared_error: 4.0832 - val_mean_absolute_error: 1.5676\n",
      "Epoch 81/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9856 - mean_squared_error: 3.9856 - mean_absolute_error: 1.5645 - val_loss: 4.0832 - val_mean_squared_error: 4.0832 - val_mean_absolute_error: 1.5671\n",
      "Epoch 82/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9856 - mean_squared_error: 3.9856 - mean_absolute_error: 1.5638 - val_loss: 4.0833 - val_mean_squared_error: 4.0833 - val_mean_absolute_error: 1.5662\n",
      "Epoch 83/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5638 - val_loss: 4.0833 - val_mean_squared_error: 4.0833 - val_mean_absolute_error: 1.5663\n",
      "Epoch 84/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5640 - val_loss: 4.0833 - val_mean_squared_error: 4.0833 - val_mean_absolute_error: 1.5662\n",
      "Epoch 85/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5635 - val_loss: 4.0833 - val_mean_squared_error: 4.0833 - val_mean_absolute_error: 1.5661\n",
      "Epoch 86/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5632 - val_loss: 4.0833 - val_mean_squared_error: 4.0833 - val_mean_absolute_error: 1.5657\n",
      "Epoch 87/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5629 - val_loss: 4.0834 - val_mean_squared_error: 4.0834 - val_mean_absolute_error: 1.5655\n",
      "Epoch 88/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5629 - val_loss: 4.0834 - val_mean_squared_error: 4.0834 - val_mean_absolute_error: 1.5653\n",
      "Epoch 89/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5624 - val_loss: 4.0834 - val_mean_squared_error: 4.0834 - val_mean_absolute_error: 1.5649\n",
      "Epoch 90/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5623 - val_loss: 4.0834 - val_mean_squared_error: 4.0834 - val_mean_absolute_error: 1.5650\n",
      "Epoch 91/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5623 - val_loss: 4.0834 - val_mean_squared_error: 4.0834 - val_mean_absolute_error: 1.5648\n",
      "Epoch 92/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5623 - val_loss: 4.0834 - val_mean_squared_error: 4.0834 - val_mean_absolute_error: 1.5648\n",
      "Epoch 93/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5619 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5644\n",
      "Epoch 94/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5621 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5644\n",
      "Epoch 95/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5614 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5641\n",
      "Epoch 96/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5623 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5645\n",
      "Epoch 97/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5616 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5643\n",
      "Epoch 98/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5623 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5646\n",
      "Epoch 99/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5619 - val_loss: 4.0835 - val_mean_squared_error: 4.0835 - val_mean_absolute_error: 1.5641\n",
      "Epoch 100/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 101/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5637\n",
      "Epoch 102/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 103/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5609 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5637\n",
      "Epoch 104/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5633\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0837 - val_mean_squared_error: 4.0837 - val_mean_absolute_error: 1.5630\n",
      "Epoch 106/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5609 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 107/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5607 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 108/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5633\n",
      "Epoch 109/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5605 - val_loss: 4.0837 - val_mean_squared_error: 4.0837 - val_mean_absolute_error: 1.5630\n",
      "Epoch 110/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5606 - val_loss: 4.0837 - val_mean_squared_error: 4.0837 - val_mean_absolute_error: 1.5630\n",
      "Epoch 111/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 112/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5605 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5632\n",
      "Epoch 113/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5606 - val_loss: 4.0837 - val_mean_squared_error: 4.0837 - val_mean_absolute_error: 1.5630\n",
      "Epoch 114/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5603 - val_loss: 4.0837 - val_mean_squared_error: 4.0837 - val_mean_absolute_error: 1.5630\n",
      "Epoch 115/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5611 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 116/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 117/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 118/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 119/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 120/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5607 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5633\n",
      "Epoch 121/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 122/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5608 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5633\n",
      "Epoch 123/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5611 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 124/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 125/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5607 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5632\n",
      "Epoch 126/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5606 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5632\n",
      "Epoch 127/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 128/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5607 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5632\n",
      "Epoch 129/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 130/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 131/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5638\n",
      "Epoch 132/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5611 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 133/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5605 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 134/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5609 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 135/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5606 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 136/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5609 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5635\n",
      "Epoch 137/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5605 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5632\n",
      "Epoch 138/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5609 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5633\n",
      "Epoch 139/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5606 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5632\n",
      "Epoch 140/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5606 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5633\n",
      "Epoch 141/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5613 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5638\n",
      "Epoch 142/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5637\n",
      "Epoch 143/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5607 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 144/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5604 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5633\n",
      "Epoch 145/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 146/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 147/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5612 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 148/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5634\n",
      "Epoch 149/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5636\n",
      "Epoch 150/150\n",
      "10224/10224 [==============================] - 12s 1ms/step - loss: 3.9855 - mean_squared_error: 3.9855 - mean_absolute_error: 1.5610 - val_loss: 4.0836 - val_mean_squared_error: 4.0836 - val_mean_absolute_error: 1.5637\n",
      "EndTime : 2019-12-05 15:20:43.451000\n"
     ]
    }
   ],
   "source": [
    "StartTime8 = datetime.now()\n",
    "print(\"StartTime :\", StartTime8)\n",
    "with K.tf.device('/GPU:0'):\n",
    "    model_train = model.fit(train_X, training_label_array, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                        validation_data=(test_X, test_label_array))\n",
    "\n",
    "EndTime8 = datetime.now()\n",
    "print(\"EndTime :\", EndTime8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"E://Ronny_TF//DrugResponsivenessGuidelines//Experiments//191205_rerun//ResNet//Result//EDC-11K//ResNet\"\n",
    "# Option 1: Save Weights + Architecture\n",
    "model.save_weights(workdir+ '//EDC11K_ResNet_model_fix_v3.h5')\n",
    "with open(workdir + '//EDC11K_ResNet_model_architecture_fix_v3.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "# Option 1: Load Weights + Architecture\n",
    "# with open('model_architecture.json', 'r') as f:\n",
    "#     new_model_1 = model_from_json(f.read())\n",
    "# new_model_1.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Save/Load the Entire Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save(workdir + '//EDC11K_ResNet_model_fix_2080ti_v3.h5')\n",
    "\n",
    "# Deletes the existing model\n",
    "# del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136/1136 [==============================] - 1s 482us/step\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(test_X, test_label_array, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.083572182856815, 4.083572182856815, 1.5637088224921427]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['mean_squared_error']\n",
    "val_accuracy = model_train.history['val_mean_squared_error']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "\n",
    "np_acc = np.array(accuracy)\n",
    "np_val_acc = np.array(val_accuracy)\n",
    "np_loss = np.array(loss)\n",
    "np_val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"EDC11K_ResNet_acc_cls3_fix_2080ti_v3.csv\", np_acc, delimiter=\",\")\n",
    "np.savetxt(\"EDC11K_ResNet_val_acc_cls3_fix_2080ti_v3.csv\", np_val_acc, delimiter=\",\")\n",
    "np.savetxt(\"EDC11K_ResNet_loss_cls3_fix_2080ti_v3.csv\", np_loss, delimiter=\",\")\n",
    "np.savetxt(\"EDC11K_ResNet_val_loss_cls3_fix_2080ti_v3.csv\", np_val_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy = model_train.history['acc']\n",
    "# val_accuracy = model_train.history['val_acc']\n",
    "# loss = model_train.history['loss']\n",
    "# val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training mse')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation mse')\n",
    "plt.title('Training and validation mse')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(workdir + '//EDC11K_ResNet_mse_loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_label_array)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(workdir + '//EDC11K_ResNet_Predicted_test_val_for_plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.393330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>0.308173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.270682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.674144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-1.784149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>0.455815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>0.752405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-0.029018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.413085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.228590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-2.456043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.799557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-1.982132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-3.715987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.224780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-3.079947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>0.713340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>1.641961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-2.171559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>-3.241047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>0.282580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>0.857019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.860245</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted      Test\n",
       "0      0.860245  1.393330\n",
       "1      0.860245  2.079442\n",
       "2      0.860245  0.308173\n",
       "3      0.860245  2.079442\n",
       "4      0.860245  2.079442\n",
       "5      0.860245  1.270682\n",
       "6      0.860245  2.079442\n",
       "7      0.860245  1.674144\n",
       "8      0.860245  2.079442\n",
       "9      0.860245  2.079442\n",
       "10     0.860245  2.079442\n",
       "11     0.860245 -1.784149\n",
       "12     0.860245  0.455815\n",
       "13     0.860245  2.079442\n",
       "14     0.860245  2.079442\n",
       "15     0.860245  2.079442\n",
       "16     0.860245  0.752405\n",
       "17     0.860245  2.079442\n",
       "18     0.860245 -0.029018\n",
       "19     0.860245  1.413085\n",
       "20     0.860245  1.228590\n",
       "21     0.860245  2.079442\n",
       "22     0.860245  2.079442\n",
       "23     0.860245  2.079442\n",
       "24     0.860245 -2.456043\n",
       "25     0.860245  2.079442\n",
       "26     0.860245  1.799557\n",
       "27     0.860245  2.079442\n",
       "28     0.860245 -1.982132\n",
       "29     0.860245 -3.715987\n",
       "...         ...       ...\n",
       "1106   0.860245  2.079442\n",
       "1107   0.860245  1.224780\n",
       "1108   0.860245  2.079442\n",
       "1109   0.860245  2.079442\n",
       "1110   0.860245 -3.079947\n",
       "1111   0.860245  2.079442\n",
       "1112   0.860245  2.079442\n",
       "1113   0.860245  2.079442\n",
       "1114   0.860245  2.079442\n",
       "1115   0.860245  2.079442\n",
       "1116   0.860245  2.079442\n",
       "1117   0.860245  2.079442\n",
       "1118   0.860245  2.079442\n",
       "1119   0.860245  0.713340\n",
       "1120   0.860245  2.079442\n",
       "1121   0.860245  2.079442\n",
       "1122   0.860245  1.641961\n",
       "1123   0.860245  2.079442\n",
       "1124   0.860245 -2.171559\n",
       "1125   0.860245  2.079442\n",
       "1126   0.860245  2.079442\n",
       "1127   0.860245  2.079442\n",
       "1128   0.860245  2.079442\n",
       "1129   0.860245 -3.241047\n",
       "1130   0.860245  2.079442\n",
       "1131   0.860245  2.079442\n",
       "1132   0.860245  2.079442\n",
       "1133   0.860245  0.282580\n",
       "1134   0.860245  0.857019\n",
       "1135   0.860245  2.079442\n",
       "\n",
       "[1136 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1136, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_label_array,predicted_value,c='blue')\n",
    "plt.xlabel('test_IC50_value')\n",
    "plt.ylabel('predicted_IC50_value')\n",
    "plt.savefig(workdir + '//EDC11K_ResNet_test_scatterplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rmse value is = 2.020785038736874\n"
     ]
    }
   ],
   "source": [
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
