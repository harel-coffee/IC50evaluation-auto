{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# input file path\n",
    "workdir = \"E://Ronny_TF//200914_reupload//Dataset//Scenario3_EYDC-9K\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7867321242121240432\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 8267812044\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16097461122789034336\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "# 출처: https://3months.tistory.com/206 [Deep Play]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and index file\n",
    "dataset = np.load(workdir + \"//200914_EYDC9K.npz\")\n",
    "ss0 = np.load(workdir + '//200914_EYDC9K_r0_9_1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and index file assign\n",
    "x = dataset['x']\n",
    "y = dataset['y']\n",
    "# y_linear = dataset['y_lnIC50']\n",
    "ss0_train = ss0['train']\n",
    "ss0_test = ss0['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test dataset assign\n",
    "training_image_array, training_label_array = x[ss0_train], y[ss0_train]\n",
    "test_image_array, test_label_array = x[ss0_test], y[ss0_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9590, 41505)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the size of dataset\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8631, 41505)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the size of training set\n",
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters of this model\n",
    "num_classes = 1\n",
    "learning_rate = 0.0002\n",
    "training_epochs = 150\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = training_image_array, training_label_array, test_image_array, test_label_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shaping for ResNet model\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1],1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1],1)\n",
    "#input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8631, 41505, 1) (8631,) (959, 41505, 1) (959,)\n"
     ]
    }
   ],
   "source": [
    "# data shape\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (8631, 41505, 1)\n",
      "8631 train samples\n",
      "959 test samples\n"
     ]
    }
   ],
   "source": [
    "# defining of data type\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "# train_X /= 255\n",
    "# test_X /= 255\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8631, 41505)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0915 12:32:42.815583  9476 deprecation_wrapper.py:119] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:514: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0915 12:32:42.817535  9476 deprecation_wrapper.py:119] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:71: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0915 12:32:42.818512  9476 deprecation_wrapper.py:119] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4076: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0915 12:32:42.956128  9476 deprecation_wrapper.py:119] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3900: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0915 12:32:43.007857  9476 deprecation_wrapper.py:119] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:130: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0915 12:32:44.402561  9476 deprecation.py:506] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3363: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0915 12:32:44.876895  9476 deprecation_wrapper.py:119] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4123: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0915 12:32:44.896444  9476 deprecation_wrapper.py:119] From c:\\users\\a\\anaconda3\\envs\\tf_gpu_3.6\\lib\\site-packages\\keras\\optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "with K.tf.device('/GPU:0'):\n",
    "    inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     y = x\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#     x = AveragePooling1D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=2048, name='dense1'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout1') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#    x = Reshape((300,1))(x)\n",
    "\n",
    "#    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "#    x = MaxPooling1D(pool_size=2)(x)\n",
    "#    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense5'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout5') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=512, name='dense6'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout6') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense7'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout7') (x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=512, name='dense8'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout8') (x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=256, name='dense9'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout9') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=128, name='dense10'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout10') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "#     predictions = Dense(1, activation='linear', name='predictions')(x)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN20190327')\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                  metrics=['mse','mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 41505, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 20753, 16)    64          inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 4150, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4150, 16)     64          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4150, 16)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4150, 16)     784         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4150, 16)     64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4150, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4150, 16)     784         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4150, 16)     64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4150, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 4150, 16)     784         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4150, 16)     64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4150, 16)     0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 4150, 16)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 4150, 16)     784         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4150, 16)     64          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 4150, 16)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 4150, 16)     784         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4150, 16)     64          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4150, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 4150, 16)     784         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4150, 16)     64          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4150, 16)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 4150, 16)     784         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4150, 16)     64          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4150, 16)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4150, 16)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2075, 32)     1568        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2075, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 2075, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 2075, 32)     3104        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2075, 32)     3104        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2075, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2075, 32)     0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 2075, 32)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 2075, 32)     3104        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2075, 32)     128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2075, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 2075, 32)     3104        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2075, 32)     128         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2075, 32)     0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 2075, 32)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 2075, 32)     3104        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2075, 32)     128         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2075, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 2075, 32)     3104        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2075, 32)     128         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2075, 32)     0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2075, 32)     0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1038, 64)     6208        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1038, 64)     256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1038, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1038, 64)     12352       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1038, 64)     12352       conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1038, 64)     256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1038, 64)     0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1038, 64)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1038, 64)     12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1038, 64)     256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 1038, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1038, 64)     12352       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1038, 64)     256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1038, 64)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1038, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1038, 64)     12352       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 1038, 64)     256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1038, 64)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1038, 64)     12352       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1038, 64)     256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1038, 64)     0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1038, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 66432)        0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 2048)         136054784   flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2048)         8192        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 2048)         0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2048)         0           dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense5 (Dense)                  (None, 1024)         2098176     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1024)         4096        dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout5 (Dropout)              (None, 1024)         0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1024)         0           dropout5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense6 (Dense)                  (None, 512)          524800      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512)          2048        dense6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout6 (Dropout)              (None, 512)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512)          0           dropout6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense7 (Dense)                  (None, 1024)         525312      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1024)         4096        dense7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout7 (Dropout)              (None, 1024)         0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1024)         0           dropout7[0][0]                   \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1024)         0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense8 (Dense)                  (None, 512)          524800      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 512)          2048        dense8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout8 (Dropout)              (None, 512)          0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512)          0           dropout8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense9 (Dense)                  (None, 256)          131328      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256)          1024        dense9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout9 (Dropout)              (None, 256)          0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256)          0           dropout9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense10 (Dense)                 (None, 128)          32896       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128)          512         dense10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout10 (Dropout)             (None, 128)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128)          0           dropout10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            129         activation_27[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 140,023,121\n",
      "Trainable params: 140,010,705\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2020-09-15 12:32:44.948331\n",
      "Train on 8631 samples, validate on 959 samples\n",
      "Epoch 1/150\n",
      "8631/8631 [==============================] - 31s 4ms/step - loss: 4.7291 - mean_squared_error: 4.7291 - mean_absolute_error: 1.9739 - val_loss: 4.6872 - val_mean_squared_error: 4.6872 - val_mean_absolute_error: 1.9673\n",
      "Epoch 2/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.7017 - mean_squared_error: 4.7017 - mean_absolute_error: 1.9651 - val_loss: 4.6579 - val_mean_squared_error: 4.6579 - val_mean_absolute_error: 1.9580\n",
      "Epoch 3/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.6752 - mean_squared_error: 4.6752 - mean_absolute_error: 1.9565 - val_loss: 4.6294 - val_mean_squared_error: 4.6294 - val_mean_absolute_error: 1.9487\n",
      "Epoch 4/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.6493 - mean_squared_error: 4.6493 - mean_absolute_error: 1.9480 - val_loss: 4.6017 - val_mean_squared_error: 4.6017 - val_mean_absolute_error: 1.9396\n",
      "Epoch 5/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.6242 - mean_squared_error: 4.6242 - mean_absolute_error: 1.9395 - val_loss: 4.5747 - val_mean_squared_error: 4.5747 - val_mean_absolute_error: 1.9305\n",
      "Epoch 6/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.5999 - mean_squared_error: 4.5999 - mean_absolute_error: 1.9312 - val_loss: 4.5486 - val_mean_squared_error: 4.5486 - val_mean_absolute_error: 1.9217\n",
      "Epoch 7/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.5764 - mean_squared_error: 4.5764 - mean_absolute_error: 1.9230 - val_loss: 4.5233 - val_mean_squared_error: 4.5233 - val_mean_absolute_error: 1.9129\n",
      "Epoch 8/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.5536 - mean_squared_error: 4.5536 - mean_absolute_error: 1.9149 - val_loss: 4.4987 - val_mean_squared_error: 4.4987 - val_mean_absolute_error: 1.9043\n",
      "Epoch 9/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.5315 - mean_squared_error: 4.5315 - mean_absolute_error: 1.9069 - val_loss: 4.4748 - val_mean_squared_error: 4.4748 - val_mean_absolute_error: 1.8958\n",
      "Epoch 10/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.5101 - mean_squared_error: 4.5101 - mean_absolute_error: 1.8990 - val_loss: 4.4515 - val_mean_squared_error: 4.4515 - val_mean_absolute_error: 1.8874\n",
      "Epoch 11/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.4893 - mean_squared_error: 4.4893 - mean_absolute_error: 1.8912 - val_loss: 4.4290 - val_mean_squared_error: 4.4290 - val_mean_absolute_error: 1.8791\n",
      "Epoch 12/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.4692 - mean_squared_error: 4.4692 - mean_absolute_error: 1.8834 - val_loss: 4.4069 - val_mean_squared_error: 4.4069 - val_mean_absolute_error: 1.8709\n",
      "Epoch 13/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.4498 - mean_squared_error: 4.4498 - mean_absolute_error: 1.8760 - val_loss: 4.3861 - val_mean_squared_error: 4.3861 - val_mean_absolute_error: 1.8631\n",
      "Epoch 14/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.4311 - mean_squared_error: 4.4311 - mean_absolute_error: 1.8684 - val_loss: 4.3655 - val_mean_squared_error: 4.3655 - val_mean_absolute_error: 1.8551\n",
      "Epoch 15/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.4129 - mean_squared_error: 4.4129 - mean_absolute_error: 1.8610 - val_loss: 4.3453 - val_mean_squared_error: 4.3453 - val_mean_absolute_error: 1.8472\n",
      "Epoch 16/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.3954 - mean_squared_error: 4.3954 - mean_absolute_error: 1.8537 - val_loss: 4.3262 - val_mean_squared_error: 4.3262 - val_mean_absolute_error: 1.8396\n",
      "Epoch 17/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.3784 - mean_squared_error: 4.3784 - mean_absolute_error: 1.8466 - val_loss: 4.3077 - val_mean_squared_error: 4.3077 - val_mean_absolute_error: 1.8320\n",
      "Epoch 18/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.3622 - mean_squared_error: 4.3622 - mean_absolute_error: 1.8396 - val_loss: 4.2898 - val_mean_squared_error: 4.2898 - val_mean_absolute_error: 1.8245\n",
      "Epoch 19/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.3464 - mean_squared_error: 4.3464 - mean_absolute_error: 1.8327 - val_loss: 4.2724 - val_mean_squared_error: 4.2724 - val_mean_absolute_error: 1.8171\n",
      "Epoch 20/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.3313 - mean_squared_error: 4.3313 - mean_absolute_error: 1.8258 - val_loss: 4.2557 - val_mean_squared_error: 4.2557 - val_mean_absolute_error: 1.8098\n",
      "Epoch 21/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.3166 - mean_squared_error: 4.3166 - mean_absolute_error: 1.8191 - val_loss: 4.2393 - val_mean_squared_error: 4.2393 - val_mean_absolute_error: 1.8026\n",
      "Epoch 22/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.3024 - mean_squared_error: 4.3024 - mean_absolute_error: 1.8122 - val_loss: 4.2233 - val_mean_squared_error: 4.2233 - val_mean_absolute_error: 1.7954\n",
      "Epoch 23/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.2887 - mean_squared_error: 4.2887 - mean_absolute_error: 1.8056 - val_loss: 4.2082 - val_mean_squared_error: 4.2082 - val_mean_absolute_error: 1.7884\n",
      "Epoch 24/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.2756 - mean_squared_error: 4.2756 - mean_absolute_error: 1.7992 - val_loss: 4.1935 - val_mean_squared_error: 4.1935 - val_mean_absolute_error: 1.7814\n",
      "Epoch 25/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.2630 - mean_squared_error: 4.2630 - mean_absolute_error: 1.7928 - val_loss: 4.1793 - val_mean_squared_error: 4.1793 - val_mean_absolute_error: 1.7746\n",
      "Epoch 26/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.2509 - mean_squared_error: 4.2509 - mean_absolute_error: 1.7865 - val_loss: 4.1655 - val_mean_squared_error: 4.1655 - val_mean_absolute_error: 1.7678\n",
      "Epoch 27/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.2392 - mean_squared_error: 4.2392 - mean_absolute_error: 1.7803 - val_loss: 4.1524 - val_mean_squared_error: 4.1524 - val_mean_absolute_error: 1.7612\n",
      "Epoch 28/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.2280 - mean_squared_error: 4.2280 - mean_absolute_error: 1.7741 - val_loss: 4.1396 - val_mean_squared_error: 4.1396 - val_mean_absolute_error: 1.7547\n",
      "Epoch 29/150\n",
      "8631/8631 [==============================] - 21s 2ms/step - loss: 4.2173 - mean_squared_error: 4.2173 - mean_absolute_error: 1.7681 - val_loss: 4.1273 - val_mean_squared_error: 4.1273 - val_mean_absolute_error: 1.7482\n",
      "Epoch 30/150\n",
      "8631/8631 [==============================] - 21s 2ms/step - loss: 4.2070 - mean_squared_error: 4.2070 - mean_absolute_error: 1.7622 - val_loss: 4.1155 - val_mean_squared_error: 4.1155 - val_mean_absolute_error: 1.7418\n",
      "Epoch 31/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1971 - mean_squared_error: 4.1971 - mean_absolute_error: 1.7564 - val_loss: 4.1043 - val_mean_squared_error: 4.1043 - val_mean_absolute_error: 1.7357\n",
      "Epoch 32/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1876 - mean_squared_error: 4.1876 - mean_absolute_error: 1.7507 - val_loss: 4.0933 - val_mean_squared_error: 4.0933 - val_mean_absolute_error: 1.7295\n",
      "Epoch 33/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1786 - mean_squared_error: 4.1786 - mean_absolute_error: 1.7451 - val_loss: 4.0829 - val_mean_squared_error: 4.0829 - val_mean_absolute_error: 1.7234\n",
      "Epoch 34/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1700 - mean_squared_error: 4.1700 - mean_absolute_error: 1.7395 - val_loss: 4.0727 - val_mean_squared_error: 4.0727 - val_mean_absolute_error: 1.7174\n",
      "Epoch 35/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1616 - mean_squared_error: 4.1616 - mean_absolute_error: 1.7341 - val_loss: 4.0631 - val_mean_squared_error: 4.0631 - val_mean_absolute_error: 1.7116\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1538 - mean_squared_error: 4.1538 - mean_absolute_error: 1.7288 - val_loss: 4.0538 - val_mean_squared_error: 4.0538 - val_mean_absolute_error: 1.7058\n",
      "Epoch 37/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1463 - mean_squared_error: 4.1463 - mean_absolute_error: 1.7235 - val_loss: 4.0448 - val_mean_squared_error: 4.0448 - val_mean_absolute_error: 1.7001\n",
      "Epoch 38/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1391 - mean_squared_error: 4.1391 - mean_absolute_error: 1.7184 - val_loss: 4.0364 - val_mean_squared_error: 4.0364 - val_mean_absolute_error: 1.6946\n",
      "Epoch 39/150\n",
      "8631/8631 [==============================] - 21s 2ms/step - loss: 4.1323 - mean_squared_error: 4.1323 - mean_absolute_error: 1.7132 - val_loss: 4.0280 - val_mean_squared_error: 4.0280 - val_mean_absolute_error: 1.6890\n",
      "Epoch 40/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1259 - mean_squared_error: 4.1259 - mean_absolute_error: 1.7084 - val_loss: 4.0205 - val_mean_squared_error: 4.0205 - val_mean_absolute_error: 1.6839\n",
      "Epoch 41/150\n",
      "8631/8631 [==============================] - 21s 2ms/step - loss: 4.1198 - mean_squared_error: 4.1198 - mean_absolute_error: 1.7037 - val_loss: 4.0130 - val_mean_squared_error: 4.0130 - val_mean_absolute_error: 1.6786\n",
      "Epoch 42/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1140 - mean_squared_error: 4.1140 - mean_absolute_error: 1.6987 - val_loss: 4.0059 - val_mean_squared_error: 4.0059 - val_mean_absolute_error: 1.6735\n",
      "Epoch 43/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1085 - mean_squared_error: 4.1085 - mean_absolute_error: 1.6940 - val_loss: 3.9992 - val_mean_squared_error: 3.9992 - val_mean_absolute_error: 1.6685\n",
      "Epoch 44/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.1033 - mean_squared_error: 4.1033 - mean_absolute_error: 1.6895 - val_loss: 3.9929 - val_mean_squared_error: 3.9929 - val_mean_absolute_error: 1.6637\n",
      "Epoch 45/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0984 - mean_squared_error: 4.0984 - mean_absolute_error: 1.6849 - val_loss: 3.9866 - val_mean_squared_error: 3.9866 - val_mean_absolute_error: 1.6588\n",
      "Epoch 46/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0939 - mean_squared_error: 4.0939 - mean_absolute_error: 1.6804 - val_loss: 3.9807 - val_mean_squared_error: 3.9807 - val_mean_absolute_error: 1.6541\n",
      "Epoch 47/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0895 - mean_squared_error: 4.0895 - mean_absolute_error: 1.6764 - val_loss: 3.9754 - val_mean_squared_error: 3.9754 - val_mean_absolute_error: 1.6497\n",
      "Epoch 48/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0855 - mean_squared_error: 4.0855 - mean_absolute_error: 1.6723 - val_loss: 3.9703 - val_mean_squared_error: 3.9703 - val_mean_absolute_error: 1.6453\n",
      "Epoch 49/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0817 - mean_squared_error: 4.0817 - mean_absolute_error: 1.6682 - val_loss: 3.9654 - val_mean_squared_error: 3.9654 - val_mean_absolute_error: 1.6411\n",
      "Epoch 50/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0782 - mean_squared_error: 4.0782 - mean_absolute_error: 1.6642 - val_loss: 3.9605 - val_mean_squared_error: 3.9605 - val_mean_absolute_error: 1.6366\n",
      "Epoch 51/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0748 - mean_squared_error: 4.0748 - mean_absolute_error: 1.6604 - val_loss: 3.9563 - val_mean_squared_error: 3.9563 - val_mean_absolute_error: 1.6328\n",
      "Epoch 52/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0717 - mean_squared_error: 4.0717 - mean_absolute_error: 1.6566 - val_loss: 3.9521 - val_mean_squared_error: 3.9521 - val_mean_absolute_error: 1.6287\n",
      "Epoch 53/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0688 - mean_squared_error: 4.0688 - mean_absolute_error: 1.6529 - val_loss: 3.9481 - val_mean_squared_error: 3.9481 - val_mean_absolute_error: 1.6247\n",
      "Epoch 54/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0662 - mean_squared_error: 4.0662 - mean_absolute_error: 1.6493 - val_loss: 3.9445 - val_mean_squared_error: 3.9445 - val_mean_absolute_error: 1.6210\n",
      "Epoch 55/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0637 - mean_squared_error: 4.0637 - mean_absolute_error: 1.6460 - val_loss: 3.9412 - val_mean_squared_error: 3.9412 - val_mean_absolute_error: 1.6175\n",
      "Epoch 56/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0615 - mean_squared_error: 4.0615 - mean_absolute_error: 1.6424 - val_loss: 3.9378 - val_mean_squared_error: 3.9378 - val_mean_absolute_error: 1.6137\n",
      "Epoch 57/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0593 - mean_squared_error: 4.0593 - mean_absolute_error: 1.6392 - val_loss: 3.9346 - val_mean_squared_error: 3.9346 - val_mean_absolute_error: 1.6101\n",
      "Epoch 58/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0574 - mean_squared_error: 4.0574 - mean_absolute_error: 1.6361 - val_loss: 3.9320 - val_mean_squared_error: 3.9320 - val_mean_absolute_error: 1.6070\n",
      "Epoch 59/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0556 - mean_squared_error: 4.0556 - mean_absolute_error: 1.6331 - val_loss: 3.9293 - val_mean_squared_error: 3.9293 - val_mean_absolute_error: 1.6037\n",
      "Epoch 60/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0540 - mean_squared_error: 4.0540 - mean_absolute_error: 1.6301 - val_loss: 3.9268 - val_mean_squared_error: 3.9268 - val_mean_absolute_error: 1.6005\n",
      "Epoch 61/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0526 - mean_squared_error: 4.0526 - mean_absolute_error: 1.6274 - val_loss: 3.9245 - val_mean_squared_error: 3.9245 - val_mean_absolute_error: 1.5975\n",
      "Epoch 62/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0512 - mean_squared_error: 4.0512 - mean_absolute_error: 1.6246 - val_loss: 3.9225 - val_mean_squared_error: 3.9225 - val_mean_absolute_error: 1.5948\n",
      "Epoch 63/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0501 - mean_squared_error: 4.0501 - mean_absolute_error: 1.6221 - val_loss: 3.9206 - val_mean_squared_error: 3.9206 - val_mean_absolute_error: 1.5921\n",
      "Epoch 64/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0490 - mean_squared_error: 4.0490 - mean_absolute_error: 1.6197 - val_loss: 3.9186 - val_mean_squared_error: 3.9186 - val_mean_absolute_error: 1.5891\n",
      "Epoch 65/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0480 - mean_squared_error: 4.0480 - mean_absolute_error: 1.6174 - val_loss: 3.9170 - val_mean_squared_error: 3.9170 - val_mean_absolute_error: 1.5868\n",
      "Epoch 66/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0471 - mean_squared_error: 4.0471 - mean_absolute_error: 1.6152 - val_loss: 3.9155 - val_mean_squared_error: 3.9155 - val_mean_absolute_error: 1.5844\n",
      "Epoch 67/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0463 - mean_squared_error: 4.0463 - mean_absolute_error: 1.6131 - val_loss: 3.9141 - val_mean_squared_error: 3.9141 - val_mean_absolute_error: 1.5823\n",
      "Epoch 68/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0456 - mean_squared_error: 4.0456 - mean_absolute_error: 1.6108 - val_loss: 3.9128 - val_mean_squared_error: 3.9128 - val_mean_absolute_error: 1.5800\n",
      "Epoch 69/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0449 - mean_squared_error: 4.0449 - mean_absolute_error: 1.6086 - val_loss: 3.9114 - val_mean_squared_error: 3.9114 - val_mean_absolute_error: 1.5777\n",
      "Epoch 70/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0444 - mean_squared_error: 4.0444 - mean_absolute_error: 1.6071 - val_loss: 3.9103 - val_mean_squared_error: 3.9103 - val_mean_absolute_error: 1.5758\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0439 - mean_squared_error: 4.0439 - mean_absolute_error: 1.6051 - val_loss: 3.9092 - val_mean_squared_error: 3.9092 - val_mean_absolute_error: 1.5738\n",
      "Epoch 72/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0435 - mean_squared_error: 4.0435 - mean_absolute_error: 1.6036 - val_loss: 3.9084 - val_mean_squared_error: 3.9084 - val_mean_absolute_error: 1.5723\n",
      "Epoch 73/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0431 - mean_squared_error: 4.0431 - mean_absolute_error: 1.6020 - val_loss: 3.9076 - val_mean_squared_error: 3.9076 - val_mean_absolute_error: 1.5708\n",
      "Epoch 74/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.6005 - val_loss: 3.9067 - val_mean_squared_error: 3.9067 - val_mean_absolute_error: 1.5691\n",
      "Epoch 75/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0425 - mean_squared_error: 4.0425 - mean_absolute_error: 1.5995 - val_loss: 3.9061 - val_mean_squared_error: 3.9061 - val_mean_absolute_error: 1.5677\n",
      "Epoch 76/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0422 - mean_squared_error: 4.0422 - mean_absolute_error: 1.5981 - val_loss: 3.9055 - val_mean_squared_error: 3.9055 - val_mean_absolute_error: 1.5665\n",
      "Epoch 77/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0420 - mean_squared_error: 4.0420 - mean_absolute_error: 1.5967 - val_loss: 3.9048 - val_mean_squared_error: 3.9048 - val_mean_absolute_error: 1.5651\n",
      "Epoch 78/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0418 - mean_squared_error: 4.0418 - mean_absolute_error: 1.5956 - val_loss: 3.9042 - val_mean_squared_error: 3.9042 - val_mean_absolute_error: 1.5638\n",
      "Epoch 79/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0416 - mean_squared_error: 4.0416 - mean_absolute_error: 1.5943 - val_loss: 3.9036 - val_mean_squared_error: 3.9036 - val_mean_absolute_error: 1.5625\n",
      "Epoch 80/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0415 - mean_squared_error: 4.0415 - mean_absolute_error: 1.5938 - val_loss: 3.9034 - val_mean_squared_error: 3.9034 - val_mean_absolute_error: 1.5619\n",
      "Epoch 81/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0413 - mean_squared_error: 4.0413 - mean_absolute_error: 1.5925 - val_loss: 3.9028 - val_mean_squared_error: 3.9028 - val_mean_absolute_error: 1.5606\n",
      "Epoch 82/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0412 - mean_squared_error: 4.0412 - mean_absolute_error: 1.5916 - val_loss: 3.9024 - val_mean_squared_error: 3.9024 - val_mean_absolute_error: 1.5596\n",
      "Epoch 83/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0411 - mean_squared_error: 4.0411 - mean_absolute_error: 1.5906 - val_loss: 3.9020 - val_mean_squared_error: 3.9020 - val_mean_absolute_error: 1.5586\n",
      "Epoch 84/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0410 - mean_squared_error: 4.0410 - mean_absolute_error: 1.5901 - val_loss: 3.9018 - val_mean_squared_error: 3.9018 - val_mean_absolute_error: 1.5581\n",
      "Epoch 85/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0410 - mean_squared_error: 4.0410 - mean_absolute_error: 1.5893 - val_loss: 3.9016 - val_mean_squared_error: 3.9016 - val_mean_absolute_error: 1.5576\n",
      "Epoch 86/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0409 - mean_squared_error: 4.0409 - mean_absolute_error: 1.5885 - val_loss: 3.9012 - val_mean_squared_error: 3.9012 - val_mean_absolute_error: 1.5565\n",
      "Epoch 87/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0409 - mean_squared_error: 4.0409 - mean_absolute_error: 1.5885 - val_loss: 3.9011 - val_mean_squared_error: 3.9011 - val_mean_absolute_error: 1.5564\n",
      "Epoch 88/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0408 - mean_squared_error: 4.0408 - mean_absolute_error: 1.5876 - val_loss: 3.9008 - val_mean_squared_error: 3.9008 - val_mean_absolute_error: 1.5556\n",
      "Epoch 89/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0408 - mean_squared_error: 4.0408 - mean_absolute_error: 1.5873 - val_loss: 3.9007 - val_mean_squared_error: 3.9007 - val_mean_absolute_error: 1.5553\n",
      "Epoch 90/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0408 - mean_squared_error: 4.0408 - mean_absolute_error: 1.5871 - val_loss: 3.9006 - val_mean_squared_error: 3.9006 - val_mean_absolute_error: 1.5550\n",
      "Epoch 91/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0407 - mean_squared_error: 4.0407 - mean_absolute_error: 1.5863 - val_loss: 3.9003 - val_mean_squared_error: 3.9003 - val_mean_absolute_error: 1.5541\n",
      "Epoch 92/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0407 - mean_squared_error: 4.0407 - mean_absolute_error: 1.5859 - val_loss: 3.9001 - val_mean_squared_error: 3.9001 - val_mean_absolute_error: 1.5538\n",
      "Epoch 93/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0407 - mean_squared_error: 4.0407 - mean_absolute_error: 1.5858 - val_loss: 3.9001 - val_mean_squared_error: 3.9001 - val_mean_absolute_error: 1.5536\n",
      "Epoch 94/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5853 - val_loss: 3.8999 - val_mean_squared_error: 3.8999 - val_mean_absolute_error: 1.5531\n",
      "Epoch 95/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5846 - val_loss: 3.8997 - val_mean_squared_error: 3.8997 - val_mean_absolute_error: 1.5525\n",
      "Epoch 96/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5847 - val_loss: 3.8997 - val_mean_squared_error: 3.8997 - val_mean_absolute_error: 1.5527\n",
      "Epoch 97/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5843 - val_loss: 3.8995 - val_mean_squared_error: 3.8995 - val_mean_absolute_error: 1.5521\n",
      "Epoch 98/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5842 - val_loss: 3.8995 - val_mean_squared_error: 3.8995 - val_mean_absolute_error: 1.5519\n",
      "Epoch 99/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5838 - val_loss: 3.8994 - val_mean_squared_error: 3.8994 - val_mean_absolute_error: 1.5516\n",
      "Epoch 100/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5837 - val_loss: 3.8993 - val_mean_squared_error: 3.8993 - val_mean_absolute_error: 1.5514\n",
      "Epoch 101/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5838 - val_loss: 3.8993 - val_mean_squared_error: 3.8993 - val_mean_absolute_error: 1.5514\n",
      "Epoch 102/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5832 - val_loss: 3.8992 - val_mean_squared_error: 3.8992 - val_mean_absolute_error: 1.5511\n",
      "Epoch 103/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5829 - val_loss: 3.8991 - val_mean_squared_error: 3.8991 - val_mean_absolute_error: 1.5509\n",
      "Epoch 104/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5828 - val_loss: 3.8990 - val_mean_squared_error: 3.8990 - val_mean_absolute_error: 1.5507\n",
      "Epoch 105/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5828 - val_loss: 3.8990 - val_mean_squared_error: 3.8990 - val_mean_absolute_error: 1.5505\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5822 - val_loss: 3.8988 - val_mean_squared_error: 3.8988 - val_mean_absolute_error: 1.5500\n",
      "Epoch 107/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5824 - val_loss: 3.8989 - val_mean_squared_error: 3.8989 - val_mean_absolute_error: 1.5503\n",
      "Epoch 108/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5824 - val_loss: 3.8989 - val_mean_squared_error: 3.8989 - val_mean_absolute_error: 1.5502\n",
      "Epoch 109/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5824 - val_loss: 3.8989 - val_mean_squared_error: 3.8989 - val_mean_absolute_error: 1.5502\n",
      "Epoch 110/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5823 - val_loss: 3.8988 - val_mean_squared_error: 3.8988 - val_mean_absolute_error: 1.5499\n",
      "Epoch 111/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5824 - val_loss: 3.8989 - val_mean_squared_error: 3.8989 - val_mean_absolute_error: 1.5501\n",
      "Epoch 112/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5821 - val_loss: 3.8987 - val_mean_squared_error: 3.8987 - val_mean_absolute_error: 1.5497\n",
      "Epoch 113/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5817 - val_loss: 3.8987 - val_mean_squared_error: 3.8987 - val_mean_absolute_error: 1.5496\n",
      "Epoch 114/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5821 - val_loss: 3.8988 - val_mean_squared_error: 3.8988 - val_mean_absolute_error: 1.5500\n",
      "Epoch 115/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5820 - val_loss: 3.8986 - val_mean_squared_error: 3.8986 - val_mean_absolute_error: 1.5494\n",
      "Epoch 116/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5817 - val_loss: 3.8987 - val_mean_squared_error: 3.8987 - val_mean_absolute_error: 1.5496\n",
      "Epoch 117/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5819 - val_loss: 3.8987 - val_mean_squared_error: 3.8987 - val_mean_absolute_error: 1.5496\n",
      "Epoch 118/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5816 - val_loss: 3.8987 - val_mean_squared_error: 3.8987 - val_mean_absolute_error: 1.5496\n",
      "Epoch 119/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5816 - val_loss: 3.8986 - val_mean_squared_error: 3.8986 - val_mean_absolute_error: 1.5492\n",
      "Epoch 120/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5810 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5489\n",
      "Epoch 121/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5815 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5491\n",
      "Epoch 122/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5819 - val_loss: 3.8986 - val_mean_squared_error: 3.8986 - val_mean_absolute_error: 1.5494\n",
      "Epoch 123/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5814 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5491\n",
      "Epoch 124/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5813 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5490\n",
      "Epoch 125/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5808 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5487\n",
      "Epoch 126/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5809 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5489\n",
      "Epoch 127/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5810 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5489\n",
      "Epoch 128/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5810 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5487\n",
      "Epoch 129/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5807 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5485\n",
      "Epoch 130/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5808 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5488\n",
      "Epoch 131/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5812 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5490\n",
      "Epoch 132/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5810 - val_loss: 3.8985 - val_mean_squared_error: 3.8985 - val_mean_absolute_error: 1.5489\n",
      "Epoch 133/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5808 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5485\n",
      "Epoch 134/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5807 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5483\n",
      "Epoch 135/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5809 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5486\n",
      "Epoch 136/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5811 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5485\n",
      "Epoch 137/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5806 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5484\n",
      "Epoch 138/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5807 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5483\n",
      "Epoch 139/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5806 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5484\n",
      "Epoch 140/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5805 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5484\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5806 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5484\n",
      "Epoch 142/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0406 - mean_squared_error: 4.0406 - mean_absolute_error: 1.5811 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5487\n",
      "Epoch 143/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5810 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5486\n",
      "Epoch 144/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5808 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5485\n",
      "Epoch 145/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5810 - val_loss: 3.8984 - val_mean_squared_error: 3.8984 - val_mean_absolute_error: 1.5487\n",
      "Epoch 146/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5809 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5484\n",
      "Epoch 147/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5807 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5485\n",
      "Epoch 148/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5808 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5484\n",
      "Epoch 149/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5805 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5482\n",
      "Epoch 150/150\n",
      "8631/8631 [==============================] - 20s 2ms/step - loss: 4.0405 - mean_squared_error: 4.0405 - mean_absolute_error: 1.5808 - val_loss: 3.8983 - val_mean_squared_error: 3.8983 - val_mean_absolute_error: 1.5485\n",
      "EndTime : 2020-09-15 13:22:46.461062\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "StartTime8 = datetime.now()\n",
    "print(\"StartTime :\", StartTime8)\n",
    "with K.tf.device('/GPU:0'):\n",
    "    model_train = model.fit(train_X, training_label_array, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                        validation_data=(test_X, test_label_array))\n",
    "\n",
    "EndTime8 = datetime.now()\n",
    "print(\"EndTime :\", EndTime8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"E://Ronny_TF//200914_reupload//Result//EYDC-9K\"\n",
    "# Option 1: Save Weights + Architecture\n",
    "model.save_weights(workdir + '//EYDC9K_ResNet_model_weight_v3.h5')\n",
    "with open(workdir + '//EYDC9K_ResNet_model_architecture_fix_v3.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Save/Load the Entire Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save(workdir + '//EYDC9K_ResNet_model_entire_model.h5')\n",
    "\n",
    "# Deletes the existing model\n",
    "# del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959/959 [==============================] - 1s 788us/step\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "test_eval = model.evaluate(test_X, test_label_array, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.8983316177869365, 3.8983316177869365, 1.5484510918727632]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss record\n",
    "accuracy = model_train.history['mean_squared_error']\n",
    "val_accuracy = model_train.history['val_mean_squared_error']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "\n",
    "np_acc = np.array(accuracy)\n",
    "np_val_acc = np.array(val_accuracy)\n",
    "np_loss = np.array(loss)\n",
    "np_val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss record\n",
    "np.savetxt(\"EYDC9K_ResNet_acc_cls3_fix_2080ti_v3.csv\", np_acc, delimiter=\",\")\n",
    "np.savetxt(\"EYDC9K_ResNet_val_acc_cls3_fix_2080ti_v3.csv\", np_val_acc, delimiter=\",\")\n",
    "np.savetxt(\"EYDC9K_ResNet_loss_cls3_fix_2080ti_v3.csv\", np_loss, delimiter=\",\")\n",
    "np.savetxt(\"EYDC9K_ResNet_val_loss_cls3_fix_2080ti_v3.csv\", np_val_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy = model_train.history['acc']\n",
    "# val_accuracy = model_train.history['val_acc']\n",
    "# loss = model_train.history['loss']\n",
    "# val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training mse')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation mse')\n",
    "plt.title('Training and validation mse')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(workdir + '//EYDC9K_ResNet_mse_loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving predicted ln(IC50)s and ln(IC50)s in the test set\n",
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_label_array)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]\n",
    "c.to_csv(workdir + '//200915_EYDC9K_ResNet_pred_and_val_result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5d7060c039de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# result table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "# result table\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "plt.scatter(test_label_array,predicted_value,c='blue')\n",
    "plt.xlabel('test_IC50_value')\n",
    "plt.ylabel('predicted_IC50_value')\n",
    "plt.savefig(workdir + '//EYDC9K_ResNet_test_scatterplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared value\n",
    "from sklearn.metrics import r2_score\n",
    "r2_value = r2_score(b,a)\n",
    "print(r2_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression value (slope)\n",
    "from scipy.stats import linregress\n",
    "linregress(b[0], a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
