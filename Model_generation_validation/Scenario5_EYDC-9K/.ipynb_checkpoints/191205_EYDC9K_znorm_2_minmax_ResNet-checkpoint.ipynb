{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "workdir = \"path\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7364948117111500884\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 18038862643\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8722698628597363240\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "# 출처: https://3months.tistory.com/206 [Deep Play]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < Important note > [ Please download input data from https://mega.nz/#F!CeYGDKyS!uqkmWJ4E2XSGJp_C2VO2gg]\n",
    "# IC50evaluation//Dataset//Scenario5_EYDC-9K_znorm_minmax\n",
    "\n",
    "dataset = np.load(workdir + \"//191204_EMDC9K_z_norm_z_norm_minmax.npz\") # input file\n",
    "ss0 = np.load(workdir + '//191204_EMDC9K_z_norm_z_norm_minmax_r0.npz') # split for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['x']\n",
    "y = dataset['y']\n",
    "# y_linear = dataset['y_lnIC50']\n",
    "ss0_train = ss0['train']\n",
    "ss0_test = ss0['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_array, training_label_array = x[ss0_train], y[ss0_train]\n",
    "test_image_array, test_label_array = x[ss0_test], y[ss0_test]\n",
    "\n",
    "# # In[9]:\n",
    "# ori = training_image_array\n",
    "# bat = np.zeros((ori.shape[0],178))\n",
    "# cat = np.hstack([ori,bat])\n",
    "# training_image_array = cat\n",
    "\n",
    "# # In[8]:\n",
    "# training_image_array.shape\n",
    "\n",
    "# # In[10]:\n",
    "# ori2 = test_image_array\n",
    "# bat2 = np.zeros((ori2.shape[0],178))\n",
    "# cat2 = np.hstack([ori2,bat2])\n",
    "# test_image_array = cat2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37\n"
     ]
    }
   ],
   "source": [
    "# In[15]:\n",
    "ab =[]\n",
    "for i in range(100,300):\n",
    "    ab.append(len(training_image_array) % i)\n",
    "    \n",
    "print(min(ab), ab.index(min(ab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9590, 41505)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8631, 41505)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[21]:\n",
    "\n",
    "num_classes = 1\n",
    "learning_rate = 0.0002\n",
    "training_epochs = 150\n",
    "batch_size = 100\n",
    "# img_rows, img_cols = 154, 154\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = training_image_array, training_label_array, test_image_array, test_label_array\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     train_X = train_X.reshape(train_X.shape[0], 1, img_rows, img_cols)\n",
    "#     test_X = test_X.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "# else:\n",
    "#     train_X = train_X.reshape(train_X.shape[0], img_rows, img_cols, 1)\n",
    "#     test_X = test_X.reshape(test_X.shape[0], img_rows, img_cols, 1)\n",
    "#     input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1],1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1],1)\n",
    "#input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8631, 41505, 1) (8631,) (959, 41505, 1) (959,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (8631, 41505, 1)\n",
      "8631 train samples\n",
      "959 test samples\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "# train_X /= 255\n",
    "# test_X /= 255\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8631, 41505)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ronnytf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ronnytf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 41505, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 20753, 16)    64          inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 4150, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4150, 16)     64          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4150, 16)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4150, 16)     784         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4150, 16)     64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4150, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4150, 16)     784         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4150, 16)     64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4150, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 4150, 16)     784         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4150, 16)     64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4150, 16)     0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 4150, 16)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 4150, 16)     784         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4150, 16)     64          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 4150, 16)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 4150, 16)     784         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4150, 16)     64          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4150, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 4150, 16)     784         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4150, 16)     64          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4150, 16)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 4150, 16)     784         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4150, 16)     64          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4150, 16)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4150, 16)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2075, 32)     1568        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2075, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 2075, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 2075, 32)     3104        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2075, 32)     3104        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2075, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2075, 32)     0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 2075, 32)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 2075, 32)     3104        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2075, 32)     128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2075, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 2075, 32)     3104        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2075, 32)     128         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2075, 32)     0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 2075, 32)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 2075, 32)     3104        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2075, 32)     128         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2075, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 2075, 32)     3104        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2075, 32)     128         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2075, 32)     0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2075, 32)     0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1038, 64)     6208        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1038, 64)     256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1038, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1038, 64)     12352       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1038, 64)     12352       conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1038, 64)     256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1038, 64)     0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1038, 64)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1038, 64)     12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1038, 64)     256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 1038, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1038, 64)     12352       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1038, 64)     256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1038, 64)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1038, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1038, 64)     12352       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 1038, 64)     256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1038, 64)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1038, 64)     12352       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1038, 64)     256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1038, 64)     0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1038, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 66432)        0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 2048)         136054784   flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2048)         8192        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 2048)         0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2048)         0           dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense5 (Dense)                  (None, 1024)         2098176     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1024)         4096        dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout5 (Dropout)              (None, 1024)         0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1024)         0           dropout5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense6 (Dense)                  (None, 512)          524800      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512)          2048        dense6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout6 (Dropout)              (None, 512)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512)          0           dropout6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense7 (Dense)                  (None, 1024)         525312      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1024)         4096        dense7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout7 (Dropout)              (None, 1024)         0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1024)         0           dropout7[0][0]                   \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1024)         0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense8 (Dense)                  (None, 512)          524800      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 512)          2048        dense8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout8 (Dropout)              (None, 512)          0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512)          0           dropout8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense9 (Dense)                  (None, 256)          131328      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256)          1024        dense9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout9 (Dropout)              (None, 256)          0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256)          0           dropout9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense10 (Dense)                 (None, 128)          32896       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128)          512         dense10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout10 (Dropout)             (None, 128)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128)          0           dropout10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            129         activation_27[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 140,023,121\n",
      "Trainable params: 140,010,705\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# In[10]:\n",
    "with K.tf.device('/GPU:0'):\n",
    "    inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     y = x\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "        \n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = MaxPooling1D(pool_size=5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#     x = AveragePooling1D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=2048, name='dense1'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout1') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "#    x = Reshape((300,1))(x)\n",
    "\n",
    "#    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "#    x = MaxPooling1D(pool_size=2)(x)\n",
    "#    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense5'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout5') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=512, name='dense6'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout6') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=1024, name='dense7'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout7') (x)\n",
    "    x = keras.layers.add([x,y])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=512, name='dense8'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout8') (x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(units=256, name='dense9'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1, name='dropout9') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(units=128, name='dense10'  ) (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    x = Dropout(0.1, name='dropout10') (x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "#     predictions = Dense(1, activation='linear', name='predictions')(x)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN20190327')\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                  metrics=['mse','mae'])\n",
    "\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2019-12-05 17:43:28.215000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ronnytf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8631 samples, validate on 959 samples\n",
      "Epoch 1/150\n",
      "8631/8631 [==============================] - 26s 3ms/step - loss: 4.7378 - mean_squared_error: 4.7378 - mean_absolute_error: 1.9753 - val_loss: 4.6128 - val_mean_squared_error: 4.6128 - val_mean_absolute_error: 1.9558\n",
      "Epoch 2/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.7105 - mean_squared_error: 4.7105 - mean_absolute_error: 1.9666 - val_loss: 4.5848 - val_mean_squared_error: 4.5848 - val_mean_absolute_error: 1.9474\n",
      "Epoch 3/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.6838 - mean_squared_error: 4.6838 - mean_absolute_error: 1.9578 - val_loss: 4.5572 - val_mean_squared_error: 4.5572 - val_mean_absolute_error: 1.9389\n",
      "Epoch 4/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.6577 - mean_squared_error: 4.6577 - mean_absolute_error: 1.9492 - val_loss: 4.5305 - val_mean_squared_error: 4.5305 - val_mean_absolute_error: 1.9306\n",
      "Epoch 5/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.6325 - mean_squared_error: 4.6325 - mean_absolute_error: 1.9406 - val_loss: 4.5047 - val_mean_squared_error: 4.5047 - val_mean_absolute_error: 1.9223\n",
      "Epoch 6/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.6080 - mean_squared_error: 4.6080 - mean_absolute_error: 1.9322 - val_loss: 4.4797 - val_mean_squared_error: 4.4797 - val_mean_absolute_error: 1.9142\n",
      "Epoch 7/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.5843 - mean_squared_error: 4.5843 - mean_absolute_error: 1.9239 - val_loss: 4.4553 - val_mean_squared_error: 4.4553 - val_mean_absolute_error: 1.9062\n",
      "Epoch 8/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.5612 - mean_squared_error: 4.5612 - mean_absolute_error: 1.9156 - val_loss: 4.4317 - val_mean_squared_error: 4.4317 - val_mean_absolute_error: 1.8982\n",
      "Epoch 9/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.5390 - mean_squared_error: 4.5390 - mean_absolute_error: 1.9075 - val_loss: 4.4087 - val_mean_squared_error: 4.4087 - val_mean_absolute_error: 1.8904\n",
      "Epoch 10/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.5175 - mean_squared_error: 4.5175 - mean_absolute_error: 1.8996 - val_loss: 4.3865 - val_mean_squared_error: 4.3865 - val_mean_absolute_error: 1.8827\n",
      "Epoch 11/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.4966 - mean_squared_error: 4.4966 - mean_absolute_error: 1.8917 - val_loss: 4.3649 - val_mean_squared_error: 4.3649 - val_mean_absolute_error: 1.8751\n",
      "Epoch 12/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.4764 - mean_squared_error: 4.4764 - mean_absolute_error: 1.8839 - val_loss: 4.3439 - val_mean_squared_error: 4.3439 - val_mean_absolute_error: 1.8675\n",
      "Epoch 13/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.4570 - mean_squared_error: 4.4570 - mean_absolute_error: 1.8763 - val_loss: 4.3243 - val_mean_squared_error: 4.3243 - val_mean_absolute_error: 1.8604\n",
      "Epoch 14/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.4382 - mean_squared_error: 4.4382 - mean_absolute_error: 1.8688 - val_loss: 4.3044 - val_mean_squared_error: 4.3044 - val_mean_absolute_error: 1.8531\n",
      "Epoch 15/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.4200 - mean_squared_error: 4.4200 - mean_absolute_error: 1.8614 - val_loss: 4.2857 - val_mean_squared_error: 4.2857 - val_mean_absolute_error: 1.8461\n",
      "Epoch 16/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.4024 - mean_squared_error: 4.4024 - mean_absolute_error: 1.8541 - val_loss: 4.2677 - val_mean_squared_error: 4.2677 - val_mean_absolute_error: 1.8391\n",
      "Epoch 17/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.3855 - mean_squared_error: 4.3855 - mean_absolute_error: 1.8469 - val_loss: 4.2498 - val_mean_squared_error: 4.2498 - val_mean_absolute_error: 1.8321\n",
      "Epoch 18/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.3691 - mean_squared_error: 4.3691 - mean_absolute_error: 1.8398 - val_loss: 4.2329 - val_mean_squared_error: 4.2329 - val_mean_absolute_error: 1.8254\n",
      "Epoch 19/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.3532 - mean_squared_error: 4.3532 - mean_absolute_error: 1.8327 - val_loss: 4.2165 - val_mean_squared_error: 4.2165 - val_mean_absolute_error: 1.8187\n",
      "Epoch 20/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.3379 - mean_squared_error: 4.3379 - mean_absolute_error: 1.8259 - val_loss: 4.2005 - val_mean_squared_error: 4.2005 - val_mean_absolute_error: 1.8120\n",
      "Epoch 21/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.3231 - mean_squared_error: 4.3231 - mean_absolute_error: 1.8189 - val_loss: 4.1851 - val_mean_squared_error: 4.1851 - val_mean_absolute_error: 1.8054\n",
      "Epoch 22/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.3089 - mean_squared_error: 4.3089 - mean_absolute_error: 1.8122 - val_loss: 4.1703 - val_mean_squared_error: 4.1703 - val_mean_absolute_error: 1.7990\n",
      "Epoch 23/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.2950 - mean_squared_error: 4.2950 - mean_absolute_error: 1.8055 - val_loss: 4.1558 - val_mean_squared_error: 4.1558 - val_mean_absolute_error: 1.7925\n",
      "Epoch 24/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.2818 - mean_squared_error: 4.2818 - mean_absolute_error: 1.7988 - val_loss: 4.1418 - val_mean_squared_error: 4.1418 - val_mean_absolute_error: 1.7862\n",
      "Epoch 25/150\n",
      "8631/8631 [==============================] - 14s 2ms/step - loss: 4.2691 - mean_squared_error: 4.2691 - mean_absolute_error: 1.7924 - val_loss: 4.1286 - val_mean_squared_error: 4.1286 - val_mean_absolute_error: 1.7800\n",
      "Epoch 26/150\n",
      "8631/8631 [==============================] - 14s 2ms/step - loss: 4.2569 - mean_squared_error: 4.2569 - mean_absolute_error: 1.7861 - val_loss: 4.1158 - val_mean_squared_error: 4.1158 - val_mean_absolute_error: 1.7740\n",
      "Epoch 27/150\n",
      "8631/8631 [==============================] - 14s 2ms/step - loss: 4.2452 - mean_squared_error: 4.2452 - mean_absolute_error: 1.7797 - val_loss: 4.1036 - val_mean_squared_error: 4.1036 - val_mean_absolute_error: 1.7680\n",
      "Epoch 28/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.2339 - mean_squared_error: 4.2339 - mean_absolute_error: 1.7737 - val_loss: 4.0916 - val_mean_squared_error: 4.0916 - val_mean_absolute_error: 1.7621\n",
      "Epoch 29/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.2230 - mean_squared_error: 4.2230 - mean_absolute_error: 1.7674 - val_loss: 4.0802 - val_mean_squared_error: 4.0802 - val_mean_absolute_error: 1.7562\n",
      "Epoch 30/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.2126 - mean_squared_error: 4.2126 - mean_absolute_error: 1.7616 - val_loss: 4.0692 - val_mean_squared_error: 4.0692 - val_mean_absolute_error: 1.7504\n",
      "Epoch 31/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.2025 - mean_squared_error: 4.2025 - mean_absolute_error: 1.7556 - val_loss: 4.0585 - val_mean_squared_error: 4.0585 - val_mean_absolute_error: 1.7446\n",
      "Epoch 32/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1929 - mean_squared_error: 4.1929 - mean_absolute_error: 1.7497 - val_loss: 4.0483 - val_mean_squared_error: 4.0483 - val_mean_absolute_error: 1.7390\n",
      "Epoch 33/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1837 - mean_squared_error: 4.1837 - mean_absolute_error: 1.7440 - val_loss: 4.0385 - val_mean_squared_error: 4.0385 - val_mean_absolute_error: 1.7335\n",
      "Epoch 34/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1748 - mean_squared_error: 4.1748 - mean_absolute_error: 1.7383 - val_loss: 4.0289 - val_mean_squared_error: 4.0289 - val_mean_absolute_error: 1.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1664 - mean_squared_error: 4.1664 - mean_absolute_error: 1.7328 - val_loss: 4.0200 - val_mean_squared_error: 4.0200 - val_mean_absolute_error: 1.7227\n",
      "Epoch 36/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1584 - mean_squared_error: 4.1584 - mean_absolute_error: 1.7273 - val_loss: 4.0114 - val_mean_squared_error: 4.0114 - val_mean_absolute_error: 1.7174\n",
      "Epoch 37/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1507 - mean_squared_error: 4.1507 - mean_absolute_error: 1.7221 - val_loss: 4.0033 - val_mean_squared_error: 4.0033 - val_mean_absolute_error: 1.7124\n",
      "Epoch 38/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1435 - mean_squared_error: 4.1435 - mean_absolute_error: 1.7167 - val_loss: 3.9954 - val_mean_squared_error: 3.9954 - val_mean_absolute_error: 1.7072\n",
      "Epoch 39/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1365 - mean_squared_error: 4.1365 - mean_absolute_error: 1.7116 - val_loss: 3.9881 - val_mean_squared_error: 3.9881 - val_mean_absolute_error: 1.7024\n",
      "Epoch 40/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1301 - mean_squared_error: 4.1301 - mean_absolute_error: 1.7064 - val_loss: 3.9807 - val_mean_squared_error: 3.9807 - val_mean_absolute_error: 1.6973\n",
      "Epoch 41/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1238 - mean_squared_error: 4.1238 - mean_absolute_error: 1.7018 - val_loss: 3.9745 - val_mean_squared_error: 3.9745 - val_mean_absolute_error: 1.6928\n",
      "Epoch 42/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1180 - mean_squared_error: 4.1180 - mean_absolute_error: 1.6971 - val_loss: 3.9681 - val_mean_squared_error: 3.9681 - val_mean_absolute_error: 1.6881\n",
      "Epoch 43/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1124 - mean_squared_error: 4.1124 - mean_absolute_error: 1.6922 - val_loss: 3.9619 - val_mean_squared_error: 3.9619 - val_mean_absolute_error: 1.6834\n",
      "Epoch 44/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1070 - mean_squared_error: 4.1070 - mean_absolute_error: 1.6875 - val_loss: 3.9559 - val_mean_squared_error: 3.9559 - val_mean_absolute_error: 1.6787\n",
      "Epoch 45/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.1022 - mean_squared_error: 4.1022 - mean_absolute_error: 1.6830 - val_loss: 3.9506 - val_mean_squared_error: 3.9506 - val_mean_absolute_error: 1.6743\n",
      "Epoch 46/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0976 - mean_squared_error: 4.0976 - mean_absolute_error: 1.6787 - val_loss: 3.9454 - val_mean_squared_error: 3.9454 - val_mean_absolute_error: 1.6699\n",
      "Epoch 47/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0931 - mean_squared_error: 4.0931 - mean_absolute_error: 1.6743 - val_loss: 3.9405 - val_mean_squared_error: 3.9405 - val_mean_absolute_error: 1.6657\n",
      "Epoch 48/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0889 - mean_squared_error: 4.0889 - mean_absolute_error: 1.6699 - val_loss: 3.9359 - val_mean_squared_error: 3.9359 - val_mean_absolute_error: 1.6615\n",
      "Epoch 49/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0851 - mean_squared_error: 4.0851 - mean_absolute_error: 1.6660 - val_loss: 3.9318 - val_mean_squared_error: 3.9318 - val_mean_absolute_error: 1.6576\n",
      "Epoch 50/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0816 - mean_squared_error: 4.0816 - mean_absolute_error: 1.6621 - val_loss: 3.9277 - val_mean_squared_error: 3.9277 - val_mean_absolute_error: 1.6536\n",
      "Epoch 51/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0782 - mean_squared_error: 4.0782 - mean_absolute_error: 1.6581 - val_loss: 3.9239 - val_mean_squared_error: 3.9239 - val_mean_absolute_error: 1.6498\n",
      "Epoch 52/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0750 - mean_squared_error: 4.0750 - mean_absolute_error: 1.6543 - val_loss: 3.9203 - val_mean_squared_error: 3.9203 - val_mean_absolute_error: 1.6460\n",
      "Epoch 53/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0722 - mean_squared_error: 4.0722 - mean_absolute_error: 1.6505 - val_loss: 3.9169 - val_mean_squared_error: 3.9169 - val_mean_absolute_error: 1.6423\n",
      "Epoch 54/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0695 - mean_squared_error: 4.0695 - mean_absolute_error: 1.6471 - val_loss: 3.9137 - val_mean_squared_error: 3.9137 - val_mean_absolute_error: 1.6388\n",
      "Epoch 55/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0669 - mean_squared_error: 4.0669 - mean_absolute_error: 1.6434 - val_loss: 3.9108 - val_mean_squared_error: 3.9108 - val_mean_absolute_error: 1.6354\n",
      "Epoch 56/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0646 - mean_squared_error: 4.0646 - mean_absolute_error: 1.6403 - val_loss: 3.9083 - val_mean_squared_error: 3.9083 - val_mean_absolute_error: 1.6323\n",
      "Epoch 57/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0624 - mean_squared_error: 4.0624 - mean_absolute_error: 1.6369 - val_loss: 3.9056 - val_mean_squared_error: 3.9056 - val_mean_absolute_error: 1.6289\n",
      "Epoch 58/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0605 - mean_squared_error: 4.0605 - mean_absolute_error: 1.6338 - val_loss: 3.9033 - val_mean_squared_error: 3.9033 - val_mean_absolute_error: 1.6258\n",
      "Epoch 59/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0587 - mean_squared_error: 4.0587 - mean_absolute_error: 1.6307 - val_loss: 3.9011 - val_mean_squared_error: 3.9011 - val_mean_absolute_error: 1.6229\n",
      "Epoch 60/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0570 - mean_squared_error: 4.0570 - mean_absolute_error: 1.6279 - val_loss: 3.8991 - val_mean_squared_error: 3.8991 - val_mean_absolute_error: 1.6200\n",
      "Epoch 61/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0555 - mean_squared_error: 4.0555 - mean_absolute_error: 1.6250 - val_loss: 3.8972 - val_mean_squared_error: 3.8972 - val_mean_absolute_error: 1.6172\n",
      "Epoch 62/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0541 - mean_squared_error: 4.0541 - mean_absolute_error: 1.6222 - val_loss: 3.8955 - val_mean_squared_error: 3.8955 - val_mean_absolute_error: 1.6145\n",
      "Epoch 63/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0528 - mean_squared_error: 4.0528 - mean_absolute_error: 1.6196 - val_loss: 3.8939 - val_mean_squared_error: 3.8939 - val_mean_absolute_error: 1.6118\n",
      "Epoch 64/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0517 - mean_squared_error: 4.0517 - mean_absolute_error: 1.6171 - val_loss: 3.8925 - val_mean_squared_error: 3.8925 - val_mean_absolute_error: 1.6094\n",
      "Epoch 65/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0507 - mean_squared_error: 4.0507 - mean_absolute_error: 1.6145 - val_loss: 3.8911 - val_mean_squared_error: 3.8911 - val_mean_absolute_error: 1.6069\n",
      "Epoch 66/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0497 - mean_squared_error: 4.0497 - mean_absolute_error: 1.6125 - val_loss: 3.8900 - val_mean_squared_error: 3.8900 - val_mean_absolute_error: 1.6049\n",
      "Epoch 67/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0489 - mean_squared_error: 4.0489 - mean_absolute_error: 1.6099 - val_loss: 3.8887 - val_mean_squared_error: 3.8887 - val_mean_absolute_error: 1.6024\n",
      "Epoch 68/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0481 - mean_squared_error: 4.0481 - mean_absolute_error: 1.6076 - val_loss: 3.8876 - val_mean_squared_error: 3.8876 - val_mean_absolute_error: 1.6002\n",
      "Epoch 69/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0475 - mean_squared_error: 4.0475 - mean_absolute_error: 1.6057 - val_loss: 3.8867 - val_mean_squared_error: 3.8867 - val_mean_absolute_error: 1.5983\n",
      "Epoch 70/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0469 - mean_squared_error: 4.0469 - mean_absolute_error: 1.6040 - val_loss: 3.8860 - val_mean_squared_error: 3.8860 - val_mean_absolute_error: 1.5966\n",
      "Epoch 71/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0464 - mean_squared_error: 4.0464 - mean_absolute_error: 1.6025 - val_loss: 3.8853 - val_mean_squared_error: 3.8853 - val_mean_absolute_error: 1.5951\n",
      "Epoch 72/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0460 - mean_squared_error: 4.0460 - mean_absolute_error: 1.6003 - val_loss: 3.8845 - val_mean_squared_error: 3.8845 - val_mean_absolute_error: 1.5932\n",
      "Epoch 73/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0455 - mean_squared_error: 4.0455 - mean_absolute_error: 1.5989 - val_loss: 3.8840 - val_mean_squared_error: 3.8840 - val_mean_absolute_error: 1.5918\n",
      "Epoch 74/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0452 - mean_squared_error: 4.0452 - mean_absolute_error: 1.5974 - val_loss: 3.8834 - val_mean_squared_error: 3.8834 - val_mean_absolute_error: 1.5904\n",
      "Epoch 75/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0449 - mean_squared_error: 4.0449 - mean_absolute_error: 1.5956 - val_loss: 3.8828 - val_mean_squared_error: 3.8828 - val_mean_absolute_error: 1.5886\n",
      "Epoch 76/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0445 - mean_squared_error: 4.0445 - mean_absolute_error: 1.5943 - val_loss: 3.8823 - val_mean_squared_error: 3.8823 - val_mean_absolute_error: 1.5873\n",
      "Epoch 77/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0443 - mean_squared_error: 4.0443 - mean_absolute_error: 1.5929 - val_loss: 3.8819 - val_mean_squared_error: 3.8819 - val_mean_absolute_error: 1.5859\n",
      "Epoch 78/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0440 - mean_squared_error: 4.0440 - mean_absolute_error: 1.5920 - val_loss: 3.8815 - val_mean_squared_error: 3.8815 - val_mean_absolute_error: 1.5848\n",
      "Epoch 79/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0439 - mean_squared_error: 4.0439 - mean_absolute_error: 1.5905 - val_loss: 3.8811 - val_mean_squared_error: 3.8811 - val_mean_absolute_error: 1.5835\n",
      "Epoch 80/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0437 - mean_squared_error: 4.0437 - mean_absolute_error: 1.5899 - val_loss: 3.8810 - val_mean_squared_error: 3.8810 - val_mean_absolute_error: 1.5831\n",
      "Epoch 81/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0436 - mean_squared_error: 4.0436 - mean_absolute_error: 1.5886 - val_loss: 3.8806 - val_mean_squared_error: 3.8806 - val_mean_absolute_error: 1.5817\n",
      "Epoch 82/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0434 - mean_squared_error: 4.0434 - mean_absolute_error: 1.5876 - val_loss: 3.8803 - val_mean_squared_error: 3.8803 - val_mean_absolute_error: 1.5807\n",
      "Epoch 83/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0434 - mean_squared_error: 4.0434 - mean_absolute_error: 1.5871 - val_loss: 3.8801 - val_mean_squared_error: 3.8801 - val_mean_absolute_error: 1.5800\n",
      "Epoch 84/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0433 - mean_squared_error: 4.0433 - mean_absolute_error: 1.5861 - val_loss: 3.8799 - val_mean_squared_error: 3.8799 - val_mean_absolute_error: 1.5793\n",
      "Epoch 85/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0432 - mean_squared_error: 4.0432 - mean_absolute_error: 1.5853 - val_loss: 3.8797 - val_mean_squared_error: 3.8797 - val_mean_absolute_error: 1.5784\n",
      "Epoch 86/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0431 - mean_squared_error: 4.0431 - mean_absolute_error: 1.5846 - val_loss: 3.8795 - val_mean_squared_error: 3.8795 - val_mean_absolute_error: 1.5775\n",
      "Epoch 87/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0431 - mean_squared_error: 4.0431 - mean_absolute_error: 1.5841 - val_loss: 3.8795 - val_mean_squared_error: 3.8795 - val_mean_absolute_error: 1.5774\n",
      "Epoch 88/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0430 - mean_squared_error: 4.0430 - mean_absolute_error: 1.5834 - val_loss: 3.8793 - val_mean_squared_error: 3.8793 - val_mean_absolute_error: 1.5768\n",
      "Epoch 89/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0430 - mean_squared_error: 4.0430 - mean_absolute_error: 1.5831 - val_loss: 3.8792 - val_mean_squared_error: 3.8792 - val_mean_absolute_error: 1.5763\n",
      "Epoch 90/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0430 - mean_squared_error: 4.0430 - mean_absolute_error: 1.5824 - val_loss: 3.8791 - val_mean_squared_error: 3.8791 - val_mean_absolute_error: 1.5758\n",
      "Epoch 91/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0429 - mean_squared_error: 4.0429 - mean_absolute_error: 1.5818 - val_loss: 3.8789 - val_mean_squared_error: 3.8789 - val_mean_absolute_error: 1.5750\n",
      "Epoch 92/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0429 - mean_squared_error: 4.0429 - mean_absolute_error: 1.5815 - val_loss: 3.8789 - val_mean_squared_error: 3.8789 - val_mean_absolute_error: 1.5747\n",
      "Epoch 93/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0429 - mean_squared_error: 4.0429 - mean_absolute_error: 1.5813 - val_loss: 3.8789 - val_mean_squared_error: 3.8789 - val_mean_absolute_error: 1.5747\n",
      "Epoch 94/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5809 - val_loss: 3.8788 - val_mean_squared_error: 3.8788 - val_mean_absolute_error: 1.5741\n",
      "Epoch 95/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5806 - val_loss: 3.8787 - val_mean_squared_error: 3.8787 - val_mean_absolute_error: 1.5738\n",
      "Epoch 96/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5804 - val_loss: 3.8786 - val_mean_squared_error: 3.8786 - val_mean_absolute_error: 1.5735\n",
      "Epoch 97/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5802 - val_loss: 3.8786 - val_mean_squared_error: 3.8786 - val_mean_absolute_error: 1.5734\n",
      "Epoch 98/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5796 - val_loss: 3.8785 - val_mean_squared_error: 3.8785 - val_mean_absolute_error: 1.5728\n",
      "Epoch 99/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5790 - val_loss: 3.8784 - val_mean_squared_error: 3.8784 - val_mean_absolute_error: 1.5723\n",
      "Epoch 100/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5788 - val_loss: 3.8784 - val_mean_squared_error: 3.8784 - val_mean_absolute_error: 1.5723\n",
      "Epoch 101/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5789 - val_loss: 3.8784 - val_mean_squared_error: 3.8784 - val_mean_absolute_error: 1.5721\n",
      "Epoch 102/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5784 - val_loss: 3.8783 - val_mean_squared_error: 3.8783 - val_mean_absolute_error: 1.5718\n",
      "Epoch 103/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5787 - val_loss: 3.8784 - val_mean_squared_error: 3.8784 - val_mean_absolute_error: 1.5722\n",
      "Epoch 104/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5786 - val_loss: 3.8784 - val_mean_squared_error: 3.8784 - val_mean_absolute_error: 1.5720\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5785 - val_loss: 3.8783 - val_mean_squared_error: 3.8783 - val_mean_absolute_error: 1.5716\n",
      "Epoch 106/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5782 - val_loss: 3.8783 - val_mean_squared_error: 3.8783 - val_mean_absolute_error: 1.5715\n",
      "Epoch 107/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5784 - val_loss: 3.8783 - val_mean_squared_error: 3.8783 - val_mean_absolute_error: 1.5716\n",
      "Epoch 108/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5780 - val_loss: 3.8782 - val_mean_squared_error: 3.8782 - val_mean_absolute_error: 1.5708\n",
      "Epoch 109/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5777 - val_loss: 3.8782 - val_mean_squared_error: 3.8782 - val_mean_absolute_error: 1.5713\n",
      "Epoch 110/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5776 - val_loss: 3.8782 - val_mean_squared_error: 3.8782 - val_mean_absolute_error: 1.5709\n",
      "Epoch 111/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5771 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5704\n",
      "Epoch 112/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5773 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5707\n",
      "Epoch 113/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5774 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5707\n",
      "Epoch 114/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5774 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5707\n",
      "Epoch 115/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5772 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5705\n",
      "Epoch 116/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5771 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5705\n",
      "Epoch 117/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5774 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5705\n",
      "Epoch 118/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5770 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5706\n",
      "Epoch 119/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5776 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5708\n",
      "Epoch 120/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5772 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5704\n",
      "Epoch 121/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5769 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5703\n",
      "Epoch 122/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5772 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5706\n",
      "Epoch 123/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5772 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5703\n",
      "Epoch 124/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5765 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5700\n",
      "Epoch 125/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5767 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5698\n",
      "Epoch 126/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5764 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5697\n",
      "Epoch 127/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5763 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5700\n",
      "Epoch 128/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5766 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5699\n",
      "Epoch 129/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5770 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5703\n",
      "Epoch 130/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5770 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5700\n",
      "Epoch 131/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5773 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5706\n",
      "Epoch 132/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5766 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5701\n",
      "Epoch 133/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5770 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5702\n",
      "Epoch 134/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5765 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5701\n",
      "Epoch 135/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5766 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5699\n",
      "Epoch 136/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5765 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5702\n",
      "Epoch 137/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5766 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5701\n",
      "Epoch 138/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5762 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5698\n",
      "Epoch 139/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5766 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5699\n",
      "Epoch 140/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5757 - val_loss: 3.8779 - val_mean_squared_error: 3.8779 - val_mean_absolute_error: 1.5694\n",
      "Epoch 141/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5766 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5698\n",
      "Epoch 142/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5764 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5699\n",
      "Epoch 143/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5769 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5701\n",
      "Epoch 144/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5762 - val_loss: 3.8780 - val_mean_squared_error: 3.8780 - val_mean_absolute_error: 1.5696\n",
      "Epoch 145/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5769 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5704\n",
      "Epoch 146/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5768 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5703\n",
      "Epoch 147/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5770 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5702\n",
      "Epoch 148/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0428 - mean_squared_error: 4.0428 - mean_absolute_error: 1.5773 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5704\n",
      "Epoch 149/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5769 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5703\n",
      "Epoch 150/150\n",
      "8631/8631 [==============================] - 15s 2ms/step - loss: 4.0427 - mean_squared_error: 4.0427 - mean_absolute_error: 1.5770 - val_loss: 3.8781 - val_mean_squared_error: 3.8781 - val_mean_absolute_error: 1.5703\n",
      "EndTime : 2019-12-05 18:20:21.597000\n"
     ]
    }
   ],
   "source": [
    "StartTime8 = datetime.now()\n",
    "print(\"StartTime :\", StartTime8)\n",
    "with K.tf.device('/GPU:0'):\n",
    "    model_train = model.fit(train_X, training_label_array, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                        validation_data=(test_X, test_label_array))\n",
    "\n",
    "EndTime8 = datetime.now()\n",
    "print(\"EndTime :\", EndTime8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"E://Ronny_TF//DrugResponsivenessGuidelines//Experiments//191205_rerun//ResNet//Result//EYDC-9K//ResNet\"\n",
    "# Option 1: Save Weights + Architecture\n",
    "model.save_weights(workdir+ '//EYDC9K_ResNet_model_fix_v3.h5')\n",
    "with open(workdir + '//EYDC9K_ResNet_model_architecture_fix_v3.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "# Option 1: Load Weights + Architecture\n",
    "# with open('model_architecture.json', 'r') as f:\n",
    "#     new_model_1 = model_from_json(f.read())\n",
    "# new_model_1.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Save/Load the Entire Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save(workdir + '//EYDC9K_ResNet_model_fix_2080ti_v3.h5')\n",
    "\n",
    "# Deletes the existing model\n",
    "# del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959/959 [==============================] - 1s 680us/step\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(test_X, test_label_array, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.8780664425572464, 3.8780664425572464, 1.5702752583466928]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['mean_squared_error']\n",
    "val_accuracy = model_train.history['val_mean_squared_error']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "\n",
    "np_acc = np.array(accuracy)\n",
    "np_val_acc = np.array(val_accuracy)\n",
    "np_loss = np.array(loss)\n",
    "np_val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"191205_EYDC9K_ResNet_acc_cls3_fix_2080ti_v3.csv\", np_acc, delimiter=\",\")\n",
    "np.savetxt(\"191205_EYDC9K_ResNet_val_acc_cls3_fix_2080ti_v3.csv\", np_val_acc, delimiter=\",\")\n",
    "np.savetxt(\"191205_EYDC9K_ResNet_loss_cls3_fix_2080ti_v3.csv\", np_loss, delimiter=\",\")\n",
    "np.savetxt(\"191205_EYDC9K_ResNet_val_loss_cls3_fix_2080ti_v3.csv\", np_val_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy = model_train.history['acc']\n",
    "# val_accuracy = model_train.history['val_acc']\n",
    "# loss = model_train.history['loss']\n",
    "# val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training mse')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation mse')\n",
    "plt.title('Training and validation mse')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(workdir + '//mse_loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_label_array)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(workdir + '//EYDC9K_ResNet_Predicted_test_val_for_plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-1.595384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-3.566824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-0.294071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.039509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-0.077654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-1.390504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.035422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-1.436804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>1.019624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-4.561070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-1.301971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-5.006347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-3.785315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.055531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>1.774149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-3.256286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-0.334657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-4.362381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>1.013571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-3.618670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>1.479909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>0.470163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-2.459193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>1.076232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>1.357675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-1.024949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-2.884054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-0.837603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>-1.808728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>1.896654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted      Test\n",
       "0     0.841103  2.079442\n",
       "1     0.841103  2.079442\n",
       "2     0.841103 -1.595384\n",
       "3     0.841103  2.079442\n",
       "4     0.841103 -3.566824\n",
       "5     0.841103  2.079442\n",
       "6     0.841103 -0.294071\n",
       "7     0.841103  2.079442\n",
       "8     0.841103  2.039509\n",
       "9     0.841103 -0.077654\n",
       "10    0.841103 -1.390504\n",
       "11    0.841103  2.079442\n",
       "12    0.841103  2.035422\n",
       "13    0.841103  2.079442\n",
       "14    0.841103 -1.436804\n",
       "15    0.841103  2.079442\n",
       "16    0.841103  1.019624\n",
       "17    0.841103 -4.561070\n",
       "18    0.841103 -1.301971\n",
       "19    0.841103  2.079442\n",
       "20    0.841103  2.079442\n",
       "21    0.841103  2.079442\n",
       "22    0.841103 -5.006347\n",
       "23    0.841103  2.079442\n",
       "24    0.841103  2.079442\n",
       "25    0.841103  2.079442\n",
       "26    0.841103 -3.785315\n",
       "27    0.841103  2.055531\n",
       "28    0.841103  1.774149\n",
       "29    0.841103 -3.256286\n",
       "..         ...       ...\n",
       "929   0.841103 -0.334657\n",
       "930   0.841103  2.079442\n",
       "931   0.841103 -4.362381\n",
       "932   0.841103  1.013571\n",
       "933   0.841103  2.079442\n",
       "934   0.841103  2.079442\n",
       "935   0.841103  2.079442\n",
       "936   0.841103 -3.618670\n",
       "937   0.841103  2.079442\n",
       "938   0.841103  2.079442\n",
       "939   0.841103  2.079442\n",
       "940   0.841103  2.079442\n",
       "941   0.841103  1.479909\n",
       "942   0.841103  2.079442\n",
       "943   0.841103  2.079442\n",
       "944   0.841103  0.470163\n",
       "945   0.841103  2.079442\n",
       "946   0.841103  2.079442\n",
       "947   0.841103 -2.459193\n",
       "948   0.841103  2.079442\n",
       "949   0.841103  2.079442\n",
       "950   0.841103  2.079442\n",
       "951   0.841103  1.076232\n",
       "952   0.841103  2.079442\n",
       "953   0.841103  1.357675\n",
       "954   0.841103 -1.024949\n",
       "955   0.841103 -2.884054\n",
       "956   0.841103 -0.837603\n",
       "957   0.841103 -1.808728\n",
       "958   0.841103  1.896654\n",
       "\n",
       "[959 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_label_array,predicted_value,c='blue')\n",
    "plt.xlabel('test_IC50_value')\n",
    "plt.ylabel('predicted_IC50_value')\n",
    "plt.savefig(workdir + '//191017_EMDC9k_ResNet_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rmse value is = 1.9692807444966305\n"
     ]
    }
   ],
   "source": [
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
